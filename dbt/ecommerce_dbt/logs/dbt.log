[0m03:41:15.528418 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 03:41:15.536211 | 0578c3a5-3847-4a2c-a245-95f12e8661d9 ==============================
[0m03:41:15.536211 [info ] [MainThread]: Running with dbt=1.8.0
[0m03:41:15.540230 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/.dbt --target dev', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:41:15.866876 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:41:15.877077 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:41:15.879219 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.52785033, "process_user_time": 2.622602, "process_kernel_time": 0.24499, "process_mem_max_rss": "100664", "process_in_blocks": "152", "process_out_blocks": "0"}
[0m03:41:15.881503 [debug] [MainThread]: Command `dbt deps` succeeded at 03:41:15.881289 after 0.53 seconds
[0m03:41:15.886441 [debug] [MainThread]: Flushing usage events
[0m03:41:25.744189 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 03:41:25.754915 | 2fac0da1-1d3c-4f4c-88ed-48981c639571 ==============================
[0m03:41:25.754915 [info ] [MainThread]: Running with dbt=1.8.0
[0m03:41:25.756525 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt --target dev', 'send_anonymous_usage_stats': 'True'}
[0m03:41:25.779127 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.postgres'
[0m03:41:25.780298 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "ecommerce_profile", target "dev" invalid: Runtime Error
    Could not find adapter type postgres!
[0m03:41:25.782478 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.17400031, "process_user_time": 2.086568, "process_kernel_time": 0.258799, "process_mem_max_rss": "98220", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m03:41:25.784450 [debug] [MainThread]: Command `dbt run` failed at 03:41:25.784062 after 0.18 seconds
[0m03:41:25.787053 [debug] [MainThread]: Flushing usage events
[0m03:41:52.231405 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 03:41:52.241198 | f40fb74b-b09a-4624-9c21-380d0da173c0 ==============================
[0m03:41:52.241198 [info ] [MainThread]: Running with dbt=1.8.0
[0m03:41:52.242928 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt --target dev', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:41:52.738976 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m03:41:52.809752 [debug] [MainThread]: checksum: 2a6c64e758918535ccc035b9d143fb4c91b01df5f630e583361ba23a87d2a511, vars: {}, profile: , target: dev, version: 1.8.0
[0m03:41:52.816701 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:41:58.184988 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m03:41:58.586509 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named dim_customer. Resources and their associated columns may only be described a single time. To fix this, remove the resource entry for dim_customer in one of these files:
   - models/marts/schema.yml
  models/gold/dimensions/_dimensions__models.yml
[0m03:41:58.591207 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 6.535781, "process_user_time": 4.682469, "process_kernel_time": 0.465012, "process_mem_max_rss": "113744", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m03:41:58.596303 [debug] [MainThread]: Command `dbt run` failed at 03:41:58.596073 after 6.54 seconds
[0m03:41:58.603863 [debug] [MainThread]: Flushing usage events
[0m03:42:24.327650 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 03:42:24.341266 | e171bb8b-c96f-46d3-8e9f-c456c08c7ef0 ==============================
[0m03:42:24.341266 [info ] [MainThread]: Running with dbt=1.8.0
[0m03:42:24.345032 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt --target dev', 'send_anonymous_usage_stats': 'True'}
[0m03:42:24.797822 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m03:42:24.858757 [debug] [MainThread]: checksum: 2a6c64e758918535ccc035b9d143fb4c91b01df5f630e583361ba23a87d2a511, vars: {}, profile: , target: dev, version: 1.8.0
[0m03:42:24.864943 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:42:28.400310 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m03:42:29.116890 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.marts
- models.ecommerce_dbt.staging
[0m03:42:29.576234 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m03:42:29.584255 [info ] [MainThread]: 
[0m03:42:29.588941 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:42:29.605433 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m03:42:29.694971 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m03:42:29.700532 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m03:42:29.705260 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:42:29.725317 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.020 seconds
[0m03:42:29.756755 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m03:42:29.770795 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m03:42:29.778491 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m03:42:29.787938 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:29.816755 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.029 seconds
[0m03:42:29.824059 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m03:42:29.832437 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m03:42:29.834624 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m03:42:29.837723 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:29.859069 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.021 seconds
[0m03:42:29.867096 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m03:42:29.874943 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now create_ecommerce_db_analytics_silver)
[0m03:42:29.882169 [debug] [ThreadPool]: Creating schema "database: "ecommerce_db"
schema: "analytics_silver"
"
[0m03:42:29.895942 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_silver"
[0m03:42:29.901747 [debug] [ThreadPool]: On create_ecommerce_db_analytics_silver: BEGIN
[0m03:42:29.903339 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:29.924546 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m03:42:29.927392 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_silver"
[0m03:42:29.928974 [debug] [ThreadPool]: On create_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "create_ecommerce_db_analytics_silver"} */
create schema if not exists "analytics_silver"
[0m03:42:29.935461 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m03:42:29.937667 [debug] [ThreadPool]: On create_ecommerce_db_analytics_silver: COMMIT
[0m03:42:29.941530 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_silver"
[0m03:42:29.942891 [debug] [ThreadPool]: On create_ecommerce_db_analytics_silver: COMMIT
[0m03:42:29.952591 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m03:42:29.955417 [debug] [ThreadPool]: On create_ecommerce_db_analytics_silver: Close
[0m03:42:29.956839 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_ecommerce_db_analytics_silver, now create_ecommerce_db_analytics_gold)
[0m03:42:29.962394 [debug] [ThreadPool]: Creating schema "database: "ecommerce_db"
schema: "analytics_gold"
"
[0m03:42:29.967447 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_gold"
[0m03:42:29.968850 [debug] [ThreadPool]: On create_ecommerce_db_analytics_gold: BEGIN
[0m03:42:29.969834 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:29.981079 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m03:42:29.983743 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_gold"
[0m03:42:29.990533 [debug] [ThreadPool]: On create_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "create_ecommerce_db_analytics_gold"} */
create schema if not exists "analytics_gold"
[0m03:42:29.992764 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m03:42:29.999312 [debug] [ThreadPool]: On create_ecommerce_db_analytics_gold: COMMIT
[0m03:42:30.001653 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_gold"
[0m03:42:30.003690 [debug] [ThreadPool]: On create_ecommerce_db_analytics_gold: COMMIT
[0m03:42:30.007344 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m03:42:30.017826 [debug] [ThreadPool]: On create_ecommerce_db_analytics_gold: Close
[0m03:42:30.027521 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_ecommerce_db_analytics_gold, now create_ecommerce_db_analytics_bronze)
[0m03:42:30.032444 [debug] [ThreadPool]: Creating schema "database: "ecommerce_db"
schema: "analytics_bronze"
"
[0m03:42:30.039935 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_bronze"
[0m03:42:30.045598 [debug] [ThreadPool]: On create_ecommerce_db_analytics_bronze: BEGIN
[0m03:42:30.047569 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:30.067176 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m03:42:30.068234 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_bronze"
[0m03:42:30.070617 [debug] [ThreadPool]: On create_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "create_ecommerce_db_analytics_bronze"} */
create schema if not exists "analytics_bronze"
[0m03:42:30.072299 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m03:42:30.075231 [debug] [ThreadPool]: On create_ecommerce_db_analytics_bronze: COMMIT
[0m03:42:30.076949 [debug] [ThreadPool]: Using postgres connection "create_ecommerce_db_analytics_bronze"
[0m03:42:30.079887 [debug] [ThreadPool]: On create_ecommerce_db_analytics_bronze: COMMIT
[0m03:42:30.083592 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m03:42:30.085908 [debug] [ThreadPool]: On create_ecommerce_db_analytics_bronze: Close
[0m03:42:30.092182 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics_silver)
[0m03:42:30.102749 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m03:42:30.104770 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m03:42:30.107865 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:30.128823 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m03:42:30.129948 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m03:42:30.132352 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m03:42:30.143674 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m03:42:30.148682 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m03:42:30.150906 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m03:42:30.155765 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics)
[0m03:42:30.159945 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m03:42:30.163291 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m03:42:30.165075 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:30.181208 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m03:42:30.185026 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m03:42:30.186233 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m03:42:30.193048 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m03:42:30.198405 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m03:42:30.200146 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m03:42:30.203138 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_gold)
[0m03:42:30.208404 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m03:42:30.210446 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m03:42:30.212506 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:30.225535 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m03:42:30.226411 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m03:42:30.227278 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m03:42:30.235698 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m03:42:30.241137 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m03:42:30.244923 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m03:42:30.247516 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now list_ecommerce_db_analytics_bronze)
[0m03:42:30.251093 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m03:42:30.252889 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m03:42:30.255532 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:42:30.273858 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m03:42:30.290661 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m03:42:30.293960 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m03:42:30.317764 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m03:42:30.334569 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m03:42:30.338927 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m03:42:30.351151 [debug] [MainThread]: Using postgres connection "master"
[0m03:42:30.352635 [debug] [MainThread]: On master: BEGIN
[0m03:42:30.356979 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:42:30.367901 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:42:30.371888 [debug] [MainThread]: Using postgres connection "master"
[0m03:42:30.376809 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:42:30.384429 [debug] [MainThread]: SQL status: SELECT 0 in 0.005 seconds
[0m03:42:30.387000 [debug] [MainThread]: On master: ROLLBACK
[0m03:42:30.391550 [debug] [MainThread]: Using postgres connection "master"
[0m03:42:30.393279 [debug] [MainThread]: On master: BEGIN
[0m03:42:30.395304 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:42:30.400268 [debug] [MainThread]: On master: COMMIT
[0m03:42:30.401881 [debug] [MainThread]: Using postgres connection "master"
[0m03:42:30.406778 [debug] [MainThread]: On master: COMMIT
[0m03:42:30.411582 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:42:30.414968 [debug] [MainThread]: On master: Close
[0m03:42:30.422963 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m03:42:30.427658 [info ] [MainThread]: 
[0m03:42:30.435404 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m03:42:30.442726 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m03:42:30.455811 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now model.ecommerce_dbt.brz_raw_orders)
[0m03:42:30.470726 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m03:42:30.506207 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m03:42:30.759981 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m03:42:30.821802 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m03:42:30.984738 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m03:42:30.989263 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m03:42:30.990963 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:42:31.008848 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m03:42:31.012473 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m03:42:31.032378 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    -- BRONZE LAYER: Raw Orders
-- 1:1 copy from source with metadata columns
-- No transformations, preserving original data



select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m03:42:31.054974 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.010 seconds
[0m03:42:31.078793 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m03:42:31.084551 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m03:42:31.088659 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m03:42:31.118854 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m03:42:31.121936 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m03:42:31.124020 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m03:42:31.130745 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m03:42:31.148466 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m03:42:31.159988 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m03:42:31.164315 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m03:42:31.168964 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m03:42:31.174873 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m03:42:31.181995 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.72s]
[0m03:42:31.199666 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m03:42:31.215188 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m03:42:31.228433 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m03:42:31.246715 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m03:42:31.259991 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m03:42:31.277443 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m03:42:31.369129 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m03:42:31.419951 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m03:42:31.672152 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m03:42:31.685657 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m03:42:31.691741 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:42:31.709343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m03:42:31.712672 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m03:42:31.717074 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m03:42:31.738952 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.019 seconds
[0m03:42:31.747748 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m03:42:31.751964 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m03:42:31.782454 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:42:31.818322 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m03:42:31.837983 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m03:42:31.877205 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m03:42:31.904762 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m03:42:31.931194 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m03:42:31.958715 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m03:42:31.963500 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m03:42:31.971166 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m03:42:31.974839 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m03:42:31.977372 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 268[0m in 0.73s]
[0m03:42:32.004350 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m03:42:32.018568 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m03:42:32.032840 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m03:42:32.044596 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m03:42:32.047194 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m03:42:32.060515 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m03:42:32.127227 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m03:42:32.139064 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m03:42:32.275157 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m03:42:32.290817 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m03:42:32.296078 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:42:32.314465 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m03:42:32.317083 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m03:42:32.320328 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m03:42:32.337084 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.015 seconds
[0m03:42:32.343504 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m03:42:32.345594 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m03:42:32.351495 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:42:32.357877 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m03:42:32.359500 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m03:42:32.364585 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m03:42:32.369620 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m03:42:32.378138 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m03:42:32.387600 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m03:42:32.393146 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m03:42:32.402491 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:42:32.410204 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m03:42:32.416070 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.37s]
[0m03:42:32.421210 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m03:42:32.427044 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m03:42:32.428255 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m03:42:32.433665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m03:42:32.439682 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m03:42:32.446662 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m03:42:32.599945 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m03:42:32.608241 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m03:42:32.672701 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m03:42:32.676886 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m03:42:32.684313 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:42:32.695558 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m03:42:32.696803 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m03:42:32.698303 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast(shopee_discount as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast(shipping_fee_estimated as numeric), 0) as shipping_fee_estimated,
        coalesce(cast(shipping_fee_paid as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast(shopee_discount as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m03:42:32.702704 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "product_weight" does not exist
LINE 46:         coalesce(cast(product_weight as numeric), 0) as prod...
                               ^

[0m03:42:32.704663 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: ROLLBACK
[0m03:42:32.706972 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m03:42:32.719217 [debug] [Thread-1 (]: Database Error in model slv_orders (models/silver/slv_orders.sql)
  column "product_weight" does not exist
  LINE 46:         coalesce(cast(product_weight as numeric), 0) as prod...
                                 ^
  compiled code at target/run/ecommerce_dbt/models/silver/slv_orders.sql
[0m03:42:32.721748 [error] [Thread-1 (]: 4 of 14 ERROR creating sql table model analytics_silver.slv_orders ............. [[31mERROR[0m in 0.29s]
[0m03:42:32.727847 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m03:42:32.730696 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m03:42:32.732681 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m03:42:32.734071 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m03:42:32.735524 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m03:42:32.745025 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m03:42:32.789982 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m03:42:32.804980 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m03:42:32.852915 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m03:42:32.858813 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m03:42:32.864945 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:42:32.884439 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m03:42:32.886855 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m03:42:32.888458 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders
unique_products as (
    select distinct
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        product_weight,
        original_price,
        discount_price,
        _source_system
    from source
    where product_name is not null
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m03:42:32.890558 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "product_weight" does not exist
LINE 28:         product_weight,
                 ^

[0m03:42:32.891644 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: ROLLBACK
[0m03:42:32.893069 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m03:42:32.897527 [debug] [Thread-1 (]: Database Error in model slv_products (models/silver/slv_products.sql)
  column "product_weight" does not exist
  LINE 28:         product_weight,
                   ^
  compiled code at target/run/ecommerce_dbt/models/silver/slv_products.sql
[0m03:42:32.899061 [error] [Thread-1 (]: 5 of 14 ERROR creating sql table model analytics_silver.slv_products ........... [[31mERROR[0m in 0.16s]
[0m03:42:32.901290 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m03:42:32.903604 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m03:42:32.904807 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m03:42:32.905864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m03:42:32.908886 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m03:42:32.917650 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m03:42:33.031902 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m03:42:33.037555 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m03:42:33.225604 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m03:42:33.226696 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m03:42:33.228440 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:42:33.242914 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m03:42:33.247068 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m03:42:33.251363 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m03:42:33.263417 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.009 seconds
[0m03:42:33.268661 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m03:42:33.271027 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m03:42:33.273823 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:42:33.277675 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m03:42:33.279210 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m03:42:33.280488 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m03:42:33.284244 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m03:42:33.289491 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m03:42:33.293234 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m03:42:33.294527 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m03:42:33.296532 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:42:33.301716 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m03:42:33.305037 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.40s]
[0m03:42:33.309329 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m03:42:33.311456 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m03:42:33.313345 [info ] [Thread-1 (]: 7 of 14 SKIP relation analytics_gold.dim_customer .............................. [[33mSKIP[0m]
[0m03:42:33.315587 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m03:42:33.316577 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m03:42:33.317394 [info ] [Thread-1 (]: 8 of 14 SKIP relation analytics_gold.dim_payment ............................... [[33mSKIP[0m]
[0m03:42:33.322670 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m03:42:33.325168 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m03:42:33.330980 [info ] [Thread-1 (]: 9 of 14 SKIP relation analytics_gold.dim_shipping .............................. [[33mSKIP[0m]
[0m03:42:33.337821 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m03:42:33.343367 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m03:42:33.350883 [info ] [Thread-1 (]: 10 of 14 SKIP relation analytics_gold.dim_product .............................. [[33mSKIP[0m]
[0m03:42:33.355897 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m03:42:33.359325 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m03:42:33.361400 [info ] [Thread-1 (]: 11 of 14 SKIP relation analytics_gold.fct_orders ............................... [[33mSKIP[0m]
[0m03:42:33.363346 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m03:42:33.367234 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m03:42:33.370262 [info ] [Thread-1 (]: 12 of 14 SKIP relation analytics_gold.agg_customer_summary ..................... [[33mSKIP[0m]
[0m03:42:33.373268 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m03:42:33.376085 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m03:42:33.378138 [info ] [Thread-1 (]: 13 of 14 SKIP relation analytics_gold.agg_daily_sales .......................... [[33mSKIP[0m]
[0m03:42:33.379963 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m03:42:33.382918 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m03:42:33.384298 [info ] [Thread-1 (]: 14 of 14 SKIP relation analytics_gold.agg_product_performance .................. [[33mSKIP[0m]
[0m03:42:33.386881 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m03:42:33.391272 [debug] [MainThread]: Using postgres connection "master"
[0m03:42:33.392331 [debug] [MainThread]: On master: BEGIN
[0m03:42:33.393200 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:42:33.406709 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m03:42:33.408791 [debug] [MainThread]: On master: COMMIT
[0m03:42:33.413986 [debug] [MainThread]: Using postgres connection "master"
[0m03:42:33.415330 [debug] [MainThread]: On master: COMMIT
[0m03:42:33.421274 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:42:33.422974 [debug] [MainThread]: On master: Close
[0m03:42:33.428178 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:42:33.436735 [debug] [MainThread]: Connection 'model.ecommerce_dbt.dim_date' was properly closed.
[0m03:42:33.443064 [info ] [MainThread]: 
[0m03:42:33.449750 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 3.85 seconds (3.85s).
[0m03:42:33.456973 [debug] [MainThread]: Command end result
[0m03:42:34.369757 [info ] [MainThread]: 
[0m03:42:34.372191 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m03:42:34.377760 [info ] [MainThread]: 
[0m03:42:34.385061 [error] [MainThread]:   Database Error in model slv_orders (models/silver/slv_orders.sql)
  column "product_weight" does not exist
  LINE 46:         coalesce(cast(product_weight as numeric), 0) as prod...
                                 ^
  compiled code at target/run/ecommerce_dbt/models/silver/slv_orders.sql
[0m03:42:34.387559 [info ] [MainThread]: 
[0m03:42:34.393645 [error] [MainThread]:   Database Error in model slv_products (models/silver/slv_products.sql)
  column "product_weight" does not exist
  LINE 28:         product_weight,
                   ^
  compiled code at target/run/ecommerce_dbt/models/silver/slv_products.sql
[0m03:42:34.399875 [info ] [MainThread]: 
[0m03:42:34.403709 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=2 SKIP=8 TOTAL=14
[0m03:42:34.409345 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 10.272007, "process_user_time": 6.701217, "process_kernel_time": 0.509918, "process_mem_max_rss": "127348", "process_in_blocks": "1872", "command_success": false, "process_out_blocks": "0"}
[0m03:42:34.414186 [debug] [MainThread]: Command `dbt run` failed at 03:42:34.413610 after 10.28 seconds
[0m03:42:34.416598 [debug] [MainThread]: Flushing usage events
[0m04:06:44.437235 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 04:06:44.458329 | 42756f72-3624-4b35-9c09-be4e94cd1309 ==============================
[0m04:06:44.458329 [info ] [MainThread]: Running with dbt=1.8.0
[0m04:06:44.460951 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:06:45.000149 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m04:06:45.026662 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m04:06:45.171957 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m04:06:45.173496 [debug] [MainThread]: previous checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, current checksum: 2a6c64e758918535ccc035b9d143fb4c91b01df5f630e583361ba23a87d2a511
[0m04:06:47.688168 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m04:06:48.261109 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.marts
- models.ecommerce_dbt.staging
[0m04:06:48.517078 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m04:06:48.521550 [info ] [MainThread]: 
[0m04:06:48.523739 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:06:48.531388 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m04:06:48.608471 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:06:48.609430 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:06:48.610260 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:48.628413 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.018 seconds
[0m04:06:48.630516 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:06:48.633398 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:06:48.634340 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:06:48.635075 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:06:48.645121 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.010 seconds
[0m04:06:48.647083 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:06:48.650009 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:06:48.651110 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:06:48.651908 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:06:48.662191 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.010 seconds
[0m04:06:48.664204 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:06:48.667630 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics_bronze)
[0m04:06:48.676632 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:06:48.677907 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m04:06:48.678953 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:06:48.689671 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m04:06:48.690928 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:06:48.692025 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m04:06:48.698948 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m04:06:48.701133 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m04:06:48.702507 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m04:06:48.703895 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics_silver)
[0m04:06:48.706685 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:06:48.707704 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m04:06:48.708463 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:06:48.716935 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m04:06:48.718028 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:06:48.718898 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m04:06:48.722383 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m04:06:48.724250 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m04:06:48.725388 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m04:06:48.726535 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics)
[0m04:06:48.729160 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:06:48.730076 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m04:06:48.730883 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:06:48.739656 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m04:06:48.740916 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:06:48.741992 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m04:06:48.745931 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m04:06:48.747918 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m04:06:48.749431 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m04:06:48.750978 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_gold)
[0m04:06:48.754323 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:06:48.755397 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m04:06:48.756587 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:06:48.769018 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m04:06:48.770768 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:06:48.771828 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m04:06:48.777715 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m04:06:48.780851 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m04:06:48.783353 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m04:06:48.790768 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:48.793162 [debug] [MainThread]: On master: BEGIN
[0m04:06:48.795159 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:06:48.810261 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m04:06:48.812299 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:48.814819 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:06:48.842171 [debug] [MainThread]: SQL status: SELECT 1 in 0.026 seconds
[0m04:06:48.846880 [debug] [MainThread]: On master: ROLLBACK
[0m04:06:48.848009 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:48.848837 [debug] [MainThread]: On master: BEGIN
[0m04:06:48.850195 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m04:06:48.851023 [debug] [MainThread]: On master: COMMIT
[0m04:06:48.851718 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:48.852433 [debug] [MainThread]: On master: COMMIT
[0m04:06:48.854036 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:06:48.855371 [debug] [MainThread]: On master: Close
[0m04:06:48.856872 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:06:48.857764 [info ] [MainThread]: 
[0m04:06:48.863234 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m04:06:48.864569 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m04:06:48.865627 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now model.ecommerce_dbt.brz_raw_orders)
[0m04:06:48.866545 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m04:06:48.875520 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:48.903432 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m04:06:48.962790 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:48.989117 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:48.990398 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m04:06:48.991180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:06:49.000159 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m04:06:49.001510 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:49.002549 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    -- BRONZE LAYER: Raw Orders
-- 1:1 copy from source with metadata columns
-- No transformations, preserving original data



select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m04:06:49.031033 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.027 seconds
[0m04:06:49.040715 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:49.041763 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m04:06:49.044336 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:06:49.051555 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:49.053291 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m04:06:49.056611 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m04:06:49.074221 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:06:49.075536 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:49.076728 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:06:49.082488 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m04:06:49.093043 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m04:06:49.100301 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:06:49.101279 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m04:06:49.114919 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.013 seconds
[0m04:06:49.121518 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m04:06:49.127536 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.26s]
[0m04:06:49.130550 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m04:06:49.133391 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m04:06:49.134351 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m04:06:49.135282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m04:06:49.137136 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m04:06:49.143932 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m04:06:49.174544 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m04:06:49.206498 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m04:06:49.240250 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:06:49.241825 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m04:06:49.242965 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:06:49.253427 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m04:06:49.254713 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:06:49.255942 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m04:06:49.284789 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.027 seconds
[0m04:06:49.291110 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:06:49.295983 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m04:06:49.308659 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m04:06:49.316446 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:06:49.318110 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m04:06:49.322282 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:06:49.331750 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:06:49.333702 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:06:49.336015 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:06:49.340563 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:06:49.344861 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m04:06:49.349406 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:06:49.350719 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m04:06:49.357434 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m04:06:49.359648 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m04:06:49.361343 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 268[0m in 0.23s]
[0m04:06:49.362647 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m04:06:49.364044 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m04:06:49.365522 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m04:06:49.366755 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m04:06:49.367990 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m04:06:49.372513 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m04:06:49.398841 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m04:06:49.402918 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m04:06:49.419237 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:06:49.420468 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m04:06:49.421506 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:06:49.430537 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m04:06:49.431617 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:06:49.432856 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m04:06:49.460609 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.026 seconds
[0m04:06:49.467268 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:06:49.470378 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m04:06:49.472892 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:06:49.480368 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:06:49.482441 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m04:06:49.484016 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:06:49.486952 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:06:49.487978 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:06:49.489283 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:06:49.492342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:06:49.495502 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m04:06:49.497050 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:06:49.498254 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m04:06:49.503049 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:06:49.505437 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m04:06:49.506734 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.14s]
[0m04:06:49.507782 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m04:06:49.508805 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m04:06:49.509744 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m04:06:49.510763 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m04:06:49.511583 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m04:06:49.519075 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m04:06:49.538612 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m04:06:49.544881 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m04:06:49.572362 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:06:49.573472 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m04:06:49.574561 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:06:49.583158 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m04:06:49.584434 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:06:49.585592 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast(shopee_discount as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m04:06:49.591075 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "shopee_discount" does not exist
LINE 102:         coalesce(cast(shopee_discount as numeric), 0) + 
                                ^

[0m04:06:49.592243 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: ROLLBACK
[0m04:06:49.593491 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m04:06:49.604216 [debug] [Thread-1 (]: Database Error in model slv_orders (models/silver/slv_orders.sql)
  column "shopee_discount" does not exist
  LINE 102:         coalesce(cast(shopee_discount as numeric), 0) + 
                                  ^
  compiled code at target/run/ecommerce_dbt/models/silver/slv_orders.sql
[0m04:06:49.605919 [error] [Thread-1 (]: 4 of 14 ERROR creating sql table model analytics_silver.slv_orders ............. [[31mERROR[0m in 0.09s]
[0m04:06:49.608560 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m04:06:49.610843 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m04:06:49.613219 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m04:06:49.615495 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m04:06:49.616767 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m04:06:49.623405 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m04:06:49.661942 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m04:06:49.666575 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m04:06:49.712648 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:06:49.713575 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m04:06:49.715542 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:06:49.723925 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m04:06:49.724831 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:06:49.725873 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders
unique_products as (
    select distinct
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m04:06:49.745201 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.018 seconds
[0m04:06:49.749436 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:06:49.750705 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m04:06:49.754174 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:06:49.758293 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:06:49.760255 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:06:49.762595 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:06:49.768621 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:06:49.774779 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m04:06:49.778093 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:06:49.780523 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m04:06:49.784284 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m04:06:49.789620 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m04:06:49.792368 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 236[0m in 0.18s]
[0m04:06:49.793735 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m04:06:49.794723 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m04:06:49.795881 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m04:06:49.797538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m04:06:49.798779 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m04:06:49.803659 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m04:06:49.828631 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m04:06:49.833585 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m04:06:49.883970 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:06:49.885273 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m04:06:49.886850 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:06:49.899990 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:06:49.901363 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:06:49.902687 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m04:06:49.914999 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.011 seconds
[0m04:06:49.919670 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:06:49.923861 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m04:06:49.927821 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:06:49.933151 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:06:49.937753 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m04:06:49.944849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:06:49.957440 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:06:49.967992 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:06:49.973645 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:06:49.980223 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:06:49.989878 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m04:06:49.993391 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:06:49.997784 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m04:06:50.007895 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m04:06:50.010797 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m04:06:50.012444 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.21s]
[0m04:06:50.017046 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m04:06:50.018825 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m04:06:50.023105 [info ] [Thread-1 (]: 7 of 14 SKIP relation analytics_gold.dim_customer .............................. [[33mSKIP[0m]
[0m04:06:50.028833 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m04:06:50.032639 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m04:06:50.034377 [info ] [Thread-1 (]: 8 of 14 SKIP relation analytics_gold.dim_payment ............................... [[33mSKIP[0m]
[0m04:06:50.036855 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m04:06:50.038086 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m04:06:50.039530 [info ] [Thread-1 (]: 9 of 14 SKIP relation analytics_gold.dim_shipping .............................. [[33mSKIP[0m]
[0m04:06:50.043534 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m04:06:50.045063 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m04:06:50.046086 [info ] [Thread-1 (]: 10 of 14 SKIP relation analytics_gold.dim_product .............................. [[33mSKIP[0m]
[0m04:06:50.047468 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m04:06:50.050440 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m04:06:50.052037 [info ] [Thread-1 (]: 11 of 14 SKIP relation analytics_gold.fct_orders ............................... [[33mSKIP[0m]
[0m04:06:50.053664 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m04:06:50.056071 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m04:06:50.058007 [info ] [Thread-1 (]: 12 of 14 SKIP relation analytics_gold.agg_customer_summary ..................... [[33mSKIP[0m]
[0m04:06:50.059356 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m04:06:50.061016 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m04:06:50.062427 [info ] [Thread-1 (]: 13 of 14 SKIP relation analytics_gold.agg_daily_sales .......................... [[33mSKIP[0m]
[0m04:06:50.063751 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m04:06:50.065517 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m04:06:50.067472 [info ] [Thread-1 (]: 14 of 14 SKIP relation analytics_gold.agg_product_performance .................. [[33mSKIP[0m]
[0m04:06:50.069939 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m04:06:50.073836 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:50.075218 [debug] [MainThread]: On master: BEGIN
[0m04:06:50.076743 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:06:50.089124 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m04:06:50.090203 [debug] [MainThread]: On master: COMMIT
[0m04:06:50.091645 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:50.092740 [debug] [MainThread]: On master: COMMIT
[0m04:06:50.094608 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:06:50.095765 [debug] [MainThread]: On master: Close
[0m04:06:50.097384 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:06:50.098498 [debug] [MainThread]: Connection 'model.ecommerce_dbt.dim_date' was properly closed.
[0m04:06:50.099708 [info ] [MainThread]: 
[0m04:06:50.101479 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 1.58 seconds (1.58s).
[0m04:06:50.107068 [debug] [MainThread]: Command end result
[0m04:06:50.232418 [info ] [MainThread]: 
[0m04:06:50.233558 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:06:50.234704 [info ] [MainThread]: 
[0m04:06:50.235856 [error] [MainThread]:   Database Error in model slv_orders (models/silver/slv_orders.sql)
  column "shopee_discount" does not exist
  LINE 102:         coalesce(cast(shopee_discount as numeric), 0) + 
                                  ^
  compiled code at target/run/ecommerce_dbt/models/silver/slv_orders.sql
[0m04:06:50.237252 [info ] [MainThread]: 
[0m04:06:50.238626 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=8 TOTAL=14
[0m04:06:50.240728 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 5.9962926, "process_user_time": 4.884772, "process_kernel_time": 0.964099, "process_mem_max_rss": "127060", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:06:50.241995 [debug] [MainThread]: Command `dbt run` failed at 04:06:50.241759 after 6.00 seconds
[0m04:06:50.242864 [debug] [MainThread]: Flushing usage events
[0m04:07:15.732125 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 04:07:15.744501 | c8dd79ec-e05c-4943-9ad7-55b080e7a57b ==============================
[0m04:07:15.744501 [info ] [MainThread]: Running with dbt=1.8.0
[0m04:07:15.749915 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'profiles_dir': '/opt/airflow/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:07:16.086083 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m04:07:16.125284 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m04:07:18.000284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:07:18.003152 [debug] [MainThread]: Partial parsing: updated file: ecommerce_dbt://models/silver/slv_orders.sql
[0m04:07:18.254483 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m04:07:18.483605 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.staging
- models.ecommerce_dbt.marts
[0m04:07:18.714079 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m04:07:18.718770 [info ] [MainThread]: 
[0m04:07:18.720844 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:07:18.730553 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m04:07:18.777932 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:07:18.779345 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:07:18.780642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:07:18.794046 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.013 seconds
[0m04:07:18.796167 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:07:18.799259 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:07:18.800454 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:07:18.801491 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:18.811212 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.010 seconds
[0m04:07:18.813280 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:07:18.816449 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:07:18.817910 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:07:18.819064 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:18.827178 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.008 seconds
[0m04:07:18.829216 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:07:18.832114 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics)
[0m04:07:18.840509 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:07:18.841555 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m04:07:18.842176 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:18.851973 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m04:07:18.853238 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:07:18.854624 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m04:07:18.859741 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m04:07:18.861513 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m04:07:18.862969 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m04:07:18.864923 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_silver)
[0m04:07:18.868189 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:07:18.869173 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m04:07:18.869919 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:18.880836 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m04:07:18.882279 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:07:18.883541 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m04:07:18.889042 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m04:07:18.892932 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m04:07:18.895865 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m04:07:18.897780 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics_gold)
[0m04:07:18.903983 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:07:18.905580 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m04:07:18.907567 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:18.922051 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m04:07:18.923910 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:07:18.925437 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m04:07:18.931013 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m04:07:18.934983 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m04:07:18.937260 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m04:07:18.939652 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now list_ecommerce_db_analytics_bronze)
[0m04:07:18.945482 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:07:18.947571 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m04:07:18.949650 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:18.970434 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m04:07:18.972549 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:07:18.974809 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m04:07:18.984464 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.007 seconds
[0m04:07:18.989077 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m04:07:18.991938 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m04:07:19.000234 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:19.002196 [debug] [MainThread]: On master: BEGIN
[0m04:07:19.003515 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:07:19.019288 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m04:07:19.021037 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:19.021953 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:07:19.035451 [debug] [MainThread]: SQL status: SELECT 1 in 0.012 seconds
[0m04:07:19.040831 [debug] [MainThread]: On master: ROLLBACK
[0m04:07:19.044038 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:19.046210 [debug] [MainThread]: On master: BEGIN
[0m04:07:19.049811 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:07:19.051610 [debug] [MainThread]: On master: COMMIT
[0m04:07:19.052856 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:19.053921 [debug] [MainThread]: On master: COMMIT
[0m04:07:19.056434 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m04:07:19.058446 [debug] [MainThread]: On master: Close
[0m04:07:19.061095 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:07:19.063373 [info ] [MainThread]: 
[0m04:07:19.071356 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m04:07:19.073648 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m04:07:19.075878 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now model.ecommerce_dbt.brz_raw_orders)
[0m04:07:19.077455 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m04:07:19.098937 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.138489 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m04:07:19.268166 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.312990 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.314129 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m04:07:19.315134 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:19.328486 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:07:19.330729 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.333116 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    -- BRONZE LAYER: Raw Orders
-- 1:1 copy from source with metadata columns
-- No transformations, preserving original data



select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m04:07:19.349590 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.014 seconds
[0m04:07:19.369827 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.372583 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m04:07:19.375919 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:19.381456 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.383152 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m04:07:19.386667 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m04:07:19.408590 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:07:19.409956 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.411326 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:07:19.415354 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:07:19.422473 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m04:07:19.430024 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:19.431647 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m04:07:19.436300 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.003 seconds
[0m04:07:19.439839 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m04:07:19.444887 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.37s]
[0m04:07:19.447253 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m04:07:19.451603 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m04:07:19.453484 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m04:07:19.455981 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m04:07:19.457480 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m04:07:19.463998 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m04:07:19.500710 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m04:07:19.539082 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m04:07:19.572577 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:19.573451 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m04:07:19.575102 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:19.585004 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m04:07:19.587538 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:19.590117 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m04:07:19.615165 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.022 seconds
[0m04:07:19.621446 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:19.623032 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m04:07:19.625333 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:19.632014 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:19.633522 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m04:07:19.636446 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:19.649659 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:07:19.652002 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:19.654252 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:07:19.659968 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m04:07:19.670898 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m04:07:19.680502 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:19.682221 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m04:07:19.690572 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m04:07:19.695753 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m04:07:19.699810 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 268[0m in 0.24s]
[0m04:07:19.703613 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m04:07:19.707157 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m04:07:19.710946 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m04:07:19.713860 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m04:07:19.716155 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m04:07:19.729893 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m04:07:19.797432 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m04:07:19.806495 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m04:07:19.835341 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:19.836739 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m04:07:19.837706 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:19.850635 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:07:19.854760 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:19.856650 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m04:07:19.878686 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.019 seconds
[0m04:07:19.883385 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:19.885100 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m04:07:19.887609 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:19.894479 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:19.895810 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m04:07:19.897504 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:19.899946 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:07:19.901114 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:19.902198 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:07:19.905150 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:19.908043 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m04:07:19.909403 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:19.910494 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m04:07:19.913799 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:07:19.915965 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m04:07:19.917281 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.20s]
[0m04:07:19.918377 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m04:07:19.919344 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m04:07:19.920350 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m04:07:19.921328 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m04:07:19.922047 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m04:07:19.926705 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m04:07:19.944718 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m04:07:19.949646 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m04:07:19.968064 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:19.969884 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m04:07:19.971273 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:19.983068 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:07:19.984755 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:19.986528 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m04:07:20.021581 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.033 seconds
[0m04:07:20.025758 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:20.026704 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp" rename to "slv_orders"
[0m04:07:20.028465 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:20.030965 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:07:20.031787 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:20.032900 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:07:20.038891 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m04:07:20.041991 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup"
[0m04:07:20.043231 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:20.044245 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup" cascade
[0m04:07:20.046246 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m04:07:20.048611 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m04:07:20.050040 [info ] [Thread-1 (]: 4 of 14 OK created sql table model analytics_silver.slv_orders ................. [[32mSELECT 516[0m in 0.13s]
[0m04:07:20.051726 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m04:07:20.053301 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m04:07:20.055199 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m04:07:20.056687 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m04:07:20.057778 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m04:07:20.062058 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m04:07:20.077986 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m04:07:20.086797 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m04:07:20.102905 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:20.103920 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m04:07:20.104888 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:20.113911 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m04:07:20.115098 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:20.116120 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders
unique_products as (
    select distinct
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m04:07:20.129073 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.012 seconds
[0m04:07:20.135136 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:20.136377 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products" rename to "slv_products__dbt_backup"
[0m04:07:20.137792 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:20.142088 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:20.143187 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m04:07:20.144710 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:20.147633 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:07:20.148420 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:20.149365 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:07:20.152056 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:20.155149 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m04:07:20.156763 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:20.157583 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m04:07:20.162171 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m04:07:20.164928 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m04:07:20.166330 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 236[0m in 0.11s]
[0m04:07:20.167346 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m04:07:20.168235 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m04:07:20.169461 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m04:07:20.171485 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m04:07:20.172847 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m04:07:20.178958 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m04:07:20.208799 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m04:07:20.214725 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m04:07:20.252362 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:20.253938 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m04:07:20.256315 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:20.277542 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m04:07:20.280202 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:20.282613 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m04:07:20.299700 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.014 seconds
[0m04:07:20.308601 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:20.311410 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m04:07:20.314735 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:20.323475 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:20.325324 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m04:07:20.328520 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:20.333637 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:07:20.334892 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:20.335928 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:07:20.339559 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:07:20.343649 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m04:07:20.345011 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:20.345776 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m04:07:20.348705 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:07:20.351043 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m04:07:20.352398 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.18s]
[0m04:07:20.353752 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m04:07:20.355470 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m04:07:20.356614 [info ] [Thread-1 (]: 7 of 14 START sql table model analytics_gold.dim_customer ...................... [RUN]
[0m04:07:20.358446 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_date, now model.ecommerce_dbt.dim_customer)
[0m04:07:20.359779 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_customer
[0m04:07:20.365106 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_customer"
[0m04:07:20.399855 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_customer
[0m04:07:20.406870 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_customer"
[0m04:07:20.447974 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:20.450930 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: BEGIN
[0m04:07:20.453884 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:20.465540 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:07:20.470690 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:20.471672 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Dimension
-- Business-ready customer data with RFM segmentation



with customers as (
    select * from "ecommerce_db"."analytics_silver"."slv_customers"
),

-- Calculate order aggregates per customer
order_stats as (
    select
        buyer_username,
        count(distinct order_id) as total_orders,
        sum(order_total_vnd) as total_spent,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by buyer_username
),

-- RFM calculation
rfm_calc as (
    select
        c.*,
        coalesce(o.total_orders, 0) as total_orders,
        coalesce(o.total_spent, 0) as total_spent,
        coalesce(o.avg_order_value, 0) as avg_order_value,
        o.first_order_date,
        o.last_order_date,
        coalesce(o.days_since_last_order, 999) as days_since_last_order,
        
        -- RFM Scores (1-5 scale)
        ntile(5) over (order by coalesce(o.days_since_last_order, 999) desc) as r_score,
        ntile(5) over (order by coalesce(o.total_orders, 0)) as f_score,
        ntile(5) over (order by coalesce(o.total_spent, 0)) as m_score
        
    from customers c
    left join order_stats o on c.buyer_username = o.buyer_username
),

final as (
    select
        customer_id,
        buyer_username,
        recipient_name,
        phone_number,
        
        -- Geography
        province,
        district,
        ward,
        shipping_address,
        country,
        region,
        
        -- Customer key
        customer_key,
        
        -- Order metrics
        total_orders,
        total_spent,
        avg_order_value,
        first_order_date,
        last_order_date,
        days_since_last_order,
        
        -- RFM Scores
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score as rfm_score,
        
        -- RFM Segment
        case
            when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
            when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
            when r_score >= 4 and f_score <= 2 then 'Recent Customers'
            when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
            when r_score <= 2 and f_score >= 4 then 'At Risk'
            when r_score <= 2 and f_score >= 2 then 'Hibernating'
            when r_score <= 2 and f_score <= 2 then 'Lost'
            else 'Other'
        end as customer_segment,
        
        -- Customer lifecycle
        case 
            when total_orders = 1 then 'New'
            when total_orders between 2 and 3 then 'Returning'
            when total_orders between 4 and 10 then 'Regular'
            when total_orders > 10 then 'VIP'
            else 'Prospect'
        end as customer_lifecycle,
        
        -- Customer value tier
        case
            when total_spent >= 5000000 then 'Platinum'
            when total_spent >= 2000000 then 'Gold'
            when total_spent >= 500000 then 'Silver'
            else 'Bronze'
        end as customer_value_tier,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from rfm_calc
)

select * from final
  );
  
[0m04:07:20.494778 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.022 seconds
[0m04:07:20.500458 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:20.503276 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m04:07:20.506179 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:20.509211 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:07:20.510641 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:20.511642 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:07:20.516360 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:07:20.521324 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup"
[0m04:07:20.522962 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:20.524134 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup" cascade
[0m04:07:20.526093 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m04:07:20.529235 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: Close
[0m04:07:20.531081 [info ] [Thread-1 (]: 7 of 14 OK created sql table model analytics_gold.dim_customer ................. [[32mSELECT 268[0m in 0.17s]
[0m04:07:20.533207 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m04:07:20.535626 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m04:07:20.538023 [info ] [Thread-1 (]: 8 of 14 START sql table model analytics_gold.dim_payment ....................... [RUN]
[0m04:07:20.539251 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_customer, now model.ecommerce_dbt.dim_payment)
[0m04:07:20.540245 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_payment
[0m04:07:20.545237 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_payment"
[0m04:07:20.572951 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_payment
[0m04:07:20.577614 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_payment"
[0m04:07:20.626953 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:20.628719 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: BEGIN
[0m04:07:20.630163 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:20.642150 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:07:20.643389 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:20.645006 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Payment Dimension
-- Extracted from orders, enriched with payment grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique payment methods
unique_payments as (
    select distinct
        payment_method
    from source
    where payment_method is not null
),

enriched as (
    select
        row_number() over (order by payment_method) as payment_method_id,
        trim(payment_method) as payment_method,
        
        -- Payment method grouping
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'COD'
            when payment_method ilike '%shopee%' or payment_method ilike '%spay%' or payment_method ilike '%shopeepay%' then 'ShopeePay'
            when payment_method ilike '%momo%' then 'MoMo'
            when payment_method ilike '%zalo%' then 'ZaloPay'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Credit/Debit Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank Transfer'
            when payment_method ilike '%vnpay%' then 'VNPay'
            else 'Other'
        end as payment_group,
        
        -- Payment type
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'Cash'
            when payment_method ilike '%shopee%' or payment_method ilike '%momo%' or payment_method ilike '%zalo%' or payment_method ilike '%vnpay%' then 'E-Wallet'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank'
            else 'Other'
        end as payment_type,
        
        -- Is digital payment
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then false
            else true
        end as is_digital_payment,
        
        -- Payment key
        md5(coalesce(payment_method, 'unknown')) as payment_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_payments
)

select * from enriched
  );
  
[0m04:07:20.654576 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.007 seconds
[0m04:07:20.658660 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:20.659965 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp" rename to "dim_payment"
[0m04:07:20.662905 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:20.666913 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:07:20.668333 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:20.670106 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:07:20.673333 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:20.676605 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup"
[0m04:07:20.679234 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:20.680589 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup" cascade
[0m04:07:20.682413 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m04:07:20.685036 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: Close
[0m04:07:20.686521 [info ] [Thread-1 (]: 8 of 14 OK created sql table model analytics_gold.dim_payment .................. [[32mSELECT 6[0m in 0.15s]
[0m04:07:20.687848 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m04:07:20.689013 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m04:07:20.690627 [info ] [Thread-1 (]: 9 of 14 START sql table model analytics_gold.dim_shipping ...................... [RUN]
[0m04:07:20.691973 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_payment, now model.ecommerce_dbt.dim_shipping)
[0m04:07:20.693543 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_shipping
[0m04:07:20.698457 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_shipping"
[0m04:07:20.732646 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_shipping
[0m04:07:20.737870 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_shipping"
[0m04:07:20.770276 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:20.771352 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: BEGIN
[0m04:07:20.772232 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:20.780736 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m04:07:20.784225 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:20.787109 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Shipping Dimension
-- Extracted from orders, enriched with carrier grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique shipping carriers
unique_carriers as (
    select distinct
        shipping_carrier,
        shipping_method
    from source
    where shipping_carrier is not null
),

enriched as (
    select
        row_number() over (order by shipping_carrier) as shipping_id,
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        
        -- Carrier grouping/normalization
        case
            when shipping_carrier ilike '%giao hang nhanh%' or shipping_carrier ilike '%ghn%' then 'GHN'
            when shipping_carrier ilike '%giao hang tiet kiem%' or shipping_carrier ilike '%ghtk%' then 'GHTK'
            when shipping_carrier ilike '%j&t%' or shipping_carrier ilike '%jt%' then 'J&T Express'
            when shipping_carrier ilike '%shopee express%' or shipping_carrier ilike '%spx%' then 'Shopee Express'
            when shipping_carrier ilike '%viettel%' then 'Viettel Post'
            when shipping_carrier ilike '%grab%' then 'GrabExpress'
            when shipping_carrier ilike '%ninja van%' then 'Ninja Van'
            when shipping_carrier ilike '%best%' then 'BEST Express'
            else 'Other'
        end as carrier_group,
        
        -- Carrier type
        case
            when shipping_carrier ilike '%shopee%' or shipping_carrier ilike '%spx%' then 'Platform Logistics'
            when shipping_carrier ilike '%grab%' then 'On-Demand'
            else 'Third Party Logistics'
        end as carrier_type,
        
        -- Shipping key
        md5(coalesce(shipping_carrier, 'unknown')) as shipping_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_carriers
)

select * from enriched
  );
  
[0m04:07:20.795763 [debug] [Thread-1 (]: SQL status: SELECT 9 in 0.006 seconds
[0m04:07:20.802242 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:20.803464 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp" rename to "dim_shipping"
[0m04:07:20.804759 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:20.806989 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:07:20.808573 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:20.809410 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:07:20.812179 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:20.818086 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup"
[0m04:07:20.819554 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:20.820627 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup" cascade
[0m04:07:20.822596 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m04:07:20.825516 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: Close
[0m04:07:20.827254 [info ] [Thread-1 (]: 9 of 14 OK created sql table model analytics_gold.dim_shipping ................. [[32mSELECT 9[0m in 0.14s]
[0m04:07:20.828724 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m04:07:20.830193 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m04:07:20.831226 [info ] [Thread-1 (]: 10 of 14 START sql table model analytics_gold.dim_product ...................... [RUN]
[0m04:07:20.832839 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_shipping, now model.ecommerce_dbt.dim_product)
[0m04:07:20.833973 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_product
[0m04:07:20.840187 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_product"
[0m04:07:20.869462 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_product
[0m04:07:20.874971 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_product"
[0m04:07:20.904737 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:20.905930 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: BEGIN
[0m04:07:20.908976 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:20.921731 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:07:20.923250 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:20.925111 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Dimension
-- Business-ready product data with performance metrics



with products as (
    select * from "ecommerce_db"."analytics_silver"."slv_products"
),

-- Calculate product performance
product_stats as (
    select
        product_name,
        count(distinct order_id) as total_orders,
        sum(quantity) as total_quantity_sold,
        sum(order_total_vnd) as total_revenue,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by product_name
),

final as (
    select
        p.product_id,
        p.product_name,
        p.product_sku,
        p.variant_name,
        p.variant_sku,
        p.main_category,
        
        -- Pricing
        p.original_price,
        p.discounted_price,
        case 
            when p.original_price > 0 
            then round((1 - p.discounted_price / p.original_price) * 100, 2)
            else 0
        end as discount_percentage,
        
        -- Weight
        p.product_weight,
        
        -- Product key
        p.product_key,
        
        -- Performance metrics
        coalesce(s.total_orders, 0) as total_orders,
        coalesce(s.total_quantity_sold, 0) as total_quantity_sold,
        coalesce(s.total_revenue, 0) as total_revenue,
        coalesce(s.avg_order_value, 0) as avg_order_value,
        s.first_sold_date,
        s.last_sold_date,
        
        -- Product tier based on revenue
        case
            when s.total_revenue >= 10000000 then 'Star Product'
            when s.total_revenue >= 5000000 then 'High Performer'
            when s.total_revenue >= 1000000 then 'Moderate'
            when s.total_revenue > 0 then 'Low Performer'
            else 'No Sales'
        end as product_tier,
        
        -- Velocity
        case 
            when s.total_quantity_sold >= 50 then 'Fast Moving'
            when s.total_quantity_sold >= 20 then 'Medium Moving'
            when s.total_quantity_sold >= 5 then 'Slow Moving'
            else 'Very Slow'
        end as sales_velocity,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from products p
    left join product_stats s on p.product_name = s.product_name
)

select * from final
  );
  
[0m04:07:20.964865 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.038 seconds
[0m04:07:20.973169 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:20.974417 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp" rename to "dim_product"
[0m04:07:20.975723 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:20.979554 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:07:20.984054 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:20.987436 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:07:20.991007 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:20.995212 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_product__dbt_backup"
[0m04:07:20.996944 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:20.998093 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_product__dbt_backup" cascade
[0m04:07:20.999651 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m04:07:21.001878 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: Close
[0m04:07:21.003481 [info ] [Thread-1 (]: 10 of 14 OK created sql table model analytics_gold.dim_product ................. [[32mSELECT 236[0m in 0.17s]
[0m04:07:21.004789 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m04:07:21.007586 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m04:07:21.008837 [info ] [Thread-1 (]: 11 of 14 START sql table model analytics_gold.fct_orders ....................... [RUN]
[0m04:07:21.010608 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_product, now model.ecommerce_dbt.fct_orders)
[0m04:07:21.014305 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.fct_orders
[0m04:07:21.023685 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.fct_orders"
[0m04:07:21.125749 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.fct_orders
[0m04:07:21.131497 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.fct_orders"
[0m04:07:21.241573 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:07:21.245897 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: BEGIN
[0m04:07:21.247325 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:21.260847 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:07:21.261952 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:07:21.263577 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Fact Orders
-- Main fact table - Star Schema center
-- Joins all dimensions with measures



with orders as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

customers as (
    select customer_id, buyer_username, customer_key, region, customer_segment
    from "ecommerce_db"."analytics_gold"."dim_customer"
),

products as (
    select product_id, product_name, product_key, main_category, product_tier
    from "ecommerce_db"."analytics_gold"."dim_product"
),

dates as (
    select date_key, full_date as date, is_double_day_sale, sale_event_name
    from "ecommerce_db"."analytics_gold"."dim_date"
),

shipping as (
    select shipping_id, shipping_carrier, shipping_key, carrier_group
    from "ecommerce_db"."analytics_gold"."dim_shipping"
),

payment as (
    select payment_method_id, payment_method, payment_key, payment_group
    from "ecommerce_db"."analytics_gold"."dim_payment"
),

-- Customer order sequence
order_sequence as (
    select
        order_id,
        buyer_username,
        row_number() over (
            partition by buyer_username 
            order by order_date
        ) as customer_order_seq
    from orders
),

fact_orders as (
    select
        -- Primary key
        o.order_id,
        
        -- Dimension keys (foreign keys)
        c.customer_id,
        p.product_id,
        d.date_key as order_date_key,
        s.shipping_id,
        pm.payment_method_id,
        
        -- Surrogate keys (for BI tools)
        c.customer_key,
        p.product_key,
        s.shipping_key,
        pm.payment_key,
        
        -- Natural keys (for reference)
        o.package_id,
        o.tracking_number,
        
        -- Date dimensions
        o.order_date,
        o.expected_delivery_date,
        o.actual_delivery_date,
        o.order_completed_date,
        o.payment_date,
        
        -- Delivery metrics
        case
            when o.actual_delivery_date is not null and o.order_date is not null
            then extract(day from o.actual_delivery_date - o.order_date)
            else null
        end as delivery_days,
        
        case
            when o.actual_delivery_date is not null and o.expected_delivery_date is not null
            then case 
                when o.actual_delivery_date <= o.expected_delivery_date then 'On Time'
                else 'Late'
            end
            else 'Unknown'
        end as delivery_status,
        
        -- Order status
        o.order_status,
        o.order_type,
        o.return_status,
        
        -- Product details (denormalized for performance)
        o.product_name,
        o.variant_name,
        o.product_weight,
        p.main_category,
        
        -- Quantity and pricing (MEASURES)
        o.quantity,
        o.original_price,
        o.discount_price,
        o.total_product_price,
        o.order_total_vnd,
        
        -- Discount breakdown (MEASURES)
        o.seller_discount,
        o.shopee_discount,
        o.shop_voucher,
        o.shopee_voucher,
        o.coins_cashback,
        o.total_discount,
        
        -- Shipping costs (MEASURES)
        o.shipping_fee_estimated,
        o.shipping_fee_paid,
        o.shipping_subsidy,
        
        -- Payment (MEASURES)
        o.total_paid,
        o.payment_method,
        
        -- Fees (MEASURES)
        o.fixed_fee,
        o.service_fee,
        o.payment_fee,
        o.deposit,
        
        -- Calculated measures
        o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee as net_revenue,
        
        case
            when o.original_price > 0 
            then round(((o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee) / (o.original_price * o.quantity)) * 100, 2)
            else 0
        end as profit_margin_pct,
        
        -- Order value tier
        case
            when o.order_total_vnd >= 1000000 then 'Premium (1M+)'
            when o.order_total_vnd >= 500000 then 'High (500K-1M)'
            when o.order_total_vnd >= 200000 then 'Medium (200K-500K)'
            when o.order_total_vnd >= 100000 then 'Low (100K-200K)'
            else 'Micro (<100K)'
        end as order_value_tier,
        
        -- Customer location (denormalized)
        o.province,
        o.district,
        c.region,
        
        -- Shipping info (denormalized)
        o.shipping_carrier,
        s.carrier_group,
        
        -- Payment info (denormalized)
        pm.payment_group,
        
        -- Customer order sequence
        seq.customer_order_seq,
        case when seq.customer_order_seq = 1 then 'New' else 'Repeat' end as new_vs_repeat,
        
        -- Sale event (denormalized from date)
        d.is_double_day_sale,
        d.sale_event_name,
        
        -- Flags
        o.is_bestseller,
        case when o.return_status is not null and o.return_status != '' then true else false end as is_returned,
        case when o.order_status in ('Ho√†n th√†nh', 'complete', 'completed', 'Completed') then true else false end as is_completed,
        case when o.order_status in ('ƒê√£ h·ªßy', 'cancelled', 'Cancelled', 'cancel') then true else false end as is_cancelled,
        
        -- Metadata
        o.source_file,
        o.source_loaded_at,
        current_timestamp as _gold_loaded_at
        
    from orders o
    left join customers c on o.buyer_username = c.buyer_username
    left join products p on o.product_name = p.product_name
    left join dates d on cast(o.order_date as date) = d.date
    left join shipping s on o.shipping_carrier = s.shipping_carrier
    left join payment pm on o.payment_method = pm.payment_method
    left join order_sequence seq on o.order_id = seq.order_id
)

select * from fact_orders
  );
  
[0m04:07:21.268017 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "full_date" does not exist
LINE 33:     select date_key, full_date as date, is_double_day_sale, ...
                              ^

[0m04:07:21.270698 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: ROLLBACK
[0m04:07:21.273063 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: Close
[0m04:07:21.278838 [debug] [Thread-1 (]: Database Error in model fct_orders (models/gold/facts/fct_orders.sql)
  column "full_date" does not exist
  LINE 33:     select date_key, full_date as date, is_double_day_sale, ...
                                ^
  compiled code at target/run/ecommerce_dbt/models/gold/facts/fct_orders.sql
[0m04:07:21.280440 [error] [Thread-1 (]: 11 of 14 ERROR creating sql table model analytics_gold.fct_orders .............. [[31mERROR[0m in 0.27s]
[0m04:07:21.281838 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m04:07:21.284336 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m04:07:21.285574 [info ] [Thread-1 (]: 12 of 14 SKIP relation analytics_gold.agg_customer_summary ..................... [[33mSKIP[0m]
[0m04:07:21.286932 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m04:07:21.288267 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m04:07:21.289321 [info ] [Thread-1 (]: 13 of 14 SKIP relation analytics_gold.agg_daily_sales .......................... [[33mSKIP[0m]
[0m04:07:21.290411 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m04:07:21.291653 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m04:07:21.292823 [info ] [Thread-1 (]: 14 of 14 SKIP relation analytics_gold.agg_product_performance .................. [[33mSKIP[0m]
[0m04:07:21.294331 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m04:07:21.298087 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:21.299120 [debug] [MainThread]: On master: BEGIN
[0m04:07:21.299971 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:07:21.309878 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m04:07:21.312594 [debug] [MainThread]: On master: COMMIT
[0m04:07:21.313935 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:21.315023 [debug] [MainThread]: On master: COMMIT
[0m04:07:21.318839 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:07:21.322428 [debug] [MainThread]: On master: Close
[0m04:07:21.325769 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:07:21.327564 [debug] [MainThread]: Connection 'model.ecommerce_dbt.fct_orders' was properly closed.
[0m04:07:21.329575 [info ] [MainThread]: 
[0m04:07:21.331541 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 2.61 seconds (2.61s).
[0m04:07:21.334949 [debug] [MainThread]: Command end result
[0m04:07:21.455650 [info ] [MainThread]: 
[0m04:07:21.457100 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:07:21.460821 [info ] [MainThread]: 
[0m04:07:21.462108 [error] [MainThread]:   Database Error in model fct_orders (models/gold/facts/fct_orders.sql)
  column "full_date" does not exist
  LINE 33:     select date_key, full_date as date, is_double_day_sale, ...
                                ^
  compiled code at target/run/ecommerce_dbt/models/gold/facts/fct_orders.sql
[0m04:07:21.463372 [info ] [MainThread]: 
[0m04:07:21.464537 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=1 SKIP=3 TOTAL=14
[0m04:07:21.466903 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 5.8743715, "process_user_time": 4.063142, "process_kernel_time": 0.586347, "process_mem_max_rss": "125768", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:07:21.469142 [debug] [MainThread]: Command `dbt run` failed at 04:07:21.468916 after 5.88 seconds
[0m04:07:21.471057 [debug] [MainThread]: Flushing usage events
[0m04:07:50.777264 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 04:07:50.787291 | cd7bf0e1-f050-4977-b938-063c323d8565 ==============================
[0m04:07:50.787291 [info ] [MainThread]: Running with dbt=1.8.0
[0m04:07:50.789109 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:07:51.105577 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m04:07:51.162761 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m04:07:53.475935 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:07:53.478149 [debug] [MainThread]: Partial parsing: updated file: ecommerce_dbt://models/gold/facts/fct_orders.sql
[0m04:07:53.739079 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m04:07:54.051083 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.marts
- models.ecommerce_dbt.staging
[0m04:07:54.256047 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m04:07:54.260898 [info ] [MainThread]: 
[0m04:07:54.262937 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:07:54.269350 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m04:07:54.310262 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:07:54.311402 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:07:54.312660 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:07:54.325082 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.012 seconds
[0m04:07:54.327285 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:07:54.330435 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:07:54.331402 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:07:54.332234 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:54.341283 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.009 seconds
[0m04:07:54.343114 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:07:54.346806 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:07:54.347956 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:07:54.348817 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:54.359947 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.011 seconds
[0m04:07:54.362446 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:07:54.367066 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics_bronze)
[0m04:07:54.374813 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:07:54.375962 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m04:07:54.376996 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:54.394048 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m04:07:54.395877 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:07:54.397092 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m04:07:54.402553 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m04:07:54.408345 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m04:07:54.411954 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m04:07:54.415115 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics_silver)
[0m04:07:54.422434 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:07:54.424468 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m04:07:54.425555 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:54.435427 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m04:07:54.437224 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:07:54.439084 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m04:07:54.445738 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.005 seconds
[0m04:07:54.448012 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m04:07:54.449413 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m04:07:54.450725 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics)
[0m04:07:54.456281 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:07:54.457416 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m04:07:54.458306 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:54.468293 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m04:07:54.469357 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:07:54.470173 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m04:07:54.474141 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m04:07:54.476130 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m04:07:54.477411 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m04:07:54.478728 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_gold)
[0m04:07:54.481282 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:07:54.482242 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m04:07:54.483213 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:07:54.492944 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m04:07:54.494112 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:07:54.495036 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m04:07:54.499437 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.003 seconds
[0m04:07:54.501655 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m04:07:54.503148 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m04:07:54.510096 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:54.511097 [debug] [MainThread]: On master: BEGIN
[0m04:07:54.511969 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:07:54.520945 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m04:07:54.522160 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:54.523196 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:07:54.533814 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m04:07:54.536551 [debug] [MainThread]: On master: ROLLBACK
[0m04:07:54.537931 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:54.538931 [debug] [MainThread]: On master: BEGIN
[0m04:07:54.540211 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m04:07:54.541455 [debug] [MainThread]: On master: COMMIT
[0m04:07:54.542497 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:54.543350 [debug] [MainThread]: On master: COMMIT
[0m04:07:54.544706 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:07:54.548600 [debug] [MainThread]: On master: Close
[0m04:07:54.550522 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:07:54.552336 [info ] [MainThread]: 
[0m04:07:54.562233 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m04:07:54.564074 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m04:07:54.566550 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now model.ecommerce_dbt.brz_raw_orders)
[0m04:07:54.570591 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m04:07:54.597627 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.641038 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m04:07:54.741782 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.772257 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.773191 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m04:07:54.774282 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:54.783734 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m04:07:54.784820 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.785719 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    -- BRONZE LAYER: Raw Orders
-- 1:1 copy from source with metadata columns
-- No transformations, preserving original data



select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m04:07:54.791781 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m04:07:54.801483 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.802627 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m04:07:54.805107 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m04:07:54.808776 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.809766 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m04:07:54.811598 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:54.832840 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:07:54.833830 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.834773 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:07:54.837295 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:54.845921 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m04:07:54.852964 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:07:54.854288 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m04:07:54.858780 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.003 seconds
[0m04:07:54.862299 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m04:07:54.865040 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.30s]
[0m04:07:54.866443 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m04:07:54.868175 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m04:07:54.869260 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m04:07:54.870170 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m04:07:54.871433 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m04:07:54.876751 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m04:07:54.898298 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m04:07:54.925240 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m04:07:54.952200 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:54.953753 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m04:07:54.955473 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:54.967239 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:07:54.969785 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:54.972166 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m04:07:54.997253 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.023 seconds
[0m04:07:55.001500 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:55.002843 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m04:07:55.004946 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.008932 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:55.010135 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m04:07:55.012043 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.020584 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:07:55.021779 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:55.022742 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:07:55.026074 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:55.030898 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m04:07:55.037446 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:07:55.038653 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m04:07:55.042944 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:07:55.045798 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m04:07:55.047827 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 268[0m in 0.18s]
[0m04:07:55.050018 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m04:07:55.051628 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m04:07:55.053367 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m04:07:55.056193 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m04:07:55.058158 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m04:07:55.067484 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m04:07:55.105905 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m04:07:55.113072 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m04:07:55.148302 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:55.150311 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m04:07:55.152280 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:55.168518 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:07:55.169773 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:55.170991 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m04:07:55.189922 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.017 seconds
[0m04:07:55.200007 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:55.201617 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m04:07:55.204457 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.213832 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:55.216213 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m04:07:55.219527 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.224882 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:07:55.226284 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:55.227496 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:07:55.229715 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m04:07:55.241186 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m04:07:55.243877 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:07:55.245296 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m04:07:55.252997 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m04:07:55.257687 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m04:07:55.260831 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.20s]
[0m04:07:55.262433 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m04:07:55.263638 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m04:07:55.264621 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m04:07:55.265745 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m04:07:55.266550 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m04:07:55.271215 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m04:07:55.290008 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m04:07:55.294106 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m04:07:55.311619 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:55.312834 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m04:07:55.313718 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:55.322047 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m04:07:55.323216 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:55.324188 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m04:07:55.353515 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.028 seconds
[0m04:07:55.357429 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:55.358558 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders" rename to "slv_orders__dbt_backup"
[0m04:07:55.360233 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.363735 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:55.364758 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp" rename to "slv_orders"
[0m04:07:55.366433 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.368773 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:07:55.369894 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:55.370768 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:07:55.374771 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:07:55.377806 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup"
[0m04:07:55.379111 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:07:55.380103 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup" cascade
[0m04:07:55.384558 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:07:55.386623 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m04:07:55.388016 [info ] [Thread-1 (]: 4 of 14 OK created sql table model analytics_silver.slv_orders ................. [[32mSELECT 516[0m in 0.12s]
[0m04:07:55.389619 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m04:07:55.390717 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m04:07:55.392017 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m04:07:55.393185 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m04:07:55.394262 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m04:07:55.398176 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m04:07:55.425329 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m04:07:55.431320 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m04:07:55.461466 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:55.462470 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m04:07:55.463426 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:55.472222 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m04:07:55.473186 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:55.474283 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders
unique_products as (
    select distinct
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m04:07:55.489298 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.014 seconds
[0m04:07:55.493511 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:55.494797 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products" rename to "slv_products__dbt_backup"
[0m04:07:55.496815 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.500755 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:55.501976 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m04:07:55.503662 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.506291 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:07:55.507423 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:55.508425 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:07:55.512533 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:07:55.516583 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m04:07:55.518653 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:07:55.519898 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m04:07:55.525910 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m04:07:55.528597 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m04:07:55.530454 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 236[0m in 0.14s]
[0m04:07:55.531898 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m04:07:55.533149 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m04:07:55.534135 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m04:07:55.535516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m04:07:55.536347 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m04:07:55.540075 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m04:07:55.570796 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m04:07:55.574935 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m04:07:55.605506 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:55.606650 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m04:07:55.608327 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:55.619816 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:07:55.620975 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:55.622053 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m04:07:55.633701 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.010 seconds
[0m04:07:55.637878 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:55.639015 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m04:07:55.640420 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:55.644127 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:55.645301 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m04:07:55.646710 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:55.648922 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:07:55.649919 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:55.650856 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:07:55.653880 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:55.657893 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m04:07:55.659747 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:07:55.660871 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m04:07:55.665174 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:07:55.667789 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m04:07:55.670607 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.13s]
[0m04:07:55.675067 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m04:07:55.676741 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m04:07:55.678280 [info ] [Thread-1 (]: 7 of 14 START sql table model analytics_gold.dim_customer ...................... [RUN]
[0m04:07:55.680041 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_date, now model.ecommerce_dbt.dim_customer)
[0m04:07:55.681227 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_customer
[0m04:07:55.685939 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_customer"
[0m04:07:55.705997 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_customer
[0m04:07:55.710027 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_customer"
[0m04:07:55.735360 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:55.736827 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: BEGIN
[0m04:07:55.737851 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:55.748500 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:07:55.749410 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:55.750816 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Dimension
-- Business-ready customer data with RFM segmentation



with customers as (
    select * from "ecommerce_db"."analytics_silver"."slv_customers"
),

-- Calculate order aggregates per customer
order_stats as (
    select
        buyer_username,
        count(distinct order_id) as total_orders,
        sum(order_total_vnd) as total_spent,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by buyer_username
),

-- RFM calculation
rfm_calc as (
    select
        c.*,
        coalesce(o.total_orders, 0) as total_orders,
        coalesce(o.total_spent, 0) as total_spent,
        coalesce(o.avg_order_value, 0) as avg_order_value,
        o.first_order_date,
        o.last_order_date,
        coalesce(o.days_since_last_order, 999) as days_since_last_order,
        
        -- RFM Scores (1-5 scale)
        ntile(5) over (order by coalesce(o.days_since_last_order, 999) desc) as r_score,
        ntile(5) over (order by coalesce(o.total_orders, 0)) as f_score,
        ntile(5) over (order by coalesce(o.total_spent, 0)) as m_score
        
    from customers c
    left join order_stats o on c.buyer_username = o.buyer_username
),

final as (
    select
        customer_id,
        buyer_username,
        recipient_name,
        phone_number,
        
        -- Geography
        province,
        district,
        ward,
        shipping_address,
        country,
        region,
        
        -- Customer key
        customer_key,
        
        -- Order metrics
        total_orders,
        total_spent,
        avg_order_value,
        first_order_date,
        last_order_date,
        days_since_last_order,
        
        -- RFM Scores
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score as rfm_score,
        
        -- RFM Segment
        case
            when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
            when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
            when r_score >= 4 and f_score <= 2 then 'Recent Customers'
            when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
            when r_score <= 2 and f_score >= 4 then 'At Risk'
            when r_score <= 2 and f_score >= 2 then 'Hibernating'
            when r_score <= 2 and f_score <= 2 then 'Lost'
            else 'Other'
        end as customer_segment,
        
        -- Customer lifecycle
        case 
            when total_orders = 1 then 'New'
            when total_orders between 2 and 3 then 'Returning'
            when total_orders between 4 and 10 then 'Regular'
            when total_orders > 10 then 'VIP'
            else 'Prospect'
        end as customer_lifecycle,
        
        -- Customer value tier
        case
            when total_spent >= 5000000 then 'Platinum'
            when total_spent >= 2000000 then 'Gold'
            when total_spent >= 500000 then 'Silver'
            else 'Bronze'
        end as customer_value_tier,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from rfm_calc
)

select * from final
  );
  
[0m04:07:55.773857 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.022 seconds
[0m04:07:55.781163 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:55.782156 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer" rename to "dim_customer__dbt_backup"
[0m04:07:55.783817 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.789317 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:55.790431 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m04:07:55.791690 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:55.795268 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:07:55.796906 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:55.798635 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:07:55.804319 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:07:55.809849 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup"
[0m04:07:55.812269 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:07:55.813495 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup" cascade
[0m04:07:55.818104 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:07:55.821171 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: Close
[0m04:07:55.823020 [info ] [Thread-1 (]: 7 of 14 OK created sql table model analytics_gold.dim_customer ................. [[32mSELECT 268[0m in 0.14s]
[0m04:07:55.825818 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m04:07:55.827256 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m04:07:55.828746 [info ] [Thread-1 (]: 8 of 14 START sql table model analytics_gold.dim_payment ....................... [RUN]
[0m04:07:55.830408 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_customer, now model.ecommerce_dbt.dim_payment)
[0m04:07:55.832073 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_payment
[0m04:07:55.837329 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_payment"
[0m04:07:55.864873 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_payment
[0m04:07:55.872436 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_payment"
[0m04:07:55.896694 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:55.898353 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: BEGIN
[0m04:07:55.899897 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:55.914193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:07:55.916920 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:55.918507 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Payment Dimension
-- Extracted from orders, enriched with payment grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique payment methods
unique_payments as (
    select distinct
        payment_method
    from source
    where payment_method is not null
),

enriched as (
    select
        row_number() over (order by payment_method) as payment_method_id,
        trim(payment_method) as payment_method,
        
        -- Payment method grouping
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'COD'
            when payment_method ilike '%shopee%' or payment_method ilike '%spay%' or payment_method ilike '%shopeepay%' then 'ShopeePay'
            when payment_method ilike '%momo%' then 'MoMo'
            when payment_method ilike '%zalo%' then 'ZaloPay'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Credit/Debit Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank Transfer'
            when payment_method ilike '%vnpay%' then 'VNPay'
            else 'Other'
        end as payment_group,
        
        -- Payment type
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'Cash'
            when payment_method ilike '%shopee%' or payment_method ilike '%momo%' or payment_method ilike '%zalo%' or payment_method ilike '%vnpay%' then 'E-Wallet'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank'
            else 'Other'
        end as payment_type,
        
        -- Is digital payment
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then false
            else true
        end as is_digital_payment,
        
        -- Payment key
        md5(coalesce(payment_method, 'unknown')) as payment_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_payments
)

select * from enriched
  );
  
[0m04:07:55.966198 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.046 seconds
[0m04:07:55.974195 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:55.975314 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment" rename to "dim_payment__dbt_backup"
[0m04:07:55.977340 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.983789 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:55.984971 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp" rename to "dim_payment"
[0m04:07:55.987100 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:55.990262 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:07:55.991281 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:55.992106 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:07:55.994506 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:55.997607 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup"
[0m04:07:55.999164 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:07:56.000239 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup" cascade
[0m04:07:56.003564 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:07:56.005671 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: Close
[0m04:07:56.006875 [info ] [Thread-1 (]: 8 of 14 OK created sql table model analytics_gold.dim_payment .................. [[32mSELECT 6[0m in 0.18s]
[0m04:07:56.008296 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m04:07:56.009264 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m04:07:56.010117 [info ] [Thread-1 (]: 9 of 14 START sql table model analytics_gold.dim_shipping ...................... [RUN]
[0m04:07:56.011082 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_payment, now model.ecommerce_dbt.dim_shipping)
[0m04:07:56.012003 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_shipping
[0m04:07:56.015816 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.040630 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_shipping
[0m04:07:56.045017 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.069660 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.070630 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: BEGIN
[0m04:07:56.071388 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:56.080065 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m04:07:56.081224 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.082146 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Shipping Dimension
-- Extracted from orders, enriched with carrier grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique shipping carriers
unique_carriers as (
    select distinct
        shipping_carrier,
        shipping_method
    from source
    where shipping_carrier is not null
),

enriched as (
    select
        row_number() over (order by shipping_carrier) as shipping_id,
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        
        -- Carrier grouping/normalization
        case
            when shipping_carrier ilike '%giao hang nhanh%' or shipping_carrier ilike '%ghn%' then 'GHN'
            when shipping_carrier ilike '%giao hang tiet kiem%' or shipping_carrier ilike '%ghtk%' then 'GHTK'
            when shipping_carrier ilike '%j&t%' or shipping_carrier ilike '%jt%' then 'J&T Express'
            when shipping_carrier ilike '%shopee express%' or shipping_carrier ilike '%spx%' then 'Shopee Express'
            when shipping_carrier ilike '%viettel%' then 'Viettel Post'
            when shipping_carrier ilike '%grab%' then 'GrabExpress'
            when shipping_carrier ilike '%ninja van%' then 'Ninja Van'
            when shipping_carrier ilike '%best%' then 'BEST Express'
            else 'Other'
        end as carrier_group,
        
        -- Carrier type
        case
            when shipping_carrier ilike '%shopee%' or shipping_carrier ilike '%spx%' then 'Platform Logistics'
            when shipping_carrier ilike '%grab%' then 'On-Demand'
            else 'Third Party Logistics'
        end as carrier_type,
        
        -- Shipping key
        md5(coalesce(shipping_carrier, 'unknown')) as shipping_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_carriers
)

select * from enriched
  );
  
[0m04:07:56.104038 [debug] [Thread-1 (]: SQL status: SELECT 9 in 0.021 seconds
[0m04:07:56.107449 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.108328 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping" rename to "dim_shipping__dbt_backup"
[0m04:07:56.109535 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:07:56.113674 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.115542 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp" rename to "dim_shipping"
[0m04:07:56.117866 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:56.123914 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:07:56.124981 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.125992 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:07:56.129372 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:07:56.132912 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup"
[0m04:07:56.134191 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:07:56.135335 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup" cascade
[0m04:07:56.139667 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:07:56.142285 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: Close
[0m04:07:56.143831 [info ] [Thread-1 (]: 9 of 14 OK created sql table model analytics_gold.dim_shipping ................. [[32mSELECT 9[0m in 0.13s]
[0m04:07:56.145035 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m04:07:56.146129 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m04:07:56.147233 [info ] [Thread-1 (]: 10 of 14 START sql table model analytics_gold.dim_product ...................... [RUN]
[0m04:07:56.148094 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_shipping, now model.ecommerce_dbt.dim_product)
[0m04:07:56.149304 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_product
[0m04:07:56.153670 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_product"
[0m04:07:56.182124 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_product
[0m04:07:56.192703 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_product"
[0m04:07:56.241384 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:56.243468 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: BEGIN
[0m04:07:56.244942 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:56.257313 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:07:56.260470 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:56.264061 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Dimension
-- Business-ready product data with performance metrics



with products as (
    select * from "ecommerce_db"."analytics_silver"."slv_products"
),

-- Calculate product performance
product_stats as (
    select
        product_name,
        count(distinct order_id) as total_orders,
        sum(quantity) as total_quantity_sold,
        sum(order_total_vnd) as total_revenue,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by product_name
),

final as (
    select
        p.product_id,
        p.product_name,
        p.product_sku,
        p.variant_name,
        p.variant_sku,
        p.main_category,
        
        -- Pricing
        p.original_price,
        p.discounted_price,
        case 
            when p.original_price > 0 
            then round((1 - p.discounted_price / p.original_price) * 100, 2)
            else 0
        end as discount_percentage,
        
        -- Weight
        p.product_weight,
        
        -- Product key
        p.product_key,
        
        -- Performance metrics
        coalesce(s.total_orders, 0) as total_orders,
        coalesce(s.total_quantity_sold, 0) as total_quantity_sold,
        coalesce(s.total_revenue, 0) as total_revenue,
        coalesce(s.avg_order_value, 0) as avg_order_value,
        s.first_sold_date,
        s.last_sold_date,
        
        -- Product tier based on revenue
        case
            when s.total_revenue >= 10000000 then 'Star Product'
            when s.total_revenue >= 5000000 then 'High Performer'
            when s.total_revenue >= 1000000 then 'Moderate'
            when s.total_revenue > 0 then 'Low Performer'
            else 'No Sales'
        end as product_tier,
        
        -- Velocity
        case 
            when s.total_quantity_sold >= 50 then 'Fast Moving'
            when s.total_quantity_sold >= 20 then 'Medium Moving'
            when s.total_quantity_sold >= 5 then 'Slow Moving'
            else 'Very Slow'
        end as sales_velocity,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from products p
    left join product_stats s on p.product_name = s.product_name
)

select * from final
  );
  
[0m04:07:56.288310 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.023 seconds
[0m04:07:56.295000 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:56.296513 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product" rename to "dim_product__dbt_backup"
[0m04:07:56.298705 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:56.303351 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:56.305207 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp" rename to "dim_product"
[0m04:07:56.307801 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:56.314491 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:07:56.317966 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:56.320324 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:07:56.325864 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:07:56.334730 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_product__dbt_backup"
[0m04:07:56.337656 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:07:56.339771 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_product__dbt_backup" cascade
[0m04:07:56.348665 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m04:07:56.354802 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: Close
[0m04:07:56.359330 [info ] [Thread-1 (]: 10 of 14 OK created sql table model analytics_gold.dim_product ................. [[32mSELECT 236[0m in 0.21s]
[0m04:07:56.362117 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m04:07:56.364293 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m04:07:56.366837 [info ] [Thread-1 (]: 11 of 14 START sql table model analytics_gold.fct_orders ....................... [RUN]
[0m04:07:56.370383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_product, now model.ecommerce_dbt.fct_orders)
[0m04:07:56.374019 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.fct_orders
[0m04:07:56.385672 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.fct_orders"
[0m04:07:56.434768 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.fct_orders
[0m04:07:56.441905 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.fct_orders"
[0m04:07:56.509934 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:07:56.513807 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: BEGIN
[0m04:07:56.516275 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:56.534755 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:07:56.537570 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:07:56.540802 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Fact Orders
-- Main fact table - Star Schema center
-- Joins all dimensions with measures



with orders as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

customers as (
    select customer_id, buyer_username, customer_key, region, customer_segment
    from "ecommerce_db"."analytics_gold"."dim_customer"
),

products as (
    select product_id, product_name, product_key, main_category, product_tier
    from "ecommerce_db"."analytics_gold"."dim_product"
),

dates as (
    select date_key, date, is_double_day_sale, sale_event_name
    from "ecommerce_db"."analytics_gold"."dim_date"
),

shipping as (
    select shipping_id, shipping_carrier, shipping_key, carrier_group
    from "ecommerce_db"."analytics_gold"."dim_shipping"
),

payment as (
    select payment_method_id, payment_method, payment_key, payment_group
    from "ecommerce_db"."analytics_gold"."dim_payment"
),

-- Customer order sequence
order_sequence as (
    select
        order_id,
        buyer_username,
        row_number() over (
            partition by buyer_username 
            order by order_date
        ) as customer_order_seq
    from orders
),

fact_orders as (
    select
        -- Primary key
        o.order_id,
        
        -- Dimension keys (foreign keys)
        c.customer_id,
        p.product_id,
        d.date_key as order_date_key,
        s.shipping_id,
        pm.payment_method_id,
        
        -- Surrogate keys (for BI tools)
        c.customer_key,
        p.product_key,
        s.shipping_key,
        pm.payment_key,
        
        -- Natural keys (for reference)
        o.package_id,
        o.tracking_number,
        
        -- Date dimensions
        o.order_date,
        o.expected_delivery_date,
        o.actual_delivery_date,
        o.order_completed_date,
        o.payment_date,
        
        -- Delivery metrics
        case
            when o.actual_delivery_date is not null and o.order_date is not null
            then extract(day from o.actual_delivery_date - o.order_date)
            else null
        end as delivery_days,
        
        case
            when o.actual_delivery_date is not null and o.expected_delivery_date is not null
            then case 
                when o.actual_delivery_date <= o.expected_delivery_date then 'On Time'
                else 'Late'
            end
            else 'Unknown'
        end as delivery_status,
        
        -- Order status
        o.order_status,
        o.order_type,
        o.return_status,
        
        -- Product details (denormalized for performance)
        o.product_name,
        o.variant_name,
        o.product_weight,
        p.main_category,
        
        -- Quantity and pricing (MEASURES)
        o.quantity,
        o.original_price,
        o.discount_price,
        o.total_product_price,
        o.order_total_vnd,
        
        -- Discount breakdown (MEASURES)
        o.seller_discount,
        o.shopee_discount,
        o.shop_voucher,
        o.shopee_voucher,
        o.coins_cashback,
        o.total_discount,
        
        -- Shipping costs (MEASURES)
        o.shipping_fee_estimated,
        o.shipping_fee_paid,
        o.shipping_subsidy,
        
        -- Payment (MEASURES)
        o.total_paid,
        o.payment_method,
        
        -- Fees (MEASURES)
        o.fixed_fee,
        o.service_fee,
        o.payment_fee,
        o.deposit,
        
        -- Calculated measures
        o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee as net_revenue,
        
        case
            when o.original_price > 0 
            then round(((o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee) / (o.original_price * o.quantity)) * 100, 2)
            else 0
        end as profit_margin_pct,
        
        -- Order value tier
        case
            when o.order_total_vnd >= 1000000 then 'Premium (1M+)'
            when o.order_total_vnd >= 500000 then 'High (500K-1M)'
            when o.order_total_vnd >= 200000 then 'Medium (200K-500K)'
            when o.order_total_vnd >= 100000 then 'Low (100K-200K)'
            else 'Micro (<100K)'
        end as order_value_tier,
        
        -- Customer location (denormalized)
        o.province,
        o.district,
        c.region,
        
        -- Shipping info (denormalized)
        o.shipping_carrier,
        s.carrier_group,
        
        -- Payment info (denormalized)
        pm.payment_group,
        
        -- Customer order sequence
        seq.customer_order_seq,
        case when seq.customer_order_seq = 1 then 'New' else 'Repeat' end as new_vs_repeat,
        
        -- Sale event (denormalized from date)
        d.is_double_day_sale,
        d.sale_event_name,
        
        -- Flags
        o.is_bestseller,
        case when o.return_status is not null and o.return_status != '' then true else false end as is_returned,
        case when o.order_status in ('Ho√†n th√†nh', 'complete', 'completed', 'Completed') then true else false end as is_completed,
        case when o.order_status in ('ƒê√£ h·ªßy', 'cancelled', 'Cancelled', 'cancel') then true else false end as is_cancelled,
        
        -- Metadata
        o.source_file,
        o.source_loaded_at,
        current_timestamp as _gold_loaded_at
        
    from orders o
    left join customers c on o.buyer_username = c.buyer_username
    left join products p on o.product_name = p.product_name
    left join dates d on cast(o.order_date as date) = d.date
    left join shipping s on o.shipping_carrier = s.shipping_carrier
    left join payment pm on o.payment_method = pm.payment_method
    left join order_sequence seq on o.order_id = seq.order_id
)

select * from fact_orders
  );
  
[0m04:07:57.079053 [debug] [Thread-1 (]: SQL status: SELECT 25442 in 0.535 seconds
[0m04:07:57.088881 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:07:57.090369 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp" rename to "fct_orders"
[0m04:07:57.092351 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:07:57.098678 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m04:07:57.101039 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:07:57.103782 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m04:07:57.109280 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m04:07:57.113867 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup"
[0m04:07:57.115762 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:07:57.117156 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
drop table if exists "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup" cascade
[0m04:07:57.121106 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m04:07:57.126498 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: Close
[0m04:07:57.130243 [info ] [Thread-1 (]: 11 of 14 OK created sql table model analytics_gold.fct_orders .................. [[32mSELECT 25442[0m in 0.76s]
[0m04:07:57.132902 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m04:07:57.135026 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m04:07:57.136443 [info ] [Thread-1 (]: 12 of 14 START sql table model analytics_gold.agg_customer_summary ............. [RUN]
[0m04:07:57.138114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.fct_orders, now model.ecommerce_dbt.agg_customer_summary)
[0m04:07:57.139627 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_customer_summary
[0m04:07:57.144475 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_customer_summary"
[0m04:07:57.212379 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_customer_summary
[0m04:07:57.222455 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_customer_summary"
[0m04:07:57.273376 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:07:57.274283 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: BEGIN
[0m04:07:57.275403 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:57.286676 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:07:57.289290 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:07:57.291447 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Summary Aggregate
-- Customer-level aggregated metrics with RFM



with customer_orders as (
    select
        buyer_username,
        customer_id,
        region,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Quantity
        sum(quantity) as total_items_purchased,
        
        -- Revenue
        sum(order_total_vnd) as total_spent,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Time metrics
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order,
        
        -- Product diversity
        count(distinct product_name) as unique_products_ordered,
        count(distinct main_category) as unique_categories,
        
        -- Shipping preferences
        mode() within group (order by carrier_group) as preferred_carrier,
        mode() within group (order by payment_group) as preferred_payment
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where buyer_username is not null
    group by 1, 2, 3
),

with_rfm as (
    select
        *,
        
        -- RFM Scores
        ntile(5) over (order by days_since_last_order desc nulls last) as r_score,
        ntile(5) over (order by total_orders asc nulls first) as f_score,
        ntile(5) over (order by total_spent asc nulls first) as m_score
        
    from customer_orders
    where total_orders > 0
)

select
    buyer_username,
    customer_id,
    region,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    total_items_purchased,
    
    -- Revenue metrics
    total_spent,
    total_net_revenue,
    avg_order_value,
    
    -- Time metrics
    first_order_date,
    last_order_date,
    days_since_last_order,
    
    -- Tenure (days as customer)
    current_date - first_order_date::date as customer_tenure_days,
    
    -- Frequency (orders per month)
    case 
        when current_date - first_order_date::date > 30 
        then round(total_orders * 30.0 / (current_date - first_order_date::date), 2)
        else total_orders
    end as orders_per_month,
    
    -- Product diversity
    unique_products_ordered,
    unique_categories,
    
    -- Preferences
    preferred_carrier,
    preferred_payment,
    
    -- RFM
    r_score,
    f_score,
    m_score,
    r_score * 100 + f_score * 10 + m_score as rfm_score,
    
    -- RFM Segment
    case
        when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
        when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
        when r_score >= 4 and f_score <= 2 then 'Recent Customers'
        when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
        when r_score <= 2 and f_score >= 4 then 'At Risk'
        when r_score <= 2 and f_score >= 2 then 'Hibernating'
        when r_score <= 2 and f_score <= 2 then 'Lost'
        else 'Other'
    end as customer_segment,
    
    -- Customer lifecycle
    case 
        when total_orders = 1 then 'New'
        when total_orders between 2 and 3 then 'Returning'
        when total_orders between 4 and 10 then 'Regular'
        when total_orders > 10 then 'VIP'
    end as customer_lifecycle,
    
    -- Value tier
    case
        when total_spent >= 5000000 then 'Platinum'
        when total_spent >= 2000000 then 'Gold'
        when total_spent >= 500000 then 'Silver'
        else 'Bronze'
    end as customer_value_tier,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from with_rfm
order by total_spent desc
  );
  
[0m04:07:57.293295 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "buyer_username" does not exist
LINE 19:         buyer_username,
                 ^

[0m04:07:57.294935 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: ROLLBACK
[0m04:07:57.298371 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: Close
[0m04:07:57.307497 [debug] [Thread-1 (]: Database Error in model agg_customer_summary (models/gold/aggregates/agg_customer_summary.sql)
  column "buyer_username" does not exist
  LINE 19:         buyer_username,
                   ^
  compiled code at target/run/ecommerce_dbt/models/gold/aggregates/agg_customer_summary.sql
[0m04:07:57.308676 [error] [Thread-1 (]: 12 of 14 ERROR creating sql table model analytics_gold.agg_customer_summary .... [[31mERROR[0m in 0.17s]
[0m04:07:57.309839 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m04:07:57.312118 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m04:07:57.317976 [info ] [Thread-1 (]: 13 of 14 START sql table model analytics_gold.agg_daily_sales .................. [RUN]
[0m04:07:57.320572 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_customer_summary, now model.ecommerce_dbt.agg_daily_sales)
[0m04:07:57.321571 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_daily_sales
[0m04:07:57.325419 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_daily_sales"
[0m04:07:57.346258 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_daily_sales
[0m04:07:57.351063 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_daily_sales"
[0m04:07:57.382481 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:07:57.394745 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: BEGIN
[0m04:07:57.399897 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:57.418609 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m04:07:57.420615 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:07:57.424565 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Daily Sales Aggregate
-- Daily sales metrics for dashboards



with daily_orders as (
    select
        cast(order_date as date) as order_date,
        order_date_key,
        is_double_day_sale,
        sale_event_name,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_cancelled then order_id end) as cancelled_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        count(distinct case when new_vs_repeat = 'Repeat' then buyer_username end) as repeat_customers,
        
        -- Product counts
        count(distinct product_name) as unique_products,
        sum(quantity) as total_quantity,
        
        -- Revenue metrics
        sum(order_total_vnd) as gross_revenue,
        sum(net_revenue) as net_revenue,
        sum(total_discount) as total_discount,
        sum(shipping_fee_paid) as total_shipping,
        
        -- Fee breakdown
        sum(fixed_fee) as total_fixed_fee,
        sum(service_fee) as total_service_fee,
        sum(payment_fee) as total_payment_fee,
        
        -- Averages
        avg(order_total_vnd) as avg_order_value,
        avg(quantity) as avg_items_per_order,
        avg(delivery_days) as avg_delivery_days,
        
        -- By order value tier
        count(distinct case when order_value_tier = 'Premium (1M+)' then order_id end) as premium_orders,
        count(distinct case when order_value_tier = 'Micro (<100K)' then order_id end) as micro_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    group by 1, 2, 3, 4
)

select
    d.*,
    
    -- Completion rate
    case 
        when total_orders > 0 
        then round(completed_orders * 100.0 / total_orders, 2)
        else 0 
    end as completion_rate_pct,
    
    -- Cancellation rate
    case 
        when total_orders > 0 
        then round(cancelled_orders * 100.0 / total_orders, 2)
        else 0 
    end as cancellation_rate_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- New customer rate
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from daily_orders d
order by order_date desc
  );
  
[0m04:07:57.431974 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "buyer_username" does not exist
LINE 31:         count(distinct buyer_username) as unique_customers,
                                ^

[0m04:07:57.437978 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: ROLLBACK
[0m04:07:57.441609 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: Close
[0m04:07:57.448504 [debug] [Thread-1 (]: Database Error in model agg_daily_sales (models/gold/aggregates/agg_daily_sales.sql)
  column "buyer_username" does not exist
  LINE 31:         count(distinct buyer_username) as unique_customers,
                                  ^
  compiled code at target/run/ecommerce_dbt/models/gold/aggregates/agg_daily_sales.sql
[0m04:07:57.470489 [error] [Thread-1 (]: 13 of 14 ERROR creating sql table model analytics_gold.agg_daily_sales ......... [[31mERROR[0m in 0.15s]
[0m04:07:57.479849 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m04:07:57.487319 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m04:07:57.501985 [info ] [Thread-1 (]: 14 of 14 START sql table model analytics_gold.agg_product_performance .......... [RUN]
[0m04:07:57.509181 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_daily_sales, now model.ecommerce_dbt.agg_product_performance)
[0m04:07:57.518492 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_product_performance
[0m04:07:57.535510 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_product_performance"
[0m04:07:57.619787 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_product_performance
[0m04:07:57.623828 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_product_performance"
[0m04:07:57.698973 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:07:57.700301 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: BEGIN
[0m04:07:57.703867 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:07:57.717772 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:07:57.720443 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:07:57.722345 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Performance Aggregate
-- Product-level aggregated metrics



with product_orders as (
    select
        product_name,
        product_id,
        main_category,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        
        -- Quantity
        sum(quantity) as total_quantity_sold,
        avg(quantity) as avg_quantity_per_order,
        
        -- Revenue
        sum(order_total_vnd) as total_revenue,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Pricing
        avg(original_price) as avg_original_price,
        avg(discount_price) as avg_discount_price,
        sum(total_discount) as total_discount_given,
        
        -- Time metrics
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date,
        current_date - max(order_date)::date as days_since_last_sale,
        
        -- Geography
        mode() within group (order by region) as top_region,
        
        -- Sale events
        count(distinct case when is_double_day_sale then order_id end) as sale_event_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where product_name is not null
    group by 1, 2, 3
)

select
    product_name,
    product_id,
    main_category,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    
    -- Customer metrics
    unique_customers,
    new_customers,
    
    -- Quantity metrics
    total_quantity_sold,
    avg_quantity_per_order,
    
    -- Revenue metrics
    total_revenue,
    total_net_revenue,
    avg_order_value,
    
    -- Pricing metrics
    avg_original_price,
    avg_discount_price,
    total_discount_given,
    
    -- Discount percentage
    case 
        when avg_original_price > 0 
        then round((1 - avg_discount_price / avg_original_price) * 100, 2)
        else 0 
    end as avg_discount_pct,
    
    -- Time metrics
    first_sold_date,
    last_sold_date,
    days_since_last_sale,
    
    -- Selling period (days)
    last_sold_date::date - first_sold_date::date as selling_period_days,
    
    -- Sales velocity (units per day)
    case 
        when last_sold_date::date - first_sold_date::date > 0 
        then round(total_quantity_sold * 1.0 / (last_sold_date::date - first_sold_date::date + 1), 2)
        else total_quantity_sold
    end as daily_sales_velocity,
    
    -- Top region
    top_region,
    
    -- Sale event performance
    sale_event_orders,
    case 
        when total_orders > 0 
        then round(sale_event_orders * 100.0 / total_orders, 2)
        else 0 
    end as sale_event_order_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Customer acquisition
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_pct,
    
    -- Product tier
    case
        when total_revenue >= 10000000 then 'Star Product'
        when total_revenue >= 5000000 then 'High Performer'
        when total_revenue >= 1000000 then 'Moderate'
        when total_revenue > 0 then 'Low Performer'
        else 'No Sales'
    end as product_tier,
    
    -- Sales velocity category
    case 
        when total_quantity_sold >= 50 then 'Fast Moving'
        when total_quantity_sold >= 20 then 'Medium Moving'
        when total_quantity_sold >= 5 then 'Slow Moving'
        else 'Very Slow'
    end as sales_velocity_category,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from product_orders
order by total_revenue desc
  );
  
[0m04:07:57.725261 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "buyer_username" does not exist
LINE 29:         count(distinct buyer_username) as unique_customers,
                                ^

[0m04:07:57.726471 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: ROLLBACK
[0m04:07:57.728194 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: Close
[0m04:07:57.731499 [debug] [Thread-1 (]: Database Error in model agg_product_performance (models/gold/aggregates/agg_product_performance.sql)
  column "buyer_username" does not exist
  LINE 29:         count(distinct buyer_username) as unique_customers,
                                  ^
  compiled code at target/run/ecommerce_dbt/models/gold/aggregates/agg_product_performance.sql
[0m04:07:57.732860 [error] [Thread-1 (]: 14 of 14 ERROR creating sql table model analytics_gold.agg_product_performance . [[31mERROR[0m in 0.22s]
[0m04:07:57.734248 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m04:07:57.736662 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:57.738761 [debug] [MainThread]: On master: BEGIN
[0m04:07:57.739728 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:07:57.749683 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m04:07:57.751995 [debug] [MainThread]: On master: COMMIT
[0m04:07:57.753144 [debug] [MainThread]: Using postgres connection "master"
[0m04:07:57.758125 [debug] [MainThread]: On master: COMMIT
[0m04:07:57.763290 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:07:57.764780 [debug] [MainThread]: On master: Close
[0m04:07:57.770439 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:07:57.775521 [debug] [MainThread]: Connection 'model.ecommerce_dbt.agg_product_performance' was properly closed.
[0m04:07:57.779915 [info ] [MainThread]: 
[0m04:07:57.787672 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 3.52 seconds (3.52s).
[0m04:07:57.795758 [debug] [MainThread]: Command end result
[0m04:07:57.993792 [info ] [MainThread]: 
[0m04:07:57.994881 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m04:07:57.996345 [info ] [MainThread]: 
[0m04:07:57.997542 [error] [MainThread]:   Database Error in model agg_customer_summary (models/gold/aggregates/agg_customer_summary.sql)
  column "buyer_username" does not exist
  LINE 19:         buyer_username,
                   ^
  compiled code at target/run/ecommerce_dbt/models/gold/aggregates/agg_customer_summary.sql
[0m04:07:57.999227 [info ] [MainThread]: 
[0m04:07:58.000250 [error] [MainThread]:   Database Error in model agg_daily_sales (models/gold/aggregates/agg_daily_sales.sql)
  column "buyer_username" does not exist
  LINE 31:         count(distinct buyer_username) as unique_customers,
                                  ^
  compiled code at target/run/ecommerce_dbt/models/gold/aggregates/agg_daily_sales.sql
[0m04:07:58.001429 [info ] [MainThread]: 
[0m04:07:58.003756 [error] [MainThread]:   Database Error in model agg_product_performance (models/gold/aggregates/agg_product_performance.sql)
  column "buyer_username" does not exist
  LINE 29:         count(distinct buyer_username) as unique_customers,
                                  ^
  compiled code at target/run/ecommerce_dbt/models/gold/aggregates/agg_product_performance.sql
[0m04:07:58.005898 [info ] [MainThread]: 
[0m04:07:58.007043 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=3 SKIP=0 TOTAL=14
[0m04:07:58.009172 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 7.3793597, "process_user_time": 3.769354, "process_kernel_time": 0.512339, "process_mem_max_rss": "126204", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:07:58.010915 [debug] [MainThread]: Command `dbt run` failed at 04:07:58.010645 after 7.38 seconds
[0m04:07:58.014028 [debug] [MainThread]: Flushing usage events
[0m04:08:39.504812 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 04:08:39.517439 | 0bbcc4b0-5cea-4bbb-83ff-fc05911d928a ==============================
[0m04:08:39.517439 [info ] [MainThread]: Running with dbt=1.8.0
[0m04:08:39.521074 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'profiles_dir': '/opt/airflow/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:08:39.915270 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m04:08:39.982722 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m04:08:43.116870 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:08:43.120389 [debug] [MainThread]: Partial parsing: updated file: ecommerce_dbt://models/gold/facts/fct_orders.sql
[0m04:08:43.403457 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m04:08:43.744627 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.staging
- models.ecommerce_dbt.marts
[0m04:08:44.237508 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m04:08:44.242108 [info ] [MainThread]: 
[0m04:08:44.244588 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:08:44.255993 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m04:08:44.330725 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:08:44.332472 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:08:44.333769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:08:44.359442 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.025 seconds
[0m04:08:44.363043 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:08:44.366897 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:08:44.368062 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:08:44.370088 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:08:44.384025 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.014 seconds
[0m04:08:44.386859 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:08:44.393253 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:08:44.394678 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:08:44.396974 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:08:44.411126 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.014 seconds
[0m04:08:44.414624 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:08:44.419788 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics_bronze)
[0m04:08:44.428106 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:08:44.429757 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m04:08:44.431053 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:08:44.450393 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m04:08:44.452411 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:08:44.454162 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m04:08:44.462297 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m04:08:44.465499 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m04:08:44.468756 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m04:08:44.472152 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics_gold)
[0m04:08:44.479463 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:08:44.482015 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m04:08:44.484491 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:08:44.502854 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m04:08:44.505232 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:08:44.508571 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m04:08:44.516440 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.005 seconds
[0m04:08:44.521615 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m04:08:44.524864 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m04:08:44.527789 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now list_ecommerce_db_analytics)
[0m04:08:44.532872 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:08:44.535056 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m04:08:44.537131 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:08:44.549446 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m04:08:44.551422 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:08:44.553442 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m04:08:44.564108 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.009 seconds
[0m04:08:44.569412 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m04:08:44.571792 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m04:08:44.576650 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_silver)
[0m04:08:44.581081 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:08:44.582426 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m04:08:44.584668 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:08:44.602348 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:08:44.605234 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:08:44.608363 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m04:08:44.617989 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.007 seconds
[0m04:08:44.624937 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m04:08:44.628663 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m04:08:44.641112 [debug] [MainThread]: Using postgres connection "master"
[0m04:08:44.643511 [debug] [MainThread]: On master: BEGIN
[0m04:08:44.646084 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:08:44.657116 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m04:08:44.658174 [debug] [MainThread]: Using postgres connection "master"
[0m04:08:44.660008 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:08:44.677823 [debug] [MainThread]: SQL status: SELECT 1 in 0.016 seconds
[0m04:08:44.682412 [debug] [MainThread]: On master: ROLLBACK
[0m04:08:44.687395 [debug] [MainThread]: Using postgres connection "master"
[0m04:08:44.689921 [debug] [MainThread]: On master: BEGIN
[0m04:08:44.693874 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m04:08:44.695414 [debug] [MainThread]: On master: COMMIT
[0m04:08:44.696925 [debug] [MainThread]: Using postgres connection "master"
[0m04:08:44.698931 [debug] [MainThread]: On master: COMMIT
[0m04:08:44.701653 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m04:08:44.704030 [debug] [MainThread]: On master: Close
[0m04:08:44.706790 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:08:44.709712 [info ] [MainThread]: 
[0m04:08:44.714110 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m04:08:44.712822 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m04:08:44.714023 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now model.ecommerce_dbt.brz_raw_orders)
[0m04:08:44.714850 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m04:08:44.723874 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:44.808177 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m04:08:44.939408 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:45.029107 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:45.035772 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m04:08:45.038523 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:45.056264 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:08:45.058787 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:45.061226 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    -- BRONZE LAYER: Raw Orders
-- 1:1 copy from source with metadata columns
-- No transformations, preserving original data



select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m04:08:45.071702 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m04:08:45.083723 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:45.085434 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m04:08:45.088718 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m04:08:45.093555 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:45.095140 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m04:08:45.097704 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:45.116952 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:08:45.119541 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:45.121463 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:08:45.127394 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m04:08:45.144350 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m04:08:45.155744 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:08:45.158359 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m04:08:45.166094 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.005 seconds
[0m04:08:45.173041 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m04:08:45.176283 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.46s]
[0m04:08:45.178343 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m04:08:45.181144 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m04:08:45.183193 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m04:08:45.185839 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m04:08:45.187010 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m04:08:45.193003 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m04:08:45.260792 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m04:08:45.303314 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m04:08:45.390528 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:08:45.393284 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m04:08:45.395711 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:45.414647 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m04:08:45.416018 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:08:45.418736 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m04:08:45.446477 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.025 seconds
[0m04:08:45.453553 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:08:45.456921 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m04:08:45.460625 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:45.469700 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:08:45.471994 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m04:08:45.474450 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:45.482455 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:08:45.483780 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:08:45.485473 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:08:45.491665 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m04:08:45.502350 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m04:08:45.509959 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:08:45.511846 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m04:08:45.518391 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m04:08:45.522442 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m04:08:45.524738 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 268[0m in 0.34s]
[0m04:08:45.527075 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m04:08:45.528292 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m04:08:45.529270 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m04:08:45.530121 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m04:08:45.530958 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m04:08:45.535133 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m04:08:45.607386 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m04:08:45.619229 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m04:08:45.755337 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:08:45.763202 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m04:08:45.770025 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:45.791127 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m04:08:45.792543 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:08:45.794722 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m04:08:45.810255 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.014 seconds
[0m04:08:45.815300 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:08:45.818674 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m04:08:45.822059 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:45.828298 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:08:45.830260 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m04:08:45.836191 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:45.840325 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:08:45.841697 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:08:45.843229 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:08:45.846762 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:08:45.851287 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m04:08:45.852904 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:08:45.853903 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m04:08:45.858191 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:08:45.862572 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m04:08:45.864864 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.33s]
[0m04:08:45.867411 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m04:08:45.868612 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m04:08:45.869989 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m04:08:45.871609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m04:08:45.876019 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m04:08:45.882491 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m04:08:45.929404 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m04:08:45.936287 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m04:08:45.995621 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:08:46.000660 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m04:08:46.003414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:46.016135 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:08:46.019435 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:08:46.021436 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m04:08:46.041441 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.018 seconds
[0m04:08:46.050115 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:08:46.051382 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders" rename to "slv_orders__dbt_backup"
[0m04:08:46.053345 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:46.059909 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:08:46.061524 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp" rename to "slv_orders"
[0m04:08:46.063377 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:46.067313 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:08:46.068863 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:08:46.071989 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:08:46.075749 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m04:08:46.080152 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup"
[0m04:08:46.082789 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:08:46.085554 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup" cascade
[0m04:08:46.090721 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:08:46.094875 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m04:08:46.096569 [info ] [Thread-1 (]: 4 of 14 OK created sql table model analytics_silver.slv_orders ................. [[32mSELECT 516[0m in 0.23s]
[0m04:08:46.099191 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m04:08:46.101071 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m04:08:46.103188 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m04:08:46.105467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m04:08:46.106746 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m04:08:46.111279 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m04:08:46.196340 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m04:08:46.213703 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m04:08:46.290984 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:08:46.294580 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m04:08:46.296178 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:46.312359 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:08:46.314877 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:08:46.315929 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders
unique_products as (
    select distinct
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m04:08:46.328804 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.012 seconds
[0m04:08:46.332979 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:08:46.334340 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products" rename to "slv_products__dbt_backup"
[0m04:08:46.336546 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:08:46.341701 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:08:46.342989 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m04:08:46.344354 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:08:46.347519 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:08:46.349744 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:08:46.352407 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:08:46.355282 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m04:08:46.358748 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m04:08:46.362131 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:08:46.364452 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m04:08:46.367961 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:08:46.371250 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m04:08:46.373952 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 236[0m in 0.27s]
[0m04:08:46.375691 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m04:08:46.382318 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m04:08:46.383566 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m04:08:46.384609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m04:08:46.385672 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m04:08:46.390181 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m04:08:46.459592 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m04:08:46.464282 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m04:08:46.539772 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:08:46.542252 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m04:08:46.545461 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:46.563871 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:08:46.566273 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:08:46.568172 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m04:08:46.584517 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.014 seconds
[0m04:08:46.596903 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:08:46.601432 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m04:08:46.605499 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:46.612348 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:08:46.614070 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m04:08:46.615894 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:46.619338 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:08:46.620770 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:08:46.622074 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:08:46.625509 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:08:46.628863 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m04:08:46.630515 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:08:46.631752 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m04:08:46.636618 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m04:08:46.638971 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m04:08:46.640616 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.26s]
[0m04:08:46.641992 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m04:08:46.646329 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m04:08:46.647454 [info ] [Thread-1 (]: 7 of 14 START sql table model analytics_gold.dim_customer ...................... [RUN]
[0m04:08:46.648404 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_date, now model.ecommerce_dbt.dim_customer)
[0m04:08:46.649810 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_customer
[0m04:08:46.654531 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_customer"
[0m04:08:46.722461 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_customer
[0m04:08:46.736127 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_customer"
[0m04:08:46.802396 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:08:46.803768 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: BEGIN
[0m04:08:46.806707 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:46.819989 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:08:46.821240 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:08:46.822572 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Dimension
-- Business-ready customer data with RFM segmentation



with customers as (
    select * from "ecommerce_db"."analytics_silver"."slv_customers"
),

-- Calculate order aggregates per customer
order_stats as (
    select
        buyer_username,
        count(distinct order_id) as total_orders,
        sum(order_total_vnd) as total_spent,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by buyer_username
),

-- RFM calculation
rfm_calc as (
    select
        c.*,
        coalesce(o.total_orders, 0) as total_orders,
        coalesce(o.total_spent, 0) as total_spent,
        coalesce(o.avg_order_value, 0) as avg_order_value,
        o.first_order_date,
        o.last_order_date,
        coalesce(o.days_since_last_order, 999) as days_since_last_order,
        
        -- RFM Scores (1-5 scale)
        ntile(5) over (order by coalesce(o.days_since_last_order, 999) desc) as r_score,
        ntile(5) over (order by coalesce(o.total_orders, 0)) as f_score,
        ntile(5) over (order by coalesce(o.total_spent, 0)) as m_score
        
    from customers c
    left join order_stats o on c.buyer_username = o.buyer_username
),

final as (
    select
        customer_id,
        buyer_username,
        recipient_name,
        phone_number,
        
        -- Geography
        province,
        district,
        ward,
        shipping_address,
        country,
        region,
        
        -- Customer key
        customer_key,
        
        -- Order metrics
        total_orders,
        total_spent,
        avg_order_value,
        first_order_date,
        last_order_date,
        days_since_last_order,
        
        -- RFM Scores
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score as rfm_score,
        
        -- RFM Segment
        case
            when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
            when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
            when r_score >= 4 and f_score <= 2 then 'Recent Customers'
            when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
            when r_score <= 2 and f_score >= 4 then 'At Risk'
            when r_score <= 2 and f_score >= 2 then 'Hibernating'
            when r_score <= 2 and f_score <= 2 then 'Lost'
            else 'Other'
        end as customer_segment,
        
        -- Customer lifecycle
        case 
            when total_orders = 1 then 'New'
            when total_orders between 2 and 3 then 'Returning'
            when total_orders between 4 and 10 then 'Regular'
            when total_orders > 10 then 'VIP'
            else 'Prospect'
        end as customer_lifecycle,
        
        -- Customer value tier
        case
            when total_spent >= 5000000 then 'Platinum'
            when total_spent >= 2000000 then 'Gold'
            when total_spent >= 500000 then 'Silver'
            else 'Bronze'
        end as customer_value_tier,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from rfm_calc
)

select * from final
  );
  
[0m04:08:46.841395 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.016 seconds
[0m04:08:46.848278 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:08:46.849635 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer" rename to "dim_customer__dbt_backup"
[0m04:08:46.851553 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:46.856536 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:08:46.858692 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m04:08:46.860251 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:46.862439 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:08:46.863271 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:08:46.863984 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:08:46.866905 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:08:46.870210 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup"
[0m04:08:46.871840 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:08:46.872917 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup" cascade
[0m04:08:46.876550 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:08:46.878836 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: Close
[0m04:08:46.880308 [info ] [Thread-1 (]: 7 of 14 OK created sql table model analytics_gold.dim_customer ................. [[32mSELECT 268[0m in 0.23s]
[0m04:08:46.881619 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m04:08:46.882766 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m04:08:46.883758 [info ] [Thread-1 (]: 8 of 14 START sql table model analytics_gold.dim_payment ....................... [RUN]
[0m04:08:46.884849 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_customer, now model.ecommerce_dbt.dim_payment)
[0m04:08:46.890166 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_payment
[0m04:08:46.894052 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_payment"
[0m04:08:46.942202 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_payment
[0m04:08:46.947336 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_payment"
[0m04:08:47.022710 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:08:47.024232 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: BEGIN
[0m04:08:47.026593 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:47.041987 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m04:08:47.044209 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:08:47.046040 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Payment Dimension
-- Extracted from orders, enriched with payment grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique payment methods
unique_payments as (
    select distinct
        payment_method
    from source
    where payment_method is not null
),

enriched as (
    select
        row_number() over (order by payment_method) as payment_method_id,
        trim(payment_method) as payment_method,
        
        -- Payment method grouping
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'COD'
            when payment_method ilike '%shopee%' or payment_method ilike '%spay%' or payment_method ilike '%shopeepay%' then 'ShopeePay'
            when payment_method ilike '%momo%' then 'MoMo'
            when payment_method ilike '%zalo%' then 'ZaloPay'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Credit/Debit Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank Transfer'
            when payment_method ilike '%vnpay%' then 'VNPay'
            else 'Other'
        end as payment_group,
        
        -- Payment type
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'Cash'
            when payment_method ilike '%shopee%' or payment_method ilike '%momo%' or payment_method ilike '%zalo%' or payment_method ilike '%vnpay%' then 'E-Wallet'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank'
            else 'Other'
        end as payment_type,
        
        -- Is digital payment
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then false
            else true
        end as is_digital_payment,
        
        -- Payment key
        md5(coalesce(payment_method, 'unknown')) as payment_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_payments
)

select * from enriched
  );
  
[0m04:08:47.060594 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.013 seconds
[0m04:08:47.066846 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:08:47.068778 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment" rename to "dim_payment__dbt_backup"
[0m04:08:47.071338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:47.078914 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:08:47.080426 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp" rename to "dim_payment"
[0m04:08:47.082816 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:47.086159 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:08:47.087446 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:08:47.088517 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:08:47.091974 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:08:47.095991 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup"
[0m04:08:47.097562 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:08:47.098798 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup" cascade
[0m04:08:47.103262 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:08:47.106380 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: Close
[0m04:08:47.110842 [info ] [Thread-1 (]: 8 of 14 OK created sql table model analytics_gold.dim_payment .................. [[32mSELECT 6[0m in 0.23s]
[0m04:08:47.112818 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m04:08:47.114912 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m04:08:47.117102 [info ] [Thread-1 (]: 9 of 14 START sql table model analytics_gold.dim_shipping ...................... [RUN]
[0m04:08:47.119234 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_payment, now model.ecommerce_dbt.dim_shipping)
[0m04:08:47.122070 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_shipping
[0m04:08:47.138175 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.207051 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_shipping
[0m04:08:47.213139 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.325603 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.332384 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: BEGIN
[0m04:08:47.334670 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:47.353313 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m04:08:47.354611 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.355885 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Shipping Dimension
-- Extracted from orders, enriched with carrier grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique shipping carriers
unique_carriers as (
    select distinct
        shipping_carrier,
        shipping_method
    from source
    where shipping_carrier is not null
),

enriched as (
    select
        row_number() over (order by shipping_carrier) as shipping_id,
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        
        -- Carrier grouping/normalization
        case
            when shipping_carrier ilike '%giao hang nhanh%' or shipping_carrier ilike '%ghn%' then 'GHN'
            when shipping_carrier ilike '%giao hang tiet kiem%' or shipping_carrier ilike '%ghtk%' then 'GHTK'
            when shipping_carrier ilike '%j&t%' or shipping_carrier ilike '%jt%' then 'J&T Express'
            when shipping_carrier ilike '%shopee express%' or shipping_carrier ilike '%spx%' then 'Shopee Express'
            when shipping_carrier ilike '%viettel%' then 'Viettel Post'
            when shipping_carrier ilike '%grab%' then 'GrabExpress'
            when shipping_carrier ilike '%ninja van%' then 'Ninja Van'
            when shipping_carrier ilike '%best%' then 'BEST Express'
            else 'Other'
        end as carrier_group,
        
        -- Carrier type
        case
            when shipping_carrier ilike '%shopee%' or shipping_carrier ilike '%spx%' then 'Platform Logistics'
            when shipping_carrier ilike '%grab%' then 'On-Demand'
            else 'Third Party Logistics'
        end as carrier_type,
        
        -- Shipping key
        md5(coalesce(shipping_carrier, 'unknown')) as shipping_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_carriers
)

select * from enriched
  );
  
[0m04:08:47.367788 [debug] [Thread-1 (]: SQL status: SELECT 9 in 0.010 seconds
[0m04:08:47.379689 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.382362 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping" rename to "dim_shipping__dbt_backup"
[0m04:08:47.387107 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:47.396932 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.400910 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp" rename to "dim_shipping"
[0m04:08:47.404774 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:47.418695 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:08:47.420580 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.425460 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:08:47.436909 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m04:08:47.441623 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup"
[0m04:08:47.446253 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:08:47.450371 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup" cascade
[0m04:08:47.460064 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m04:08:47.464720 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: Close
[0m04:08:47.470498 [info ] [Thread-1 (]: 9 of 14 OK created sql table model analytics_gold.dim_shipping ................. [[32mSELECT 9[0m in 0.35s]
[0m04:08:47.474737 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m04:08:47.479282 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m04:08:47.482827 [info ] [Thread-1 (]: 10 of 14 START sql table model analytics_gold.dim_product ...................... [RUN]
[0m04:08:47.488507 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_shipping, now model.ecommerce_dbt.dim_product)
[0m04:08:47.491297 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_product
[0m04:08:47.497251 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_product"
[0m04:08:47.603174 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_product
[0m04:08:47.613979 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_product"
[0m04:08:47.751286 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:08:47.760313 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: BEGIN
[0m04:08:47.768115 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:47.793664 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m04:08:47.797051 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:08:47.802915 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Dimension
-- Business-ready product data with performance metrics



with products as (
    select * from "ecommerce_db"."analytics_silver"."slv_products"
),

-- Calculate product performance
product_stats as (
    select
        product_name,
        count(distinct order_id) as total_orders,
        sum(quantity) as total_quantity_sold,
        sum(order_total_vnd) as total_revenue,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by product_name
),

final as (
    select
        p.product_id,
        p.product_name,
        p.product_sku,
        p.variant_name,
        p.variant_sku,
        p.main_category,
        
        -- Pricing
        p.original_price,
        p.discounted_price,
        case 
            when p.original_price > 0 
            then round((1 - p.discounted_price / p.original_price) * 100, 2)
            else 0
        end as discount_percentage,
        
        -- Weight
        p.product_weight,
        
        -- Product key
        p.product_key,
        
        -- Performance metrics
        coalesce(s.total_orders, 0) as total_orders,
        coalesce(s.total_quantity_sold, 0) as total_quantity_sold,
        coalesce(s.total_revenue, 0) as total_revenue,
        coalesce(s.avg_order_value, 0) as avg_order_value,
        s.first_sold_date,
        s.last_sold_date,
        
        -- Product tier based on revenue
        case
            when s.total_revenue >= 10000000 then 'Star Product'
            when s.total_revenue >= 5000000 then 'High Performer'
            when s.total_revenue >= 1000000 then 'Moderate'
            when s.total_revenue > 0 then 'Low Performer'
            else 'No Sales'
        end as product_tier,
        
        -- Velocity
        case 
            when s.total_quantity_sold >= 50 then 'Fast Moving'
            when s.total_quantity_sold >= 20 then 'Medium Moving'
            when s.total_quantity_sold >= 5 then 'Slow Moving'
            else 'Very Slow'
        end as sales_velocity,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from products p
    left join product_stats s on p.product_name = s.product_name
)

select * from final
  );
  
[0m04:08:47.832725 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.023 seconds
[0m04:08:47.840671 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:08:47.849206 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product" rename to "dim_product__dbt_backup"
[0m04:08:47.851906 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:47.864960 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:08:47.878505 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp" rename to "dim_product"
[0m04:08:47.892658 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:47.904967 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:08:47.915966 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:08:47.928469 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:08:47.937850 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:08:47.949708 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_product__dbt_backup"
[0m04:08:47.954337 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:08:47.962358 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_product__dbt_backup" cascade
[0m04:08:47.974222 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m04:08:47.980853 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: Close
[0m04:08:47.985406 [info ] [Thread-1 (]: 10 of 14 OK created sql table model analytics_gold.dim_product ................. [[32mSELECT 236[0m in 0.50s]
[0m04:08:47.988992 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m04:08:47.995409 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m04:08:47.998534 [info ] [Thread-1 (]: 11 of 14 START sql table model analytics_gold.fct_orders ....................... [RUN]
[0m04:08:48.003115 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_product, now model.ecommerce_dbt.fct_orders)
[0m04:08:48.006706 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.fct_orders
[0m04:08:48.016824 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.fct_orders"
[0m04:08:48.131747 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.fct_orders
[0m04:08:48.142677 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.fct_orders"
[0m04:08:48.286478 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:08:48.290253 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: BEGIN
[0m04:08:48.292663 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:48.314686 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m04:08:48.317338 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:08:48.321568 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Fact Orders
-- Main fact table - Star Schema center
-- Joins all dimensions with measures



with orders as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

customers as (
    select customer_id, buyer_username, customer_key, region, customer_segment
    from "ecommerce_db"."analytics_gold"."dim_customer"
),

products as (
    select product_id, product_name, product_key, main_category, product_tier
    from "ecommerce_db"."analytics_gold"."dim_product"
),

dates as (
    select date_key, date, is_double_day_sale, sale_event_name
    from "ecommerce_db"."analytics_gold"."dim_date"
),

shipping as (
    select shipping_id, shipping_carrier, shipping_key, carrier_group
    from "ecommerce_db"."analytics_gold"."dim_shipping"
),

payment as (
    select payment_method_id, payment_method, payment_key, payment_group
    from "ecommerce_db"."analytics_gold"."dim_payment"
),

-- Customer order sequence
order_sequence as (
    select
        order_id,
        buyer_username,
        row_number() over (
            partition by buyer_username 
            order by order_date
        ) as customer_order_seq
    from orders
),

fact_orders as (
    select
        -- Primary key
        o.order_id,
        
        -- Dimension keys (foreign keys)
        c.customer_id,
        p.product_id,
        d.date_key as order_date_key,
        s.shipping_id,
        pm.payment_method_id,
        
        -- Surrogate keys (for BI tools)
        c.customer_key,
        p.product_key,
        s.shipping_key,
        pm.payment_key,
        
        -- Natural keys (for reference)
        o.package_id,
        o.tracking_number,
        o.buyer_username,
        
        -- Date dimensions
        o.order_date,
        o.expected_delivery_date,
        o.actual_delivery_date,
        o.order_completed_date,
        o.payment_date,
        
        -- Delivery metrics
        case
            when o.actual_delivery_date is not null and o.order_date is not null
            then extract(day from o.actual_delivery_date - o.order_date)
            else null
        end as delivery_days,
        
        case
            when o.actual_delivery_date is not null and o.expected_delivery_date is not null
            then case 
                when o.actual_delivery_date <= o.expected_delivery_date then 'On Time'
                else 'Late'
            end
            else 'Unknown'
        end as delivery_status,
        
        -- Order status
        o.order_status,
        o.order_type,
        o.return_status,
        
        -- Product details (denormalized for performance)
        o.product_name,
        o.variant_name,
        o.product_weight,
        p.main_category,
        
        -- Quantity and pricing (MEASURES)
        o.quantity,
        o.original_price,
        o.discount_price,
        o.total_product_price,
        o.order_total_vnd,
        
        -- Discount breakdown (MEASURES)
        o.seller_discount,
        o.shopee_discount,
        o.shop_voucher,
        o.shopee_voucher,
        o.coins_cashback,
        o.total_discount,
        
        -- Shipping costs (MEASURES)
        o.shipping_fee_estimated,
        o.shipping_fee_paid,
        o.shipping_subsidy,
        
        -- Payment (MEASURES)
        o.total_paid,
        o.payment_method,
        
        -- Fees (MEASURES)
        o.fixed_fee,
        o.service_fee,
        o.payment_fee,
        o.deposit,
        
        -- Calculated measures
        o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee as net_revenue,
        
        case
            when o.original_price > 0 
            then round(((o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee) / (o.original_price * o.quantity)) * 100, 2)
            else 0
        end as profit_margin_pct,
        
        -- Order value tier
        case
            when o.order_total_vnd >= 1000000 then 'Premium (1M+)'
            when o.order_total_vnd >= 500000 then 'High (500K-1M)'
            when o.order_total_vnd >= 200000 then 'Medium (200K-500K)'
            when o.order_total_vnd >= 100000 then 'Low (100K-200K)'
            else 'Micro (<100K)'
        end as order_value_tier,
        
        -- Customer location (denormalized)
        o.province,
        o.district,
        c.region,
        
        -- Shipping info (denormalized)
        o.shipping_carrier,
        s.carrier_group,
        
        -- Payment info (denormalized)
        pm.payment_group,
        
        -- Customer order sequence
        seq.customer_order_seq,
        case when seq.customer_order_seq = 1 then 'New' else 'Repeat' end as new_vs_repeat,
        
        -- Sale event (denormalized from date)
        d.is_double_day_sale,
        d.sale_event_name,
        
        -- Flags
        o.is_bestseller,
        case when o.return_status is not null and o.return_status != '' then true else false end as is_returned,
        case when o.order_status in ('Ho√†n th√†nh', 'complete', 'completed', 'Completed') then true else false end as is_completed,
        case when o.order_status in ('ƒê√£ h·ªßy', 'cancelled', 'Cancelled', 'cancel') then true else false end as is_cancelled,
        
        -- Metadata
        o.source_file,
        o.source_loaded_at,
        current_timestamp as _gold_loaded_at
        
    from orders o
    left join customers c on o.buyer_username = c.buyer_username
    left join products p on o.product_name = p.product_name
    left join dates d on cast(o.order_date as date) = d.date
    left join shipping s on o.shipping_carrier = s.shipping_carrier
    left join payment pm on o.payment_method = pm.payment_method
    left join order_sequence seq on o.order_id = seq.order_id
)

select * from fact_orders
  );
  
[0m04:08:48.810069 [debug] [Thread-1 (]: SQL status: SELECT 25442 in 0.484 seconds
[0m04:08:48.816287 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:08:48.819733 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders" rename to "fct_orders__dbt_backup"
[0m04:08:48.823248 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:48.830912 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:08:48.832829 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp" rename to "fct_orders"
[0m04:08:48.835363 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:48.840882 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m04:08:48.844363 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:08:48.847009 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m04:08:48.863923 [debug] [Thread-1 (]: SQL status: COMMIT in 0.014 seconds
[0m04:08:48.872040 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup"
[0m04:08:48.875084 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:08:48.877422 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
drop table if exists "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup" cascade
[0m04:08:48.896096 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.016 seconds
[0m04:08:48.901308 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: Close
[0m04:08:48.905380 [info ] [Thread-1 (]: 11 of 14 OK created sql table model analytics_gold.fct_orders .................. [[32mSELECT 25442[0m in 0.90s]
[0m04:08:48.908668 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m04:08:48.910854 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m04:08:48.912742 [info ] [Thread-1 (]: 12 of 14 START sql table model analytics_gold.agg_customer_summary ............. [RUN]
[0m04:08:48.914985 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.fct_orders, now model.ecommerce_dbt.agg_customer_summary)
[0m04:08:48.916190 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_customer_summary
[0m04:08:48.923461 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_customer_summary"
[0m04:08:48.997819 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_customer_summary
[0m04:08:49.005538 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_customer_summary"
[0m04:08:49.092047 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:08:49.096385 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: BEGIN
[0m04:08:49.097803 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:49.108720 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:08:49.110604 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:08:49.112167 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Summary Aggregate
-- Customer-level aggregated metrics with RFM



with customer_orders as (
    select
        buyer_username,
        customer_id,
        region,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Quantity
        sum(quantity) as total_items_purchased,
        
        -- Revenue
        sum(order_total_vnd) as total_spent,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Time metrics
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order,
        
        -- Product diversity
        count(distinct product_name) as unique_products_ordered,
        count(distinct main_category) as unique_categories,
        
        -- Shipping preferences
        mode() within group (order by carrier_group) as preferred_carrier,
        mode() within group (order by payment_group) as preferred_payment
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where buyer_username is not null
    group by 1, 2, 3
),

with_rfm as (
    select
        *,
        
        -- RFM Scores
        ntile(5) over (order by days_since_last_order desc nulls last) as r_score,
        ntile(5) over (order by total_orders asc nulls first) as f_score,
        ntile(5) over (order by total_spent asc nulls first) as m_score
        
    from customer_orders
    where total_orders > 0
)

select
    buyer_username,
    customer_id,
    region,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    total_items_purchased,
    
    -- Revenue metrics
    total_spent,
    total_net_revenue,
    avg_order_value,
    
    -- Time metrics
    first_order_date,
    last_order_date,
    days_since_last_order,
    
    -- Tenure (days as customer)
    current_date - first_order_date::date as customer_tenure_days,
    
    -- Frequency (orders per month)
    case 
        when current_date - first_order_date::date > 30 
        then round(total_orders * 30.0 / (current_date - first_order_date::date), 2)
        else total_orders
    end as orders_per_month,
    
    -- Product diversity
    unique_products_ordered,
    unique_categories,
    
    -- Preferences
    preferred_carrier,
    preferred_payment,
    
    -- RFM
    r_score,
    f_score,
    m_score,
    r_score * 100 + f_score * 10 + m_score as rfm_score,
    
    -- RFM Segment
    case
        when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
        when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
        when r_score >= 4 and f_score <= 2 then 'Recent Customers'
        when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
        when r_score <= 2 and f_score >= 4 then 'At Risk'
        when r_score <= 2 and f_score >= 2 then 'Hibernating'
        when r_score <= 2 and f_score <= 2 then 'Lost'
        else 'Other'
    end as customer_segment,
    
    -- Customer lifecycle
    case 
        when total_orders = 1 then 'New'
        when total_orders between 2 and 3 then 'Returning'
        when total_orders between 4 and 10 then 'Regular'
        when total_orders > 10 then 'VIP'
    end as customer_lifecycle,
    
    -- Value tier
    case
        when total_spent >= 5000000 then 'Platinum'
        when total_spent >= 2000000 then 'Gold'
        when total_spent >= 500000 then 'Silver'
        else 'Bronze'
    end as customer_value_tier,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from with_rfm
order by total_spent desc
  );
  
[0m04:08:49.232804 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.119 seconds
[0m04:08:49.236851 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:08:49.238938 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp" rename to "agg_customer_summary"
[0m04:08:49.243351 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:49.248090 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m04:08:49.250421 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:08:49.251538 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m04:08:49.255029 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:08:49.258343 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup"
[0m04:08:49.260033 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:08:49.261057 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup" cascade
[0m04:08:49.262869 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m04:08:49.265992 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: Close
[0m04:08:49.270004 [info ] [Thread-1 (]: 12 of 14 OK created sql table model analytics_gold.agg_customer_summary ........ [[32mSELECT 268[0m in 0.35s]
[0m04:08:49.273376 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m04:08:49.276156 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m04:08:49.277687 [info ] [Thread-1 (]: 13 of 14 START sql table model analytics_gold.agg_daily_sales .................. [RUN]
[0m04:08:49.278763 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_customer_summary, now model.ecommerce_dbt.agg_daily_sales)
[0m04:08:49.279765 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_daily_sales
[0m04:08:49.284153 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_daily_sales"
[0m04:08:49.366075 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_daily_sales
[0m04:08:49.381203 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_daily_sales"
[0m04:08:49.505344 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:08:49.515470 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: BEGIN
[0m04:08:49.519690 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:49.531738 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:08:49.533011 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:08:49.534154 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Daily Sales Aggregate
-- Daily sales metrics for dashboards



with daily_orders as (
    select
        cast(order_date as date) as order_date,
        order_date_key,
        is_double_day_sale,
        sale_event_name,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_cancelled then order_id end) as cancelled_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        count(distinct case when new_vs_repeat = 'Repeat' then buyer_username end) as repeat_customers,
        
        -- Product counts
        count(distinct product_name) as unique_products,
        sum(quantity) as total_quantity,
        
        -- Revenue metrics
        sum(order_total_vnd) as gross_revenue,
        sum(net_revenue) as net_revenue,
        sum(total_discount) as total_discount,
        sum(shipping_fee_paid) as total_shipping,
        
        -- Fee breakdown
        sum(fixed_fee) as total_fixed_fee,
        sum(service_fee) as total_service_fee,
        sum(payment_fee) as total_payment_fee,
        
        -- Averages
        avg(order_total_vnd) as avg_order_value,
        avg(quantity) as avg_items_per_order,
        avg(delivery_days) as avg_delivery_days,
        
        -- By order value tier
        count(distinct case when order_value_tier = 'Premium (1M+)' then order_id end) as premium_orders,
        count(distinct case when order_value_tier = 'Micro (<100K)' then order_id end) as micro_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    group by 1, 2, 3, 4
)

select
    d.*,
    
    -- Completion rate
    case 
        when total_orders > 0 
        then round(completed_orders * 100.0 / total_orders, 2)
        else 0 
    end as completion_rate_pct,
    
    -- Cancellation rate
    case 
        when total_orders > 0 
        then round(cancelled_orders * 100.0 / total_orders, 2)
        else 0 
    end as cancellation_rate_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- New customer rate
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from daily_orders d
order by order_date desc
  );
  
[0m04:08:49.647132 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.111 seconds
[0m04:08:49.654332 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:08:49.658928 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp" rename to "agg_daily_sales"
[0m04:08:49.662137 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:49.674759 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m04:08:49.680984 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:08:49.688881 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m04:08:49.694828 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:08:49.701468 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup"
[0m04:08:49.706916 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:08:49.711285 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup" cascade
[0m04:08:49.719945 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m04:08:49.730403 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: Close
[0m04:08:49.738999 [info ] [Thread-1 (]: 13 of 14 OK created sql table model analytics_gold.agg_daily_sales ............. [[32mSELECT 111[0m in 0.46s]
[0m04:08:49.746962 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m04:08:49.750575 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m04:08:49.755611 [info ] [Thread-1 (]: 14 of 14 START sql table model analytics_gold.agg_product_performance .......... [RUN]
[0m04:08:49.762835 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_daily_sales, now model.ecommerce_dbt.agg_product_performance)
[0m04:08:49.767863 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_product_performance
[0m04:08:49.777957 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_product_performance"
[0m04:08:49.950619 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_product_performance
[0m04:08:49.961052 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_product_performance"
[0m04:08:50.094845 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:08:50.099034 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: BEGIN
[0m04:08:50.108397 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:08:50.125510 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m04:08:50.131687 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:08:50.135551 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Performance Aggregate
-- Product-level aggregated metrics



with product_orders as (
    select
        product_name,
        product_id,
        main_category,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        
        -- Quantity
        sum(quantity) as total_quantity_sold,
        avg(quantity) as avg_quantity_per_order,
        
        -- Revenue
        sum(order_total_vnd) as total_revenue,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Pricing
        avg(original_price) as avg_original_price,
        avg(discount_price) as avg_discount_price,
        sum(total_discount) as total_discount_given,
        
        -- Time metrics
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date,
        current_date - max(order_date)::date as days_since_last_sale,
        
        -- Geography
        mode() within group (order by region) as top_region,
        
        -- Sale events
        count(distinct case when is_double_day_sale then order_id end) as sale_event_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where product_name is not null
    group by 1, 2, 3
)

select
    product_name,
    product_id,
    main_category,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    
    -- Customer metrics
    unique_customers,
    new_customers,
    
    -- Quantity metrics
    total_quantity_sold,
    avg_quantity_per_order,
    
    -- Revenue metrics
    total_revenue,
    total_net_revenue,
    avg_order_value,
    
    -- Pricing metrics
    avg_original_price,
    avg_discount_price,
    total_discount_given,
    
    -- Discount percentage
    case 
        when avg_original_price > 0 
        then round((1 - avg_discount_price / avg_original_price) * 100, 2)
        else 0 
    end as avg_discount_pct,
    
    -- Time metrics
    first_sold_date,
    last_sold_date,
    days_since_last_sale,
    
    -- Selling period (days)
    last_sold_date::date - first_sold_date::date as selling_period_days,
    
    -- Sales velocity (units per day)
    case 
        when last_sold_date::date - first_sold_date::date > 0 
        then round(total_quantity_sold * 1.0 / (last_sold_date::date - first_sold_date::date + 1), 2)
        else total_quantity_sold
    end as daily_sales_velocity,
    
    -- Top region
    top_region,
    
    -- Sale event performance
    sale_event_orders,
    case 
        when total_orders > 0 
        then round(sale_event_orders * 100.0 / total_orders, 2)
        else 0 
    end as sale_event_order_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Customer acquisition
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_pct,
    
    -- Product tier
    case
        when total_revenue >= 10000000 then 'Star Product'
        when total_revenue >= 5000000 then 'High Performer'
        when total_revenue >= 1000000 then 'Moderate'
        when total_revenue > 0 then 'Low Performer'
        else 'No Sales'
    end as product_tier,
    
    -- Sales velocity category
    case 
        when total_quantity_sold >= 50 then 'Fast Moving'
        when total_quantity_sold >= 20 then 'Medium Moving'
        when total_quantity_sold >= 5 then 'Slow Moving'
        else 'Very Slow'
    end as sales_velocity_category,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from product_orders
order by total_revenue desc
  );
  
[0m04:08:50.290845 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.150 seconds
[0m04:08:50.297298 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:08:50.302492 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp" rename to "agg_product_performance"
[0m04:08:50.312369 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:08:50.323333 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m04:08:50.326280 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:08:50.327283 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m04:08:50.330251 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:08:50.340158 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup"
[0m04:08:50.342449 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:08:50.345110 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup" cascade
[0m04:08:50.348072 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m04:08:50.354215 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: Close
[0m04:08:50.357333 [info ] [Thread-1 (]: 14 of 14 OK created sql table model analytics_gold.agg_product_performance ..... [[32mSELECT 236[0m in 0.59s]
[0m04:08:50.361756 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m04:08:50.367938 [debug] [MainThread]: Using postgres connection "master"
[0m04:08:50.370944 [debug] [MainThread]: On master: BEGIN
[0m04:08:50.373229 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:08:50.385438 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m04:08:50.389072 [debug] [MainThread]: On master: COMMIT
[0m04:08:50.391184 [debug] [MainThread]: Using postgres connection "master"
[0m04:08:50.392720 [debug] [MainThread]: On master: COMMIT
[0m04:08:50.394906 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:08:50.396109 [debug] [MainThread]: On master: Close
[0m04:08:50.397961 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:08:50.399077 [debug] [MainThread]: Connection 'model.ecommerce_dbt.agg_product_performance' was properly closed.
[0m04:08:50.401236 [info ] [MainThread]: 
[0m04:08:50.403246 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 6.16 seconds (6.16s).
[0m04:08:50.406880 [debug] [MainThread]: Command end result
[0m04:08:50.722603 [info ] [MainThread]: 
[0m04:08:50.723751 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:08:50.724738 [info ] [MainThread]: 
[0m04:08:50.725725 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
[0m04:08:50.728026 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.526809, "process_user_time": 5.410591, "process_kernel_time": 0.576182, "process_mem_max_rss": "125392", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:08:50.729258 [debug] [MainThread]: Command `dbt run` succeeded at 04:08:50.729097 after 11.53 seconds
[0m04:08:50.730660 [debug] [MainThread]: Flushing usage events
[0m04:09:14.994355 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 04:09:15.003594 | 185bc2ce-063c-4013-9321-f7ba17d552b1 ==============================
[0m04:09:15.003594 [info ] [MainThread]: Running with dbt=1.8.0
[0m04:09:15.005864 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:09:15.345195 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m04:09:15.383940 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m04:09:15.556704 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m04:09:18.468700 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m04:09:19.333701 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m04:09:19.342047 [info ] [MainThread]: 
[0m04:09:19.345949 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:09:19.361402 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m04:09:19.438324 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:09:19.441181 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:09:19.442312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:09:19.477762 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.035 seconds
[0m04:09:19.480968 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:09:19.486669 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:09:19.488029 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:09:19.489200 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:19.502578 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.013 seconds
[0m04:09:19.505892 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:09:19.510600 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m04:09:19.511927 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m04:09:19.513039 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:19.527216 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.014 seconds
[0m04:09:19.529757 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m04:09:19.534243 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics_bronze)
[0m04:09:19.551133 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:09:19.553628 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m04:09:19.555304 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:19.572301 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m04:09:19.574312 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:09:19.576208 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m04:09:19.585897 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m04:09:19.592389 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m04:09:19.597877 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m04:09:19.602002 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics)
[0m04:09:19.610851 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:09:19.615224 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m04:09:19.618836 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:19.636185 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m04:09:19.639617 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:09:19.642246 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m04:09:19.653364 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m04:09:19.657862 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m04:09:19.660861 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m04:09:19.663351 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_silver)
[0m04:09:19.666909 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:09:19.668527 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m04:09:19.670003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:19.681576 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m04:09:19.682649 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:09:19.684002 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m04:09:19.688138 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.003 seconds
[0m04:09:19.692068 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m04:09:19.693591 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m04:09:19.697626 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics_gold)
[0m04:09:19.701045 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:09:19.702329 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m04:09:19.703746 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:19.714794 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m04:09:19.716266 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:09:19.718730 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m04:09:19.724040 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m04:09:19.730048 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m04:09:19.732554 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m04:09:19.742825 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:19.744331 [debug] [MainThread]: On master: BEGIN
[0m04:09:19.745239 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:09:19.757623 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m04:09:19.758929 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:19.759914 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:09:19.766903 [debug] [MainThread]: SQL status: SELECT 1 in 0.006 seconds
[0m04:09:19.771269 [debug] [MainThread]: On master: ROLLBACK
[0m04:09:19.773477 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:19.775284 [debug] [MainThread]: On master: BEGIN
[0m04:09:19.778469 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:09:19.780445 [debug] [MainThread]: On master: COMMIT
[0m04:09:19.781389 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:19.782879 [debug] [MainThread]: On master: COMMIT
[0m04:09:19.784067 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:09:19.785410 [debug] [MainThread]: On master: Close
[0m04:09:19.787761 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:09:19.789083 [info ] [MainThread]: 
[0m04:09:19.795665 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m04:09:19.797080 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m04:09:19.798277 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now model.ecommerce_dbt.brz_raw_orders)
[0m04:09:19.799611 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m04:09:19.809314 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:19.835539 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m04:09:19.882977 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:19.922632 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:19.924054 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m04:09:19.926059 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:19.942306 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:09:19.945222 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:19.947682 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    -- BRONZE LAYER: Raw Orders
-- 1:1 copy from source with metadata columns
-- No transformations, preserving original data



select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m04:09:19.959311 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m04:09:19.973736 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:19.978302 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m04:09:19.985347 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m04:09:19.999843 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:20.002460 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m04:09:20.004212 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.041627 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:09:20.043260 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:20.044306 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m04:09:20.048951 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:09:20.063689 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m04:09:20.070538 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m04:09:20.072003 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m04:09:20.075602 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m04:09:20.082430 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m04:09:20.085950 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.29s]
[0m04:09:20.087777 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m04:09:20.092559 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m04:09:20.096923 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m04:09:20.098958 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m04:09:20.100585 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m04:09:20.106498 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m04:09:20.140681 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m04:09:20.180265 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m04:09:20.218705 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:09:20.220187 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m04:09:20.222301 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:20.232677 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m04:09:20.235369 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:09:20.239889 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m04:09:20.251587 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.010 seconds
[0m04:09:20.260937 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:09:20.262056 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m04:09:20.264153 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.269556 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:09:20.271699 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m04:09:20.274020 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:09:20.283821 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:09:20.284974 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:09:20.287729 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m04:09:20.290992 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m04:09:20.295510 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m04:09:20.301836 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m04:09:20.304415 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m04:09:20.309763 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:09:20.313127 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m04:09:20.315565 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 268[0m in 0.22s]
[0m04:09:20.318435 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m04:09:20.321050 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m04:09:20.324574 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m04:09:20.326748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m04:09:20.331219 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m04:09:20.341152 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m04:09:20.379456 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m04:09:20.386292 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m04:09:20.412027 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:09:20.414413 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m04:09:20.416215 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:20.436063 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m04:09:20.438108 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:09:20.440542 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m04:09:20.453545 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.010 seconds
[0m04:09:20.458526 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:09:20.460754 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m04:09:20.463804 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.473337 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:09:20.478638 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m04:09:20.483331 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.491093 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:09:20.493659 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:09:20.496108 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m04:09:20.499724 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:09:20.508227 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m04:09:20.510357 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m04:09:20.514114 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m04:09:20.520607 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m04:09:20.526731 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m04:09:20.528393 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.20s]
[0m04:09:20.530098 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m04:09:20.531553 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m04:09:20.533050 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m04:09:20.535317 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m04:09:20.536895 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m04:09:20.544203 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m04:09:20.580142 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m04:09:20.587373 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m04:09:20.616800 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:09:20.619593 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m04:09:20.621409 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:20.637174 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:09:20.639941 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:09:20.642550 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        trim(buyer_username) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m04:09:20.673787 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.028 seconds
[0m04:09:20.678565 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:09:20.686274 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders" rename to "slv_orders__dbt_backup"
[0m04:09:20.689452 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.696137 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:09:20.697700 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp" rename to "slv_orders"
[0m04:09:20.701177 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.709866 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:09:20.712402 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:09:20.713989 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m04:09:20.719801 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m04:09:20.727185 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup"
[0m04:09:20.729123 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m04:09:20.730322 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup" cascade
[0m04:09:20.736776 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m04:09:20.741830 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m04:09:20.745789 [info ] [Thread-1 (]: 4 of 14 OK created sql table model analytics_silver.slv_orders ................. [[32mSELECT 516[0m in 0.21s]
[0m04:09:20.750097 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m04:09:20.752715 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m04:09:20.755643 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m04:09:20.758452 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m04:09:20.764368 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m04:09:20.777160 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m04:09:20.827152 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m04:09:20.838856 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m04:09:20.874302 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:09:20.875717 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m04:09:20.876935 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:20.888509 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:09:20.890158 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:09:20.891609 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders
unique_products as (
    select distinct
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m04:09:20.905648 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.013 seconds
[0m04:09:20.910729 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:09:20.911948 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products" rename to "slv_products__dbt_backup"
[0m04:09:20.913720 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.918990 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:09:20.920459 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m04:09:20.922516 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:20.926504 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:09:20.927779 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:09:20.928868 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m04:09:20.931986 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:09:20.936398 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m04:09:20.938488 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m04:09:20.939835 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m04:09:20.946723 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m04:09:20.951903 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m04:09:20.953980 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 236[0m in 0.20s]
[0m04:09:20.956241 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m04:09:20.958607 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m04:09:20.962596 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m04:09:20.970647 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m04:09:20.972329 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m04:09:20.978298 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m04:09:21.006714 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m04:09:21.015616 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m04:09:21.041311 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:09:21.042879 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m04:09:21.044466 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:21.055814 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:09:21.056917 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:09:21.058237 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m04:09:21.065747 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.006 seconds
[0m04:09:21.072874 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:09:21.074310 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m04:09:21.076579 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.082474 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:09:21.084028 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m04:09:21.085749 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.088429 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:09:21.089529 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:09:21.090535 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m04:09:21.092933 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m04:09:21.096825 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m04:09:21.099229 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m04:09:21.100382 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m04:09:21.104001 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:09:21.106883 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m04:09:21.108839 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.14s]
[0m04:09:21.110589 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m04:09:21.111831 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m04:09:21.113263 [info ] [Thread-1 (]: 7 of 14 START sql table model analytics_gold.dim_customer ...................... [RUN]
[0m04:09:21.114751 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_date, now model.ecommerce_dbt.dim_customer)
[0m04:09:21.116027 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_customer
[0m04:09:21.121559 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_customer"
[0m04:09:21.146721 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_customer
[0m04:09:21.153038 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_customer"
[0m04:09:21.179765 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:09:21.181333 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: BEGIN
[0m04:09:21.182463 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:21.194718 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:09:21.196324 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:09:21.197802 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Dimension
-- Business-ready customer data with RFM segmentation



with customers as (
    select * from "ecommerce_db"."analytics_silver"."slv_customers"
),

-- Calculate order aggregates per customer
order_stats as (
    select
        buyer_username,
        count(distinct order_id) as total_orders,
        sum(order_total_vnd) as total_spent,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by buyer_username
),

-- RFM calculation
rfm_calc as (
    select
        c.*,
        coalesce(o.total_orders, 0) as total_orders,
        coalesce(o.total_spent, 0) as total_spent,
        coalesce(o.avg_order_value, 0) as avg_order_value,
        o.first_order_date,
        o.last_order_date,
        coalesce(o.days_since_last_order, 999) as days_since_last_order,
        
        -- RFM Scores (1-5 scale)
        ntile(5) over (order by coalesce(o.days_since_last_order, 999) desc) as r_score,
        ntile(5) over (order by coalesce(o.total_orders, 0)) as f_score,
        ntile(5) over (order by coalesce(o.total_spent, 0)) as m_score
        
    from customers c
    left join order_stats o on c.buyer_username = o.buyer_username
),

final as (
    select
        customer_id,
        buyer_username,
        recipient_name,
        phone_number,
        
        -- Geography
        province,
        district,
        ward,
        shipping_address,
        country,
        region,
        
        -- Customer key
        customer_key,
        
        -- Order metrics
        total_orders,
        total_spent,
        avg_order_value,
        first_order_date,
        last_order_date,
        days_since_last_order,
        
        -- RFM Scores
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score as rfm_score,
        
        -- RFM Segment
        case
            when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
            when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
            when r_score >= 4 and f_score <= 2 then 'Recent Customers'
            when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
            when r_score <= 2 and f_score >= 4 then 'At Risk'
            when r_score <= 2 and f_score >= 2 then 'Hibernating'
            when r_score <= 2 and f_score <= 2 then 'Lost'
            else 'Other'
        end as customer_segment,
        
        -- Customer lifecycle
        case 
            when total_orders = 1 then 'New'
            when total_orders between 2 and 3 then 'Returning'
            when total_orders between 4 and 10 then 'Regular'
            when total_orders > 10 then 'VIP'
            else 'Prospect'
        end as customer_lifecycle,
        
        -- Customer value tier
        case
            when total_spent >= 5000000 then 'Platinum'
            when total_spent >= 2000000 then 'Gold'
            when total_spent >= 500000 then 'Silver'
            else 'Bronze'
        end as customer_value_tier,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from rfm_calc
)

select * from final
  );
  
[0m04:09:21.210487 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.011 seconds
[0m04:09:21.214740 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:09:21.216278 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer" rename to "dim_customer__dbt_backup"
[0m04:09:21.217875 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.222008 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:09:21.223368 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m04:09:21.225218 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.230093 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:09:21.232018 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:09:21.233123 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m04:09:21.235922 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:09:21.240552 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup"
[0m04:09:21.242813 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m04:09:21.244155 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup" cascade
[0m04:09:21.248965 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:09:21.252129 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: Close
[0m04:09:21.254465 [info ] [Thread-1 (]: 7 of 14 OK created sql table model analytics_gold.dim_customer ................. [[32mSELECT 268[0m in 0.14s]
[0m04:09:21.256931 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m04:09:21.258201 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m04:09:21.259712 [info ] [Thread-1 (]: 8 of 14 START sql table model analytics_gold.dim_payment ....................... [RUN]
[0m04:09:21.260903 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_customer, now model.ecommerce_dbt.dim_payment)
[0m04:09:21.262805 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_payment
[0m04:09:21.269196 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_payment"
[0m04:09:21.317936 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_payment
[0m04:09:21.325960 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_payment"
[0m04:09:21.385300 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:09:21.388573 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: BEGIN
[0m04:09:21.390195 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:21.403626 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:09:21.406467 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:09:21.408218 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Payment Dimension
-- Extracted from orders, enriched with payment grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique payment methods
unique_payments as (
    select distinct
        payment_method
    from source
    where payment_method is not null
),

enriched as (
    select
        row_number() over (order by payment_method) as payment_method_id,
        trim(payment_method) as payment_method,
        
        -- Payment method grouping
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'COD'
            when payment_method ilike '%shopee%' or payment_method ilike '%spay%' or payment_method ilike '%shopeepay%' then 'ShopeePay'
            when payment_method ilike '%momo%' then 'MoMo'
            when payment_method ilike '%zalo%' then 'ZaloPay'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Credit/Debit Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank Transfer'
            when payment_method ilike '%vnpay%' then 'VNPay'
            else 'Other'
        end as payment_group,
        
        -- Payment type
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'Cash'
            when payment_method ilike '%shopee%' or payment_method ilike '%momo%' or payment_method ilike '%zalo%' or payment_method ilike '%vnpay%' then 'E-Wallet'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank'
            else 'Other'
        end as payment_type,
        
        -- Is digital payment
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then false
            else true
        end as is_digital_payment,
        
        -- Payment key
        md5(coalesce(payment_method, 'unknown')) as payment_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_payments
)

select * from enriched
  );
  
[0m04:09:21.429868 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.020 seconds
[0m04:09:21.436370 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:09:21.438504 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment" rename to "dim_payment__dbt_backup"
[0m04:09:21.440622 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.450247 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:09:21.453200 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp" rename to "dim_payment"
[0m04:09:21.456980 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.460489 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:09:21.461698 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:09:21.462733 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m04:09:21.466080 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m04:09:21.470880 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup"
[0m04:09:21.472860 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m04:09:21.474182 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup" cascade
[0m04:09:21.479493 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m04:09:21.483341 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: Close
[0m04:09:21.485967 [info ] [Thread-1 (]: 8 of 14 OK created sql table model analytics_gold.dim_payment .................. [[32mSELECT 6[0m in 0.22s]
[0m04:09:21.488488 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m04:09:21.490249 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m04:09:21.491949 [info ] [Thread-1 (]: 9 of 14 START sql table model analytics_gold.dim_shipping ...................... [RUN]
[0m04:09:21.493515 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_payment, now model.ecommerce_dbt.dim_shipping)
[0m04:09:21.495398 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_shipping
[0m04:09:21.502208 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.534403 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_shipping
[0m04:09:21.541115 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.568810 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.571505 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: BEGIN
[0m04:09:21.572944 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:21.582570 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m04:09:21.584037 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.585115 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Shipping Dimension
-- Extracted from orders, enriched with carrier grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique shipping carriers
unique_carriers as (
    select distinct
        shipping_carrier,
        shipping_method
    from source
    where shipping_carrier is not null
),

enriched as (
    select
        row_number() over (order by shipping_carrier) as shipping_id,
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        
        -- Carrier grouping/normalization
        case
            when shipping_carrier ilike '%giao hang nhanh%' or shipping_carrier ilike '%ghn%' then 'GHN'
            when shipping_carrier ilike '%giao hang tiet kiem%' or shipping_carrier ilike '%ghtk%' then 'GHTK'
            when shipping_carrier ilike '%j&t%' or shipping_carrier ilike '%jt%' then 'J&T Express'
            when shipping_carrier ilike '%shopee express%' or shipping_carrier ilike '%spx%' then 'Shopee Express'
            when shipping_carrier ilike '%viettel%' then 'Viettel Post'
            when shipping_carrier ilike '%grab%' then 'GrabExpress'
            when shipping_carrier ilike '%ninja van%' then 'Ninja Van'
            when shipping_carrier ilike '%best%' then 'BEST Express'
            else 'Other'
        end as carrier_group,
        
        -- Carrier type
        case
            when shipping_carrier ilike '%shopee%' or shipping_carrier ilike '%spx%' then 'Platform Logistics'
            when shipping_carrier ilike '%grab%' then 'On-Demand'
            else 'Third Party Logistics'
        end as carrier_type,
        
        -- Shipping key
        md5(coalesce(shipping_carrier, 'unknown')) as shipping_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_carriers
)

select * from enriched
  );
  
[0m04:09:21.592534 [debug] [Thread-1 (]: SQL status: SELECT 9 in 0.006 seconds
[0m04:09:21.597882 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.598922 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping" rename to "dim_shipping__dbt_backup"
[0m04:09:21.600251 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:09:21.604131 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.605028 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp" rename to "dim_shipping"
[0m04:09:21.606311 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:09:21.609295 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:09:21.610405 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.611337 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m04:09:21.613567 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m04:09:21.617039 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup"
[0m04:09:21.618403 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m04:09:21.619389 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup" cascade
[0m04:09:21.622801 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m04:09:21.625462 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: Close
[0m04:09:21.628226 [info ] [Thread-1 (]: 9 of 14 OK created sql table model analytics_gold.dim_shipping ................. [[32mSELECT 9[0m in 0.13s]
[0m04:09:21.630146 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m04:09:21.631484 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m04:09:21.633277 [info ] [Thread-1 (]: 10 of 14 START sql table model analytics_gold.dim_product ...................... [RUN]
[0m04:09:21.634496 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_shipping, now model.ecommerce_dbt.dim_product)
[0m04:09:21.635349 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_product
[0m04:09:21.640176 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_product"
[0m04:09:21.666118 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_product
[0m04:09:21.670800 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_product"
[0m04:09:21.702673 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:09:21.703933 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: BEGIN
[0m04:09:21.704783 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:21.712374 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m04:09:21.713742 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:09:21.715428 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Dimension
-- Business-ready product data with performance metrics



with products as (
    select * from "ecommerce_db"."analytics_silver"."slv_products"
),

-- Calculate product performance
product_stats as (
    select
        product_name,
        count(distinct order_id) as total_orders,
        sum(quantity) as total_quantity_sold,
        sum(order_total_vnd) as total_revenue,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by product_name
),

final as (
    select
        p.product_id,
        p.product_name,
        p.product_sku,
        p.variant_name,
        p.variant_sku,
        p.main_category,
        
        -- Pricing
        p.original_price,
        p.discounted_price,
        case 
            when p.original_price > 0 
            then round((1 - p.discounted_price / p.original_price) * 100, 2)
            else 0
        end as discount_percentage,
        
        -- Weight
        p.product_weight,
        
        -- Product key
        p.product_key,
        
        -- Performance metrics
        coalesce(s.total_orders, 0) as total_orders,
        coalesce(s.total_quantity_sold, 0) as total_quantity_sold,
        coalesce(s.total_revenue, 0) as total_revenue,
        coalesce(s.avg_order_value, 0) as avg_order_value,
        s.first_sold_date,
        s.last_sold_date,
        
        -- Product tier based on revenue
        case
            when s.total_revenue >= 10000000 then 'Star Product'
            when s.total_revenue >= 5000000 then 'High Performer'
            when s.total_revenue >= 1000000 then 'Moderate'
            when s.total_revenue > 0 then 'Low Performer'
            else 'No Sales'
        end as product_tier,
        
        -- Velocity
        case 
            when s.total_quantity_sold >= 50 then 'Fast Moving'
            when s.total_quantity_sold >= 20 then 'Medium Moving'
            when s.total_quantity_sold >= 5 then 'Slow Moving'
            else 'Very Slow'
        end as sales_velocity,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from products p
    left join product_stats s on p.product_name = s.product_name
)

select * from final
  );
  
[0m04:09:21.726506 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.009 seconds
[0m04:09:21.730863 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:09:21.732457 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product" rename to "dim_product__dbt_backup"
[0m04:09:21.734018 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.738645 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:09:21.740603 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp" rename to "dim_product"
[0m04:09:21.743140 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:21.748629 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:09:21.750360 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:09:21.752013 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m04:09:21.755759 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:09:21.761574 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_product__dbt_backup"
[0m04:09:21.765049 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m04:09:21.767570 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_product__dbt_backup" cascade
[0m04:09:21.775503 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m04:09:21.778865 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: Close
[0m04:09:21.781082 [info ] [Thread-1 (]: 10 of 14 OK created sql table model analytics_gold.dim_product ................. [[32mSELECT 236[0m in 0.15s]
[0m04:09:21.783076 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m04:09:21.785230 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m04:09:21.786813 [info ] [Thread-1 (]: 11 of 14 START sql table model analytics_gold.fct_orders ....................... [RUN]
[0m04:09:21.788892 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_product, now model.ecommerce_dbt.fct_orders)
[0m04:09:21.790483 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.fct_orders
[0m04:09:21.805789 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.fct_orders"
[0m04:09:21.890281 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.fct_orders
[0m04:09:21.900208 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.fct_orders"
[0m04:09:21.939098 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:09:21.940403 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: BEGIN
[0m04:09:21.948474 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:21.964302 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:09:21.970608 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:09:21.976115 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Fact Orders
-- Main fact table - Star Schema center
-- Joins all dimensions with measures



with orders as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

customers as (
    select customer_id, buyer_username, customer_key, region, customer_segment
    from "ecommerce_db"."analytics_gold"."dim_customer"
),

products as (
    select product_id, product_name, product_key, main_category, product_tier
    from "ecommerce_db"."analytics_gold"."dim_product"
),

dates as (
    select date_key, date, is_double_day_sale, sale_event_name
    from "ecommerce_db"."analytics_gold"."dim_date"
),

shipping as (
    select shipping_id, shipping_carrier, shipping_key, carrier_group
    from "ecommerce_db"."analytics_gold"."dim_shipping"
),

payment as (
    select payment_method_id, payment_method, payment_key, payment_group
    from "ecommerce_db"."analytics_gold"."dim_payment"
),

-- Customer order sequence
order_sequence as (
    select
        order_id,
        buyer_username,
        row_number() over (
            partition by buyer_username 
            order by order_date
        ) as customer_order_seq
    from orders
),

fact_orders as (
    select
        -- Primary key
        o.order_id,
        
        -- Dimension keys (foreign keys)
        c.customer_id,
        p.product_id,
        d.date_key as order_date_key,
        s.shipping_id,
        pm.payment_method_id,
        
        -- Surrogate keys (for BI tools)
        c.customer_key,
        p.product_key,
        s.shipping_key,
        pm.payment_key,
        
        -- Natural keys (for reference)
        o.package_id,
        o.tracking_number,
        o.buyer_username,
        
        -- Date dimensions
        o.order_date,
        o.expected_delivery_date,
        o.actual_delivery_date,
        o.order_completed_date,
        o.payment_date,
        
        -- Delivery metrics
        case
            when o.actual_delivery_date is not null and o.order_date is not null
            then extract(day from o.actual_delivery_date - o.order_date)
            else null
        end as delivery_days,
        
        case
            when o.actual_delivery_date is not null and o.expected_delivery_date is not null
            then case 
                when o.actual_delivery_date <= o.expected_delivery_date then 'On Time'
                else 'Late'
            end
            else 'Unknown'
        end as delivery_status,
        
        -- Order status
        o.order_status,
        o.order_type,
        o.return_status,
        
        -- Product details (denormalized for performance)
        o.product_name,
        o.variant_name,
        o.product_weight,
        p.main_category,
        
        -- Quantity and pricing (MEASURES)
        o.quantity,
        o.original_price,
        o.discount_price,
        o.total_product_price,
        o.order_total_vnd,
        
        -- Discount breakdown (MEASURES)
        o.seller_discount,
        o.shopee_discount,
        o.shop_voucher,
        o.shopee_voucher,
        o.coins_cashback,
        o.total_discount,
        
        -- Shipping costs (MEASURES)
        o.shipping_fee_estimated,
        o.shipping_fee_paid,
        o.shipping_subsidy,
        
        -- Payment (MEASURES)
        o.total_paid,
        o.payment_method,
        
        -- Fees (MEASURES)
        o.fixed_fee,
        o.service_fee,
        o.payment_fee,
        o.deposit,
        
        -- Calculated measures
        o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee as net_revenue,
        
        case
            when o.original_price > 0 
            then round(((o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee) / (o.original_price * o.quantity)) * 100, 2)
            else 0
        end as profit_margin_pct,
        
        -- Order value tier
        case
            when o.order_total_vnd >= 1000000 then 'Premium (1M+)'
            when o.order_total_vnd >= 500000 then 'High (500K-1M)'
            when o.order_total_vnd >= 200000 then 'Medium (200K-500K)'
            when o.order_total_vnd >= 100000 then 'Low (100K-200K)'
            else 'Micro (<100K)'
        end as order_value_tier,
        
        -- Customer location (denormalized)
        o.province,
        o.district,
        c.region,
        
        -- Shipping info (denormalized)
        o.shipping_carrier,
        s.carrier_group,
        
        -- Payment info (denormalized)
        pm.payment_group,
        
        -- Customer order sequence
        seq.customer_order_seq,
        case when seq.customer_order_seq = 1 then 'New' else 'Repeat' end as new_vs_repeat,
        
        -- Sale event (denormalized from date)
        d.is_double_day_sale,
        d.sale_event_name,
        
        -- Flags
        o.is_bestseller,
        case when o.return_status is not null and o.return_status != '' then true else false end as is_returned,
        case when o.order_status in ('Ho√†n th√†nh', 'complete', 'completed', 'Completed') then true else false end as is_completed,
        case when o.order_status in ('ƒê√£ h·ªßy', 'cancelled', 'Cancelled', 'cancel') then true else false end as is_cancelled,
        
        -- Metadata
        o.source_file,
        o.source_loaded_at,
        current_timestamp as _gold_loaded_at
        
    from orders o
    left join customers c on o.buyer_username = c.buyer_username
    left join products p on o.product_name = p.product_name
    left join dates d on cast(o.order_date as date) = d.date
    left join shipping s on o.shipping_carrier = s.shipping_carrier
    left join payment pm on o.payment_method = pm.payment_method
    left join order_sequence seq on o.order_id = seq.order_id
)

select * from fact_orders
  );
  
[0m04:09:22.321254 [debug] [Thread-1 (]: SQL status: SELECT 25442 in 0.344 seconds
[0m04:09:22.325725 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:09:22.331368 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders" rename to "fct_orders__dbt_backup"
[0m04:09:22.334355 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:22.340404 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:09:22.343176 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp" rename to "fct_orders"
[0m04:09:22.346081 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:22.350506 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m04:09:22.352094 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:09:22.353741 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m04:09:22.368481 [debug] [Thread-1 (]: SQL status: COMMIT in 0.013 seconds
[0m04:09:22.373088 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup"
[0m04:09:22.375198 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m04:09:22.376929 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
drop table if exists "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup" cascade
[0m04:09:22.386341 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m04:09:22.390178 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: Close
[0m04:09:22.392375 [info ] [Thread-1 (]: 11 of 14 OK created sql table model analytics_gold.fct_orders .................. [[32mSELECT 25442[0m in 0.60s]
[0m04:09:22.394087 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m04:09:22.396469 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m04:09:22.398118 [info ] [Thread-1 (]: 12 of 14 START sql table model analytics_gold.agg_customer_summary ............. [RUN]
[0m04:09:22.399816 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.fct_orders, now model.ecommerce_dbt.agg_customer_summary)
[0m04:09:22.401288 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_customer_summary
[0m04:09:22.406415 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.444036 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_customer_summary
[0m04:09:22.455663 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.501213 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.502571 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: BEGIN
[0m04:09:22.504176 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:22.523203 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m04:09:22.524940 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.526230 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Summary Aggregate
-- Customer-level aggregated metrics with RFM



with customer_orders as (
    select
        buyer_username,
        customer_id,
        region,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Quantity
        sum(quantity) as total_items_purchased,
        
        -- Revenue
        sum(order_total_vnd) as total_spent,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Time metrics
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order,
        
        -- Product diversity
        count(distinct product_name) as unique_products_ordered,
        count(distinct main_category) as unique_categories,
        
        -- Shipping preferences
        mode() within group (order by carrier_group) as preferred_carrier,
        mode() within group (order by payment_group) as preferred_payment
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where buyer_username is not null
    group by 1, 2, 3
),

with_rfm as (
    select
        *,
        
        -- RFM Scores
        ntile(5) over (order by days_since_last_order desc nulls last) as r_score,
        ntile(5) over (order by total_orders asc nulls first) as f_score,
        ntile(5) over (order by total_spent asc nulls first) as m_score
        
    from customer_orders
    where total_orders > 0
)

select
    buyer_username,
    customer_id,
    region,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    total_items_purchased,
    
    -- Revenue metrics
    total_spent,
    total_net_revenue,
    avg_order_value,
    
    -- Time metrics
    first_order_date,
    last_order_date,
    days_since_last_order,
    
    -- Tenure (days as customer)
    current_date - first_order_date::date as customer_tenure_days,
    
    -- Frequency (orders per month)
    case 
        when current_date - first_order_date::date > 30 
        then round(total_orders * 30.0 / (current_date - first_order_date::date), 2)
        else total_orders
    end as orders_per_month,
    
    -- Product diversity
    unique_products_ordered,
    unique_categories,
    
    -- Preferences
    preferred_carrier,
    preferred_payment,
    
    -- RFM
    r_score,
    f_score,
    m_score,
    r_score * 100 + f_score * 10 + m_score as rfm_score,
    
    -- RFM Segment
    case
        when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
        when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
        when r_score >= 4 and f_score <= 2 then 'Recent Customers'
        when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
        when r_score <= 2 and f_score >= 4 then 'At Risk'
        when r_score <= 2 and f_score >= 2 then 'Hibernating'
        when r_score <= 2 and f_score <= 2 then 'Lost'
        else 'Other'
    end as customer_segment,
    
    -- Customer lifecycle
    case 
        when total_orders = 1 then 'New'
        when total_orders between 2 and 3 then 'Returning'
        when total_orders between 4 and 10 then 'Regular'
        when total_orders > 10 then 'VIP'
    end as customer_lifecycle,
    
    -- Value tier
    case
        when total_spent >= 5000000 then 'Platinum'
        when total_spent >= 2000000 then 'Gold'
        when total_spent >= 500000 then 'Silver'
        else 'Bronze'
    end as customer_value_tier,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from with_rfm
order by total_spent desc
  );
  
[0m04:09:22.617526 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.089 seconds
[0m04:09:22.623539 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.624794 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary" rename to "agg_customer_summary__dbt_backup"
[0m04:09:22.626645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:22.632627 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.636775 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp" rename to "agg_customer_summary"
[0m04:09:22.639456 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:22.642867 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m04:09:22.644093 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.645233 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m04:09:22.648324 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:09:22.654208 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup"
[0m04:09:22.656772 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m04:09:22.658060 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup" cascade
[0m04:09:22.661952 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:09:22.664882 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: Close
[0m04:09:22.666497 [info ] [Thread-1 (]: 12 of 14 OK created sql table model analytics_gold.agg_customer_summary ........ [[32mSELECT 268[0m in 0.27s]
[0m04:09:22.667949 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m04:09:22.669132 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m04:09:22.670340 [info ] [Thread-1 (]: 13 of 14 START sql table model analytics_gold.agg_daily_sales .................. [RUN]
[0m04:09:22.672335 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_customer_summary, now model.ecommerce_dbt.agg_daily_sales)
[0m04:09:22.673771 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_daily_sales
[0m04:09:22.680888 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.703184 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_daily_sales
[0m04:09:22.709597 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.737663 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.738872 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: BEGIN
[0m04:09:22.739756 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:22.750119 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m04:09:22.752556 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.754947 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Daily Sales Aggregate
-- Daily sales metrics for dashboards



with daily_orders as (
    select
        cast(order_date as date) as order_date,
        order_date_key,
        is_double_day_sale,
        sale_event_name,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_cancelled then order_id end) as cancelled_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        count(distinct case when new_vs_repeat = 'Repeat' then buyer_username end) as repeat_customers,
        
        -- Product counts
        count(distinct product_name) as unique_products,
        sum(quantity) as total_quantity,
        
        -- Revenue metrics
        sum(order_total_vnd) as gross_revenue,
        sum(net_revenue) as net_revenue,
        sum(total_discount) as total_discount,
        sum(shipping_fee_paid) as total_shipping,
        
        -- Fee breakdown
        sum(fixed_fee) as total_fixed_fee,
        sum(service_fee) as total_service_fee,
        sum(payment_fee) as total_payment_fee,
        
        -- Averages
        avg(order_total_vnd) as avg_order_value,
        avg(quantity) as avg_items_per_order,
        avg(delivery_days) as avg_delivery_days,
        
        -- By order value tier
        count(distinct case when order_value_tier = 'Premium (1M+)' then order_id end) as premium_orders,
        count(distinct case when order_value_tier = 'Micro (<100K)' then order_id end) as micro_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    group by 1, 2, 3, 4
)

select
    d.*,
    
    -- Completion rate
    case 
        when total_orders > 0 
        then round(completed_orders * 100.0 / total_orders, 2)
        else 0 
    end as completion_rate_pct,
    
    -- Cancellation rate
    case 
        when total_orders > 0 
        then round(cancelled_orders * 100.0 / total_orders, 2)
        else 0 
    end as cancellation_rate_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- New customer rate
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from daily_orders d
order by order_date desc
  );
  
[0m04:09:22.829991 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.073 seconds
[0m04:09:22.836825 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.838532 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales" rename to "agg_daily_sales__dbt_backup"
[0m04:09:22.841299 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:22.850479 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.854317 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp" rename to "agg_daily_sales"
[0m04:09:22.858215 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:22.862704 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m04:09:22.864543 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.866161 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m04:09:22.870216 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:09:22.878096 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup"
[0m04:09:22.882541 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m04:09:22.885714 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup" cascade
[0m04:09:22.893940 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m04:09:22.899277 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: Close
[0m04:09:22.902187 [info ] [Thread-1 (]: 13 of 14 OK created sql table model analytics_gold.agg_daily_sales ............. [[32mSELECT 111[0m in 0.23s]
[0m04:09:22.904917 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m04:09:22.906233 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m04:09:22.907704 [info ] [Thread-1 (]: 14 of 14 START sql table model analytics_gold.agg_product_performance .......... [RUN]
[0m04:09:22.910721 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_daily_sales, now model.ecommerce_dbt.agg_product_performance)
[0m04:09:22.911949 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_product_performance
[0m04:09:22.920137 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_product_performance"
[0m04:09:22.952695 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_product_performance
[0m04:09:22.957653 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_product_performance"
[0m04:09:22.992565 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:09:22.994184 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: BEGIN
[0m04:09:22.996074 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:23.011534 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:09:23.014018 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:09:23.016762 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Performance Aggregate
-- Product-level aggregated metrics



with product_orders as (
    select
        product_name,
        product_id,
        main_category,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        
        -- Quantity
        sum(quantity) as total_quantity_sold,
        avg(quantity) as avg_quantity_per_order,
        
        -- Revenue
        sum(order_total_vnd) as total_revenue,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Pricing
        avg(original_price) as avg_original_price,
        avg(discount_price) as avg_discount_price,
        sum(total_discount) as total_discount_given,
        
        -- Time metrics
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date,
        current_date - max(order_date)::date as days_since_last_sale,
        
        -- Geography
        mode() within group (order by region) as top_region,
        
        -- Sale events
        count(distinct case when is_double_day_sale then order_id end) as sale_event_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where product_name is not null
    group by 1, 2, 3
)

select
    product_name,
    product_id,
    main_category,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    
    -- Customer metrics
    unique_customers,
    new_customers,
    
    -- Quantity metrics
    total_quantity_sold,
    avg_quantity_per_order,
    
    -- Revenue metrics
    total_revenue,
    total_net_revenue,
    avg_order_value,
    
    -- Pricing metrics
    avg_original_price,
    avg_discount_price,
    total_discount_given,
    
    -- Discount percentage
    case 
        when avg_original_price > 0 
        then round((1 - avg_discount_price / avg_original_price) * 100, 2)
        else 0 
    end as avg_discount_pct,
    
    -- Time metrics
    first_sold_date,
    last_sold_date,
    days_since_last_sale,
    
    -- Selling period (days)
    last_sold_date::date - first_sold_date::date as selling_period_days,
    
    -- Sales velocity (units per day)
    case 
        when last_sold_date::date - first_sold_date::date > 0 
        then round(total_quantity_sold * 1.0 / (last_sold_date::date - first_sold_date::date + 1), 2)
        else total_quantity_sold
    end as daily_sales_velocity,
    
    -- Top region
    top_region,
    
    -- Sale event performance
    sale_event_orders,
    case 
        when total_orders > 0 
        then round(sale_event_orders * 100.0 / total_orders, 2)
        else 0 
    end as sale_event_order_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Customer acquisition
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_pct,
    
    -- Product tier
    case
        when total_revenue >= 10000000 then 'Star Product'
        when total_revenue >= 5000000 then 'High Performer'
        when total_revenue >= 1000000 then 'Moderate'
        when total_revenue > 0 then 'Low Performer'
        else 'No Sales'
    end as product_tier,
    
    -- Sales velocity category
    case 
        when total_quantity_sold >= 50 then 'Fast Moving'
        when total_quantity_sold >= 20 then 'Medium Moving'
        when total_quantity_sold >= 5 then 'Slow Moving'
        else 'Very Slow'
    end as sales_velocity_category,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from product_orders
order by total_revenue desc
  );
  
[0m04:09:23.208667 [debug] [Thread-1 (]: SQL status: SELECT 236 in 0.189 seconds
[0m04:09:23.215507 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:09:23.217388 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance" rename to "agg_product_performance__dbt_backup"
[0m04:09:23.219704 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:23.224124 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:09:23.225588 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp" rename to "agg_product_performance"
[0m04:09:23.227756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:09:23.232270 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m04:09:23.233728 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:09:23.235075 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m04:09:23.239233 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:09:23.245471 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup"
[0m04:09:23.250272 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m04:09:23.252064 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup" cascade
[0m04:09:23.258787 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m04:09:23.265181 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: Close
[0m04:09:23.270229 [info ] [Thread-1 (]: 14 of 14 OK created sql table model analytics_gold.agg_product_performance ..... [[32mSELECT 236[0m in 0.36s]
[0m04:09:23.274924 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m04:09:23.279476 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:23.280905 [debug] [MainThread]: On master: BEGIN
[0m04:09:23.282428 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:09:23.296524 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m04:09:23.298130 [debug] [MainThread]: On master: COMMIT
[0m04:09:23.299745 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:23.301184 [debug] [MainThread]: On master: COMMIT
[0m04:09:23.304031 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m04:09:23.306588 [debug] [MainThread]: On master: Close
[0m04:09:23.308933 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:09:23.311585 [debug] [MainThread]: Connection 'model.ecommerce_dbt.agg_product_performance' was properly closed.
[0m04:09:23.314329 [info ] [MainThread]: 
[0m04:09:23.315735 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 3.97 seconds (3.97s).
[0m04:09:23.319694 [debug] [MainThread]: Command end result
[0m04:09:23.464731 [info ] [MainThread]: 
[0m04:09:23.465881 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:09:23.466823 [info ] [MainThread]: 
[0m04:09:23.467842 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
[0m04:09:23.470069 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.593123, "process_user_time": 4.967885, "process_kernel_time": 0.590363, "process_mem_max_rss": "126944", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:09:23.471487 [debug] [MainThread]: Command `dbt run` succeeded at 04:09:23.471315 after 8.59 seconds
[0m04:09:23.472813 [debug] [MainThread]: Flushing usage events
[0m04:09:26.114130 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 04:09:26.129981 | c9a037da-9454-4cd8-9831-8b66d682371b ==============================
[0m04:09:26.129981 [info ] [MainThread]: Running with dbt=1.8.0
[0m04:09:26.133476 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/.dbt --warn-error-options {"warn": []}', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:09:26.456072 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m04:09:26.490503 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m04:09:28.901035 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:09:28.903747 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:09:29.327561 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m04:09:29.333808 [info ] [MainThread]: 
[0m04:09:29.336065 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:09:29.345438 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db_analytics'
[0m04:09:29.401368 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:09:29.402645 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m04:09:29.403726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:09:29.416393 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m04:09:29.417958 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m04:09:29.419066 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m04:09:29.424344 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m04:09:29.427406 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m04:09:29.429004 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m04:09:29.430837 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_silver)
[0m04:09:29.436133 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:09:29.437614 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m04:09:29.439105 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:29.454794 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m04:09:29.457457 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m04:09:29.459553 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m04:09:29.466114 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.005 seconds
[0m04:09:29.470950 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m04:09:29.473624 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m04:09:29.475339 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics_bronze)
[0m04:09:29.483416 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:09:29.485985 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m04:09:29.488231 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:29.504930 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m04:09:29.506293 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m04:09:29.507336 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m04:09:29.513757 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m04:09:29.517936 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m04:09:29.520194 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m04:09:29.522387 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics_gold)
[0m04:09:29.526169 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:09:29.527697 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m04:09:29.529824 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:09:29.544422 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m04:09:29.546363 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m04:09:29.547975 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m04:09:29.554959 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.005 seconds
[0m04:09:29.560816 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m04:09:29.563846 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m04:09:29.584116 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:29.586321 [debug] [MainThread]: On master: BEGIN
[0m04:09:29.588918 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:09:29.607948 [debug] [MainThread]: SQL status: BEGIN in 0.019 seconds
[0m04:09:29.610424 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:29.613131 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:09:29.629747 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m04:09:29.634574 [debug] [MainThread]: On master: ROLLBACK
[0m04:09:29.638235 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:29.641002 [debug] [MainThread]: On master: BEGIN
[0m04:09:29.645498 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m04:09:29.647894 [debug] [MainThread]: On master: COMMIT
[0m04:09:29.650654 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:29.652927 [debug] [MainThread]: On master: COMMIT
[0m04:09:29.660066 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m04:09:29.662498 [debug] [MainThread]: On master: Close
[0m04:09:29.665943 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:09:29.668517 [info ] [MainThread]: 
[0m04:09:29.674797 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m04:09:29.676374 [info ] [Thread-1 (]: 1 of 31 START test not_null_agg_customer_summary_buyer_username ................ [RUN]
[0m04:09:29.677805 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e)
[0m04:09:29.679412 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m04:09:29.711908 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m04:09:29.791367 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m04:09:29.825157 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m04:09:29.938023 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m04:09:29.942660 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: BEGIN
[0m04:09:29.947425 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:29.966892 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m04:09:29.970188 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m04:09:29.974880 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_gold"."agg_customer_summary"
where buyer_username is null



      
    ) dbt_internal_test
[0m04:09:29.980429 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:29.990440 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: ROLLBACK
[0m04:09:29.997507 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: Close
[0m04:09:30.001148 [info ] [Thread-1 (]: 1 of 31 PASS not_null_agg_customer_summary_buyer_username ...................... [[32mPASS[0m in 0.32s]
[0m04:09:30.003999 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m04:09:30.005703 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m04:09:30.007600 [info ] [Thread-1 (]: 2 of 31 START test not_null_agg_daily_sales_order_date ......................... [RUN]
[0m04:09:30.008945 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e, now test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8)
[0m04:09:30.009938 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m04:09:30.015456 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m04:09:30.047627 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m04:09:30.052216 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m04:09:30.119721 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m04:09:30.121987 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: BEGIN
[0m04:09:30.124612 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:30.148575 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:09:30.166250 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m04:09:30.177837 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_date
from "ecommerce_db"."analytics_gold"."agg_daily_sales"
where order_date is null



      
    ) dbt_internal_test
[0m04:09:30.183658 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:30.187753 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: ROLLBACK
[0m04:09:30.189543 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: Close
[0m04:09:30.198465 [info ] [Thread-1 (]: 2 of 31 PASS not_null_agg_daily_sales_order_date ............................... [[32mPASS[0m in 0.19s]
[0m04:09:30.200490 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m04:09:30.202187 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m04:09:30.204816 [info ] [Thread-1 (]: 3 of 31 START test not_null_agg_product_performance_product_name ............... [RUN]
[0m04:09:30.206380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8, now test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1)
[0m04:09:30.207821 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m04:09:30.215266 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m04:09:30.268545 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m04:09:30.273460 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m04:09:30.390113 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m04:09:30.394217 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: BEGIN
[0m04:09:30.399798 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:30.417239 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:09:30.421376 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m04:09:30.422752 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_name
from "ecommerce_db"."analytics_gold"."agg_product_performance"
where product_name is null



      
    ) dbt_internal_test
[0m04:09:30.425269 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:30.427808 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: ROLLBACK
[0m04:09:30.429574 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: Close
[0m04:09:30.431858 [info ] [Thread-1 (]: 3 of 31 PASS not_null_agg_product_performance_product_name ..................... [[32mPASS[0m in 0.23s]
[0m04:09:30.434317 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m04:09:30.435579 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m04:09:30.437109 [info ] [Thread-1 (]: 4 of 31 START test not_null_brz_raw_orders_order_id ............................ [RUN]
[0m04:09:30.439123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1, now test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750)
[0m04:09:30.440815 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m04:09:30.448460 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m04:09:30.548922 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m04:09:30.554561 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m04:09:30.651344 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m04:09:30.654407 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: BEGIN
[0m04:09:30.657054 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:30.671201 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:09:30.675467 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m04:09:30.679610 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
where order_id is null



      
    ) dbt_internal_test
[0m04:09:30.686831 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.004 seconds
[0m04:09:30.690343 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: ROLLBACK
[0m04:09:30.692572 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: Close
[0m04:09:30.696181 [info ] [Thread-1 (]: 4 of 31 PASS not_null_brz_raw_orders_order_id .................................. [[32mPASS[0m in 0.26s]
[0m04:09:30.698915 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m04:09:30.700300 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m04:09:30.701610 [info ] [Thread-1 (]: 5 of 31 START test not_null_dim_customer_buyer_username ........................ [RUN]
[0m04:09:30.703166 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750, now test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b)
[0m04:09:30.704318 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m04:09:30.712254 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m04:09:30.908161 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m04:09:30.917646 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m04:09:31.028834 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m04:09:31.032261 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: BEGIN
[0m04:09:31.034275 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:31.046734 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:09:31.047872 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m04:09:31.049205 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_gold"."dim_customer"
where buyer_username is null



      
    ) dbt_internal_test
[0m04:09:31.051548 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:31.054109 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: ROLLBACK
[0m04:09:31.059324 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: Close
[0m04:09:31.062052 [info ] [Thread-1 (]: 5 of 31 PASS not_null_dim_customer_buyer_username .............................. [[32mPASS[0m in 0.36s]
[0m04:09:31.063694 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m04:09:31.065162 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m04:09:31.066282 [info ] [Thread-1 (]: 6 of 31 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m04:09:31.067538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b, now test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc)
[0m04:09:31.068513 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m04:09:31.074075 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m04:09:31.166212 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m04:09:31.181747 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m04:09:31.289328 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m04:09:31.296379 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m04:09:31.300320 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:31.318197 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:09:31.319282 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m04:09:31.321500 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "ecommerce_db"."analytics_gold"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m04:09:31.325595 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:31.330859 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m04:09:31.334004 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: Close
[0m04:09:31.338255 [info ] [Thread-1 (]: 6 of 31 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.27s]
[0m04:09:31.339693 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m04:09:31.341191 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m04:09:31.342581 [info ] [Thread-1 (]: 7 of 31 START test not_null_dim_date_date_key .................................. [RUN]
[0m04:09:31.343669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc, now test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6)
[0m04:09:31.344810 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m04:09:31.354800 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m04:09:31.450987 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m04:09:31.458339 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m04:09:31.510425 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m04:09:31.512754 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: BEGIN
[0m04:09:31.515013 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:31.529660 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m04:09:31.535468 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m04:09:31.539815 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date_key
from "ecommerce_db"."analytics_gold"."dim_date"
where date_key is null



      
    ) dbt_internal_test
[0m04:09:31.543778 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:31.548919 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: ROLLBACK
[0m04:09:31.554308 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: Close
[0m04:09:31.557714 [info ] [Thread-1 (]: 7 of 31 PASS not_null_dim_date_date_key ........................................ [[32mPASS[0m in 0.21s]
[0m04:09:31.559649 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m04:09:31.561531 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m04:09:31.563520 [info ] [Thread-1 (]: 8 of 31 START test not_null_dim_payment_payment_method_id ...................... [RUN]
[0m04:09:31.565840 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6, now test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b)
[0m04:09:31.567459 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m04:09:31.580965 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m04:09:31.634967 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m04:09:31.646513 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m04:09:31.700011 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m04:09:31.705682 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: BEGIN
[0m04:09:31.708362 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:31.722771 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:09:31.726025 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m04:09:31.728579 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select payment_method_id
from "ecommerce_db"."analytics_gold"."dim_payment"
where payment_method_id is null



      
    ) dbt_internal_test
[0m04:09:31.731367 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:31.736229 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: ROLLBACK
[0m04:09:31.739142 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: Close
[0m04:09:31.740969 [info ] [Thread-1 (]: 8 of 31 PASS not_null_dim_payment_payment_method_id ............................ [[32mPASS[0m in 0.18s]
[0m04:09:31.742302 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m04:09:31.743394 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m04:09:31.744991 [info ] [Thread-1 (]: 9 of 31 START test not_null_dim_product_product_id ............................. [RUN]
[0m04:09:31.746187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b, now test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816)
[0m04:09:31.746949 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m04:09:31.751958 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m04:09:31.818297 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m04:09:31.824339 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m04:09:31.942451 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m04:09:31.946669 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: BEGIN
[0m04:09:31.950736 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:31.963737 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:09:31.966321 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m04:09:31.969095 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_id
from "ecommerce_db"."analytics_gold"."dim_product"
where product_id is null



      
    ) dbt_internal_test
[0m04:09:31.974569 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:31.981233 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: ROLLBACK
[0m04:09:31.985871 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: Close
[0m04:09:31.990993 [info ] [Thread-1 (]: 9 of 31 PASS not_null_dim_product_product_id ................................... [[32mPASS[0m in 0.24s]
[0m04:09:31.994429 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m04:09:31.995846 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m04:09:31.997494 [info ] [Thread-1 (]: 10 of 31 START test not_null_dim_shipping_shipping_id .......................... [RUN]
[0m04:09:32.001157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816, now test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc)
[0m04:09:32.005991 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m04:09:32.024527 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m04:09:32.116993 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m04:09:32.125019 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m04:09:32.248820 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m04:09:32.254939 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: BEGIN
[0m04:09:32.263452 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:32.283168 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m04:09:32.291439 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m04:09:32.298010 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select shipping_id
from "ecommerce_db"."analytics_gold"."dim_shipping"
where shipping_id is null



      
    ) dbt_internal_test
[0m04:09:32.306667 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:32.316436 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: ROLLBACK
[0m04:09:32.320651 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: Close
[0m04:09:32.323845 [info ] [Thread-1 (]: 10 of 31 PASS not_null_dim_shipping_shipping_id ................................ [[32mPASS[0m in 0.32s]
[0m04:09:32.326249 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m04:09:32.328694 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m04:09:32.329698 [info ] [Thread-1 (]: 11 of 31 START test not_null_fct_orders_order_id ............................... [RUN]
[0m04:09:32.330763 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc, now test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0)
[0m04:09:32.332618 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m04:09:32.344225 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m04:09:32.472447 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m04:09:32.480804 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m04:09:32.602559 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m04:09:32.609084 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: BEGIN
[0m04:09:32.613585 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:32.640278 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m04:09:32.644450 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m04:09:32.647021 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_gold"."fct_orders"
where order_id is null



      
    ) dbt_internal_test
[0m04:09:32.667232 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.017 seconds
[0m04:09:32.673719 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: ROLLBACK
[0m04:09:32.676979 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: Close
[0m04:09:32.680527 [info ] [Thread-1 (]: 11 of 31 PASS not_null_fct_orders_order_id ..................................... [[32mPASS[0m in 0.35s]
[0m04:09:32.681948 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m04:09:32.683221 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m04:09:32.684378 [info ] [Thread-1 (]: 12 of 31 START test not_null_fct_orders_order_total_vnd ........................ [RUN]
[0m04:09:32.685660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0, now test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95)
[0m04:09:32.687256 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m04:09:32.694704 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m04:09:32.781699 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m04:09:32.789789 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m04:09:32.875759 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m04:09:32.879399 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: BEGIN
[0m04:09:32.885526 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:32.901998 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:09:32.906774 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m04:09:32.911987 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_total_vnd
from "ecommerce_db"."analytics_gold"."fct_orders"
where order_total_vnd is null



      
    ) dbt_internal_test
[0m04:09:32.927184 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.009 seconds
[0m04:09:32.932137 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: ROLLBACK
[0m04:09:32.934831 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: Close
[0m04:09:32.939644 [info ] [Thread-1 (]: 12 of 31 PASS not_null_fct_orders_order_total_vnd .............................. [[32mPASS[0m in 0.25s]
[0m04:09:32.942933 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m04:09:32.944057 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m04:09:32.944999 [info ] [Thread-1 (]: 13 of 31 START test not_null_slv_customers_buyer_username ...................... [RUN]
[0m04:09:32.946250 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95, now test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c)
[0m04:09:32.947229 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m04:09:32.952448 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m04:09:33.024219 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m04:09:33.030634 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m04:09:33.129278 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m04:09:33.131885 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: BEGIN
[0m04:09:33.134695 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:33.147839 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:09:33.151820 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m04:09:33.159270 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_silver"."slv_customers"
where buyer_username is null



      
    ) dbt_internal_test
[0m04:09:33.166060 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:33.171281 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: ROLLBACK
[0m04:09:33.179758 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: Close
[0m04:09:33.187756 [info ] [Thread-1 (]: 13 of 31 PASS not_null_slv_customers_buyer_username ............................ [[32mPASS[0m in 0.24s]
[0m04:09:33.191832 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m04:09:33.198734 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m04:09:33.203186 [info ] [Thread-1 (]: 14 of 31 START test not_null_slv_customers_customer_id ......................... [RUN]
[0m04:09:33.204552 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c, now test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9)
[0m04:09:33.205844 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m04:09:33.211305 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m04:09:33.324403 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m04:09:33.329939 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m04:09:33.442198 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m04:09:33.448509 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: BEGIN
[0m04:09:33.455656 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:33.477128 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m04:09:33.480613 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m04:09:33.483764 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "ecommerce_db"."analytics_silver"."slv_customers"
where customer_id is null



      
    ) dbt_internal_test
[0m04:09:33.490840 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:33.497194 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: ROLLBACK
[0m04:09:33.500454 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: Close
[0m04:09:33.503690 [info ] [Thread-1 (]: 14 of 31 PASS not_null_slv_customers_customer_id ............................... [[32mPASS[0m in 0.30s]
[0m04:09:33.506131 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m04:09:33.507691 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m04:09:33.508695 [info ] [Thread-1 (]: 15 of 31 START test not_null_slv_dates_date_key ................................ [RUN]
[0m04:09:33.510405 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9, now test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954)
[0m04:09:33.511441 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m04:09:33.519728 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m04:09:33.556735 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m04:09:33.567244 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m04:09:33.643929 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m04:09:33.646455 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: BEGIN
[0m04:09:33.649915 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:33.662188 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:09:33.664249 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m04:09:33.666465 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date_key
from "ecommerce_db"."analytics_silver"."slv_dates"
where date_key is null



      
    ) dbt_internal_test
[0m04:09:33.674041 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:33.680218 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: ROLLBACK
[0m04:09:33.682448 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: Close
[0m04:09:33.684913 [info ] [Thread-1 (]: 15 of 31 PASS not_null_slv_dates_date_key ...................................... [[32mPASS[0m in 0.17s]
[0m04:09:33.686351 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m04:09:33.687548 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m04:09:33.688627 [info ] [Thread-1 (]: 16 of 31 START test not_null_slv_orders_order_date ............................. [RUN]
[0m04:09:33.689950 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954, now test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442)
[0m04:09:33.691665 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m04:09:33.696614 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m04:09:33.757299 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m04:09:33.772034 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m04:09:33.818373 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m04:09:33.820481 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: BEGIN
[0m04:09:33.823263 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:33.836073 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:09:33.837859 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m04:09:33.840760 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_date
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_date is null



      
    ) dbt_internal_test
[0m04:09:33.845968 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:33.852049 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: ROLLBACK
[0m04:09:33.855463 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: Close
[0m04:09:33.858970 [info ] [Thread-1 (]: 16 of 31 PASS not_null_slv_orders_order_date ................................... [[32mPASS[0m in 0.17s]
[0m04:09:33.862895 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m04:09:33.864161 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m04:09:33.865148 [info ] [Thread-1 (]: 17 of 31 START test not_null_slv_orders_order_id ............................... [RUN]
[0m04:09:33.866864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442, now test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2)
[0m04:09:33.868405 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m04:09:33.946318 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m04:09:33.996560 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m04:09:34.008791 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m04:09:34.078972 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m04:09:34.083188 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: BEGIN
[0m04:09:34.086782 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:34.107474 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m04:09:34.108634 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m04:09:34.109577 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_id is null



      
    ) dbt_internal_test
[0m04:09:34.113598 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:34.121155 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: ROLLBACK
[0m04:09:34.124143 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: Close
[0m04:09:34.128310 [info ] [Thread-1 (]: 17 of 31 PASS not_null_slv_orders_order_id ..................................... [[32mPASS[0m in 0.26s]
[0m04:09:34.130787 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m04:09:34.132454 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m04:09:34.135880 [info ] [Thread-1 (]: 18 of 31 START test not_null_slv_orders_order_total_vnd ........................ [RUN]
[0m04:09:34.139525 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2, now test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1)
[0m04:09:34.141477 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m04:09:34.153954 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m04:09:34.210570 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m04:09:34.214870 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m04:09:34.284569 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m04:09:34.288977 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: BEGIN
[0m04:09:34.293321 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:34.304632 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:09:34.306050 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m04:09:34.307322 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_total_vnd
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_total_vnd is null



      
    ) dbt_internal_test
[0m04:09:34.309751 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:34.312333 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: ROLLBACK
[0m04:09:34.313730 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: Close
[0m04:09:34.316484 [info ] [Thread-1 (]: 18 of 31 PASS not_null_slv_orders_order_total_vnd .............................. [[32mPASS[0m in 0.18s]
[0m04:09:34.318910 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m04:09:34.320432 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m04:09:34.321876 [info ] [Thread-1 (]: 19 of 31 START test not_null_slv_products_product_id ........................... [RUN]
[0m04:09:34.323638 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1, now test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621)
[0m04:09:34.326014 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m04:09:34.333133 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m04:09:34.375369 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m04:09:34.380026 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m04:09:34.438072 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m04:09:34.439267 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: BEGIN
[0m04:09:34.442743 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:34.453129 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m04:09:34.458508 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m04:09:34.460415 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_id
from "ecommerce_db"."analytics_silver"."slv_products"
where product_id is null



      
    ) dbt_internal_test
[0m04:09:34.466586 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:34.471768 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: ROLLBACK
[0m04:09:34.475413 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: Close
[0m04:09:34.477362 [info ] [Thread-1 (]: 19 of 31 PASS not_null_slv_products_product_id ................................. [[32mPASS[0m in 0.15s]
[0m04:09:34.478964 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m04:09:34.481794 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m04:09:34.485044 [info ] [Thread-1 (]: 20 of 31 START test unique_agg_customer_summary_buyer_username ................. [RUN]
[0m04:09:34.487649 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621, now test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359)
[0m04:09:34.490103 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m04:09:34.514184 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m04:09:34.623607 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m04:09:34.634870 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m04:09:34.786903 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m04:09:34.792231 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: BEGIN
[0m04:09:34.797022 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:34.810071 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:09:34.812269 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m04:09:34.813306 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    buyer_username as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_customer_summary"
where buyer_username is not null
group by buyer_username
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:34.816031 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:34.818900 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: ROLLBACK
[0m04:09:34.822278 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: Close
[0m04:09:34.823875 [error] [Thread-1 (]: 20 of 31 FAIL 3 unique_agg_customer_summary_buyer_username ..................... [[31mFAIL 3[0m in 0.34s]
[0m04:09:34.825777 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m04:09:34.827322 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m04:09:34.828708 [info ] [Thread-1 (]: 21 of 31 START test unique_agg_daily_sales_order_date .......................... [RUN]
[0m04:09:34.830221 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359, now test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d)
[0m04:09:34.831884 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m04:09:34.839473 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m04:09:34.934257 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m04:09:34.945937 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m04:09:35.086800 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m04:09:35.090566 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: BEGIN
[0m04:09:35.096707 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:35.114243 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:09:35.117789 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m04:09:35.120652 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_date as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_daily_sales"
where order_date is not null
group by order_date
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:35.125411 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:35.129782 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: ROLLBACK
[0m04:09:35.131842 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: Close
[0m04:09:35.134709 [info ] [Thread-1 (]: 21 of 31 PASS unique_agg_daily_sales_order_date ................................ [[32mPASS[0m in 0.30s]
[0m04:09:35.136363 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m04:09:35.137487 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m04:09:35.138441 [info ] [Thread-1 (]: 22 of 31 START test unique_agg_product_performance_product_name ................ [RUN]
[0m04:09:35.139790 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d, now test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03)
[0m04:09:35.141701 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m04:09:35.148354 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m04:09:35.229875 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m04:09:35.236624 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m04:09:35.304505 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m04:09:35.306147 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: BEGIN
[0m04:09:35.310609 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:35.321766 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:09:35.324914 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m04:09:35.328608 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_name as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_product_performance"
where product_name is not null
group by product_name
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:35.332836 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:35.335723 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: ROLLBACK
[0m04:09:35.337685 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: Close
[0m04:09:35.339837 [error] [Thread-1 (]: 22 of 31 FAIL 37 unique_agg_product_performance_product_name ................... [[31mFAIL 37[0m in 0.20s]
[0m04:09:35.343428 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m04:09:35.346600 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m04:09:35.349762 [info ] [Thread-1 (]: 23 of 31 START test unique_dim_customer_customer_id ............................ [RUN]
[0m04:09:35.351617 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03, now test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1)
[0m04:09:35.352708 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m04:09:35.360438 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m04:09:35.454325 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m04:09:35.462069 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m04:09:35.551541 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m04:09:35.555670 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: BEGIN
[0m04:09:35.559623 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:35.572421 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:09:35.573770 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m04:09:35.575413 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_customer"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:35.578598 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:35.582362 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: ROLLBACK
[0m04:09:35.583828 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: Close
[0m04:09:35.585899 [info ] [Thread-1 (]: 23 of 31 PASS unique_dim_customer_customer_id .................................. [[32mPASS[0m in 0.23s]
[0m04:09:35.588643 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m04:09:35.590634 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m04:09:35.591783 [info ] [Thread-1 (]: 24 of 31 START test unique_dim_date_date_key ................................... [RUN]
[0m04:09:35.594686 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1, now test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9)
[0m04:09:35.595826 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m04:09:35.602268 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m04:09:35.654968 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m04:09:35.660742 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m04:09:35.757769 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m04:09:35.763515 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: BEGIN
[0m04:09:35.770391 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:35.782152 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:09:35.785720 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m04:09:35.788602 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_key as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_date"
where date_key is not null
group by date_key
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:35.791906 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m04:09:35.797773 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: ROLLBACK
[0m04:09:35.801261 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: Close
[0m04:09:35.805300 [info ] [Thread-1 (]: 24 of 31 PASS unique_dim_date_date_key ......................................... [[32mPASS[0m in 0.21s]
[0m04:09:35.813512 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m04:09:35.817534 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m04:09:35.822286 [info ] [Thread-1 (]: 25 of 31 START test unique_dim_payment_payment_method_id ....................... [RUN]
[0m04:09:35.828517 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9, now test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209)
[0m04:09:35.833335 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m04:09:35.841563 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m04:09:36.010319 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m04:09:36.021284 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m04:09:36.199261 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m04:09:36.201207 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: BEGIN
[0m04:09:36.204068 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:36.219213 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m04:09:36.224660 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m04:09:36.227204 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    payment_method_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_payment"
where payment_method_id is not null
group by payment_method_id
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:36.232225 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:36.241335 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: ROLLBACK
[0m04:09:36.246002 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: Close
[0m04:09:36.250697 [info ] [Thread-1 (]: 25 of 31 PASS unique_dim_payment_payment_method_id ............................. [[32mPASS[0m in 0.42s]
[0m04:09:36.255510 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m04:09:36.259440 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m04:09:36.262597 [info ] [Thread-1 (]: 26 of 31 START test unique_dim_product_product_id .............................. [RUN]
[0m04:09:36.267200 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209, now test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe)
[0m04:09:36.269703 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m04:09:36.276174 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m04:09:36.344172 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m04:09:36.349603 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m04:09:36.460631 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m04:09:36.470272 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: BEGIN
[0m04:09:36.480092 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:36.500422 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m04:09:36.506072 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m04:09:36.511770 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_product"
where product_id is not null
group by product_id
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:36.517799 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:36.520924 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: ROLLBACK
[0m04:09:36.524281 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: Close
[0m04:09:36.527567 [info ] [Thread-1 (]: 26 of 31 PASS unique_dim_product_product_id .................................... [[32mPASS[0m in 0.26s]
[0m04:09:36.529228 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m04:09:36.531981 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m04:09:36.534348 [info ] [Thread-1 (]: 27 of 31 START test unique_dim_shipping_shipping_id ............................ [RUN]
[0m04:09:36.537551 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe, now test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f)
[0m04:09:36.539096 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m04:09:36.549836 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m04:09:36.591044 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m04:09:36.598951 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m04:09:36.677090 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m04:09:36.678903 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: BEGIN
[0m04:09:36.681389 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:36.695601 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:09:36.697416 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m04:09:36.700246 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    shipping_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_shipping"
where shipping_id is not null
group by shipping_id
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:36.706575 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m04:09:36.712386 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: ROLLBACK
[0m04:09:36.716844 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: Close
[0m04:09:36.719987 [info ] [Thread-1 (]: 27 of 31 PASS unique_dim_shipping_shipping_id .................................. [[32mPASS[0m in 0.18s]
[0m04:09:36.722103 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m04:09:36.723500 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m04:09:36.726698 [info ] [Thread-1 (]: 28 of 31 START test unique_slv_customers_customer_id ........................... [RUN]
[0m04:09:36.728702 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f, now test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b)
[0m04:09:36.731425 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m04:09:36.739583 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m04:09:36.776983 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m04:09:36.782396 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m04:09:36.882650 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m04:09:36.886594 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: BEGIN
[0m04:09:36.890305 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:36.909058 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m04:09:36.912004 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m04:09:36.915646 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_customers"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:36.921110 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:36.930192 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: ROLLBACK
[0m04:09:36.935555 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: Close
[0m04:09:36.944695 [info ] [Thread-1 (]: 28 of 31 PASS unique_slv_customers_customer_id ................................. [[32mPASS[0m in 0.22s]
[0m04:09:36.951543 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m04:09:36.955551 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m04:09:36.964068 [info ] [Thread-1 (]: 29 of 31 START test unique_slv_dates_date_key .................................. [RUN]
[0m04:09:36.972438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b, now test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc)
[0m04:09:36.977034 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m04:09:36.987091 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m04:09:37.072685 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m04:09:37.080006 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m04:09:37.143706 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m04:09:37.149946 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: BEGIN
[0m04:09:37.158794 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:37.180119 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m04:09:37.183933 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m04:09:37.188314 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_key as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_dates"
where date_key is not null
group by date_key
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:37.194229 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m04:09:37.198369 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: ROLLBACK
[0m04:09:37.200579 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: Close
[0m04:09:37.205878 [info ] [Thread-1 (]: 29 of 31 PASS unique_slv_dates_date_key ........................................ [[32mPASS[0m in 0.23s]
[0m04:09:37.211809 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m04:09:37.215625 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m04:09:37.222154 [info ] [Thread-1 (]: 30 of 31 START test unique_slv_orders_order_id ................................. [RUN]
[0m04:09:37.226427 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc, now test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e)
[0m04:09:37.230337 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m04:09:37.242152 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m04:09:37.393465 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m04:09:37.398076 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m04:09:37.447989 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m04:09:37.451827 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: BEGIN
[0m04:09:37.455090 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:37.472743 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:09:37.477105 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m04:09:37.479842 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_orders"
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:37.486155 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.004 seconds
[0m04:09:37.493769 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: ROLLBACK
[0m04:09:37.497556 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: Close
[0m04:09:37.502407 [error] [Thread-1 (]: 30 of 31 FAIL 154 unique_slv_orders_order_id ................................... [[31mFAIL 154[0m in 0.27s]
[0m04:09:37.505604 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m04:09:37.507446 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m04:09:37.508640 [info ] [Thread-1 (]: 31 of 31 START test unique_slv_products_product_id ............................. [RUN]
[0m04:09:37.510867 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e, now test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb)
[0m04:09:37.512802 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m04:09:37.519126 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m04:09:37.570341 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m04:09:37.578741 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m04:09:37.673246 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m04:09:37.676657 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: BEGIN
[0m04:09:37.681902 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:09:37.698654 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m04:09:37.704625 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m04:09:37.709622 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_products"
where product_id is not null
group by product_id
having count(*) > 1



      
    ) dbt_internal_test
[0m04:09:37.719445 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.005 seconds
[0m04:09:37.726488 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: ROLLBACK
[0m04:09:37.730963 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: Close
[0m04:09:37.737873 [info ] [Thread-1 (]: 31 of 31 PASS unique_slv_products_product_id ................................... [[32mPASS[0m in 0.23s]
[0m04:09:37.743757 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m04:09:37.751513 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:37.755788 [debug] [MainThread]: On master: BEGIN
[0m04:09:37.758501 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:09:37.769571 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m04:09:37.771074 [debug] [MainThread]: On master: COMMIT
[0m04:09:37.773749 [debug] [MainThread]: Using postgres connection "master"
[0m04:09:37.776569 [debug] [MainThread]: On master: COMMIT
[0m04:09:37.779518 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m04:09:37.781599 [debug] [MainThread]: On master: Close
[0m04:09:37.784136 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:09:37.786315 [debug] [MainThread]: Connection 'test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb' was properly closed.
[0m04:09:37.788588 [info ] [MainThread]: 
[0m04:09:37.790155 [info ] [MainThread]: Finished running 31 data tests in 0 hours 0 minutes and 8.45 seconds (8.45s).
[0m04:09:37.800884 [debug] [MainThread]: Command end result
[0m04:09:38.146154 [info ] [MainThread]: 
[0m04:09:38.147844 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m04:09:38.150207 [info ] [MainThread]: 
[0m04:09:38.156064 [error] [MainThread]: [31mFailure in test unique_agg_customer_summary_buyer_username (models/gold/aggregates/_aggregates__models.yml)[0m
[0m04:09:38.164473 [error] [MainThread]:   Got 3 results, configured to fail if != 0
[0m04:09:38.170213 [info ] [MainThread]: 
[0m04:09:38.176517 [info ] [MainThread]:   compiled code at target/compiled/ecommerce_dbt/models/gold/aggregates/_aggregates__models.yml/unique_agg_customer_summary_buyer_username.sql
[0m04:09:38.181737 [info ] [MainThread]: 
[0m04:09:38.187636 [error] [MainThread]: [31mFailure in test unique_agg_product_performance_product_name (models/gold/aggregates/_aggregates__models.yml)[0m
[0m04:09:38.190898 [error] [MainThread]:   Got 37 results, configured to fail if != 0
[0m04:09:38.192686 [info ] [MainThread]: 
[0m04:09:38.194420 [info ] [MainThread]:   compiled code at target/compiled/ecommerce_dbt/models/gold/aggregates/_aggregates__models.yml/unique_agg_product_performance_product_name.sql
[0m04:09:38.196734 [info ] [MainThread]: 
[0m04:09:38.200116 [error] [MainThread]: [31mFailure in test unique_slv_orders_order_id (models/silver/_silver__models.yml)[0m
[0m04:09:38.205200 [error] [MainThread]:   Got 154 results, configured to fail if != 0
[0m04:09:38.207873 [info ] [MainThread]: 
[0m04:09:38.212381 [info ] [MainThread]:   compiled code at target/compiled/ecommerce_dbt/models/silver/_silver__models.yml/unique_slv_orders_order_id.sql
[0m04:09:38.214787 [info ] [MainThread]: 
[0m04:09:38.219196 [info ] [MainThread]: Done. PASS=28 WARN=0 ERROR=3 SKIP=0 TOTAL=31
[0m04:09:38.224305 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 12.260476, "process_user_time": 4.277922, "process_kernel_time": 0.68817, "process_mem_max_rss": "121840", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:09:38.229249 [debug] [MainThread]: Command `dbt test` failed at 04:09:38.228745 after 12.27 seconds
[0m04:09:38.232796 [debug] [MainThread]: Flushing usage events
[0m13:15:24.314437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d6f0b860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d6d173b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d75d9e20>]}


============================== 13:15:24.327578 | 1fdd3b5b-a815-48f8-b48a-7db8b6ac8692 ==============================
[0m13:15:24.327578 [info ] [MainThread]: Running with dbt=1.8.0
[0m13:15:24.329526 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:15:24.572863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d6e5b830>]}
[0m13:15:24.664195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d6b04710>]}
[0m13:15:24.667781 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m13:15:24.694975 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m13:15:24.960650 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:15:24.961853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d75d9460>]}
[0m13:15:28.178423 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m13:15:28.179616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d4b10f20>]}
[0m13:15:28.803864 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.staging
- models.ecommerce_dbt.marts
[0m13:15:28.826256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d5b56900>]}
[0m13:15:29.142815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d4b0f110>]}
[0m13:15:29.146286 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m13:15:29.148064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d6ab9760>]}
[0m13:15:29.150776 [info ] [MainThread]: 
[0m13:15:29.156232 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:15:29.166824 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m13:15:29.226432 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:15:29.228360 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:15:29.229967 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:15:29.246367 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.016 seconds
[0m13:15:29.249572 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:15:29.256312 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:15:29.259160 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:15:29.260720 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:15:29.281677 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.021 seconds
[0m13:15:29.290525 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:15:29.297557 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:15:29.300318 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:15:29.302413 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:15:29.319746 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.017 seconds
[0m13:15:29.326871 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:15:29.333418 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics_silver)
[0m13:15:29.340974 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:15:29.361827 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m13:15:29.374790 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:15:29.403312 [debug] [ThreadPool]: SQL status: BEGIN in 0.029 seconds
[0m13:15:29.404029 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:15:29.404701 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m13:15:29.412306 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.007 seconds
[0m13:15:29.415243 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m13:15:29.416682 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m13:15:29.427227 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics_gold)
[0m13:15:29.434681 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:15:29.436815 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m13:15:29.437558 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:15:29.444652 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m13:15:29.445938 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:15:29.446536 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m13:15:29.449748 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m13:15:29.453422 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m13:15:29.454169 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m13:15:29.454907 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now list_ecommerce_db_analytics_bronze)
[0m13:15:29.459009 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:15:29.459885 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m13:15:29.460818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:15:29.468569 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m13:15:29.471000 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:15:29.472080 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m13:15:29.477522 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m13:15:29.480089 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m13:15:29.481065 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m13:15:29.482122 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics)
[0m13:15:29.484343 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:15:29.486049 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m13:15:29.486871 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:15:29.494658 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m13:15:29.495333 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:15:29.495941 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:15:29.498874 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.002 seconds
[0m13:15:29.501011 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m13:15:29.501896 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m13:15:29.506534 [debug] [MainThread]: Using postgres connection "master"
[0m13:15:29.507391 [debug] [MainThread]: On master: BEGIN
[0m13:15:29.507902 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:15:29.515058 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m13:15:29.515784 [debug] [MainThread]: Using postgres connection "master"
[0m13:15:29.516421 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:15:29.524192 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m13:15:29.527547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d4b30170>]}
[0m13:15:29.529174 [debug] [MainThread]: On master: ROLLBACK
[0m13:15:29.530365 [debug] [MainThread]: Using postgres connection "master"
[0m13:15:29.530831 [debug] [MainThread]: On master: BEGIN
[0m13:15:29.531772 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:15:29.532854 [debug] [MainThread]: On master: COMMIT
[0m13:15:29.533642 [debug] [MainThread]: Using postgres connection "master"
[0m13:15:29.534812 [debug] [MainThread]: On master: COMMIT
[0m13:15:29.536468 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:15:29.537266 [debug] [MainThread]: On master: Close
[0m13:15:29.538276 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:15:29.541446 [info ] [MainThread]: 
[0m13:15:29.546982 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m13:15:29.551622 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m13:15:29.559231 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now model.ecommerce_dbt.brz_raw_orders)
[0m13:15:29.564285 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m13:15:29.582466 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:29.714040 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m13:15:29.775775 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:29.870935 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:29.879356 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m13:15:29.885539 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:29.909226 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m13:15:29.914164 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:29.918320 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    

select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m13:15:29.949226 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.028 seconds
[0m13:15:29.960111 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:29.961499 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m13:15:29.965679 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m13:15:29.973215 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:29.974983 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m13:15:29.977212 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:30.003453 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m13:15:30.008858 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:30.011825 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m13:15:30.016848 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:15:30.029998 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m13:15:30.036535 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:15:30.037826 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m13:15:30.045879 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.007 seconds
[0m13:15:30.051101 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m13:15:30.056506 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d75da720>]}
[0m13:15:30.058270 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.49s]
[0m13:15:30.062855 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m13:15:30.067261 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m13:15:30.070986 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m13:15:30.073755 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m13:15:30.077697 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m13:15:30.081795 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m13:15:30.161115 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m13:15:30.216977 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m13:15:30.264392 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:15:30.266631 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m13:15:30.268386 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:30.286275 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m13:15:30.288933 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:15:30.291788 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null and trim(buyer_username) != ''
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        COALESCE(NULLIF(trim(buyer_username), ''), 'guest_' || row_number() over (order by recipient_name)) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m13:15:30.338055 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.043 seconds
[0m13:15:30.348074 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:15:30.351643 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m13:15:30.356942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:30.365970 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:15:30.367378 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m13:15:30.369858 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:30.381659 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m13:15:30.384113 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:15:30.385185 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m13:15:30.390850 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m13:15:30.396091 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m13:15:30.404061 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:15:30.405845 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m13:15:30.417266 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.009 seconds
[0m13:15:30.422042 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m13:15:30.423505 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d0803110>]}
[0m13:15:30.426169 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 268[0m in 0.35s]
[0m13:15:30.428060 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m13:15:30.430648 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m13:15:30.433109 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m13:15:30.437556 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m13:15:30.438757 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m13:15:30.449704 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m13:15:30.538451 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m13:15:30.546716 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m13:15:30.604447 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:15:30.606671 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m13:15:30.608407 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:30.626875 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m13:15:30.629540 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:15:30.632526 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m13:15:30.654850 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.020 seconds
[0m13:15:30.664965 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:15:30.668565 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m13:15:30.671166 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:30.682087 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:15:30.684396 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m13:15:30.687503 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:30.692394 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m13:15:30.695011 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:15:30.697007 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m13:15:30.701124 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:15:30.706630 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m13:15:30.709148 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:15:30.711522 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m13:15:30.717281 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:15:30.720752 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m13:15:30.722773 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d0823590>]}
[0m13:15:30.726042 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.29s]
[0m13:15:30.728496 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m13:15:30.729679 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m13:15:30.730554 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m13:15:30.732235 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m13:15:30.733649 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m13:15:30.744487 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m13:15:30.822072 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m13:15:30.825850 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m13:15:30.892382 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:15:30.894487 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m13:15:30.896082 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:30.908866 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:15:30.910035 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:15:30.911721 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        COALESCE(NULLIF(trim(buyer_username), ''), 'guest_' || order_id) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m13:15:30.942033 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.026 seconds
[0m13:15:30.947496 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:15:30.948661 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders" rename to "slv_orders__dbt_backup"
[0m13:15:30.953279 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:30.960296 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:15:30.961828 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp" rename to "slv_orders"
[0m13:15:30.964949 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:30.966974 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m13:15:30.968834 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:15:30.969976 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m13:15:30.974303 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:15:30.977238 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup"
[0m13:15:30.979184 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:15:30.980809 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup" cascade
[0m13:15:30.985589 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:15:30.987583 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m13:15:30.990307 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d0856750>]}
[0m13:15:30.992133 [info ] [Thread-1 (]: 4 of 14 OK created sql table model analytics_silver.slv_orders ................. [[32mSELECT 516[0m in 0.26s]
[0m13:15:30.993818 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m13:15:30.994887 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m13:15:30.996112 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m13:15:30.997816 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m13:15:30.999202 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m13:15:31.005968 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m13:15:31.066824 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m13:15:31.082137 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m13:15:31.138167 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:15:31.138853 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m13:15:31.147713 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:31.170940 [debug] [Thread-1 (]: SQL status: BEGIN in 0.023 seconds
[0m13:15:31.181829 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:15:31.190133 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders (one row per product_name, keeping highest price variant)
unique_products as (
    select distinct on (product_name)
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
    order by product_name, original_price desc
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m13:15:31.207966 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.012 seconds
[0m13:15:31.217952 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:15:31.218904 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products" rename to "slv_products__dbt_backup"
[0m13:15:31.222031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:31.225731 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:15:31.226963 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m13:15:31.229876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:31.244441 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m13:15:31.252003 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:15:31.261668 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m13:15:31.283539 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:15:31.305870 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m13:15:31.316259 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:15:31.322902 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m13:15:31.330763 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:15:31.337173 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m13:15:31.340259 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d0800410>]}
[0m13:15:31.345020 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 45[0m in 0.34s]
[0m13:15:31.350488 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m13:15:31.354083 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m13:15:31.355873 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m13:15:31.361766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m13:15:31.362679 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m13:15:31.370676 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m13:15:31.465195 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m13:15:31.473284 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m13:15:31.518468 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:15:31.520583 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m13:15:31.522581 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:31.538135 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m13:15:31.540538 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:15:31.542053 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m13:15:31.556471 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.012 seconds
[0m13:15:31.560994 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:15:31.562799 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m13:15:31.566461 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:31.574896 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:15:31.576396 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m13:15:31.581462 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:31.584799 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m13:15:31.586701 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:15:31.589400 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m13:15:31.594911 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:15:31.602396 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m13:15:31.605498 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:15:31.607199 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m13:15:31.617480 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m13:15:31.622706 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m13:15:31.626255 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d0834b00>]}
[0m13:15:31.629845 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.26s]
[0m13:15:31.634159 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m13:15:31.636602 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m13:15:31.637907 [info ] [Thread-1 (]: 7 of 14 START sql table model analytics_gold.dim_customer ...................... [RUN]
[0m13:15:31.638757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_date, now model.ecommerce_dbt.dim_customer)
[0m13:15:31.639464 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_customer
[0m13:15:31.648362 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_customer"
[0m13:15:31.729689 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_customer
[0m13:15:31.737955 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_customer"
[0m13:15:31.813828 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:15:31.815172 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: BEGIN
[0m13:15:31.817789 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:31.828752 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:15:31.829617 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:15:31.831063 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Dimension
-- Business-ready customer data with RFM segmentation



with customers as (
    select * from "ecommerce_db"."analytics_silver"."slv_customers"
),

-- Calculate order aggregates per customer
order_stats as (
    select
        buyer_username,
        count(distinct order_id) as total_orders,
        sum(order_total_vnd) as total_spent,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by buyer_username
),

-- RFM calculation
rfm_calc as (
    select
        c.*,
        coalesce(o.total_orders, 0) as total_orders,
        coalesce(o.total_spent, 0) as total_spent,
        coalesce(o.avg_order_value, 0) as avg_order_value,
        o.first_order_date,
        o.last_order_date,
        coalesce(o.days_since_last_order, 999) as days_since_last_order,
        
        -- RFM Scores (1-5 scale)
        ntile(5) over (order by coalesce(o.days_since_last_order, 999) desc) as r_score,
        ntile(5) over (order by coalesce(o.total_orders, 0)) as f_score,
        ntile(5) over (order by coalesce(o.total_spent, 0)) as m_score
        
    from customers c
    left join order_stats o on c.buyer_username = o.buyer_username
),

final as (
    select
        customer_id,
        buyer_username,
        recipient_name,
        phone_number,
        
        -- Geography
        province,
        district,
        ward,
        shipping_address,
        country,
        region,
        
        -- Customer key
        customer_key,
        
        -- Order metrics
        total_orders,
        total_spent,
        avg_order_value,
        first_order_date,
        last_order_date,
        days_since_last_order,
        
        -- RFM Scores
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score as rfm_score,
        
        -- RFM Segment
        case
            when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
            when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
            when r_score >= 4 and f_score <= 2 then 'Recent Customers'
            when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
            when r_score <= 2 and f_score >= 4 then 'At Risk'
            when r_score <= 2 and f_score >= 2 then 'Hibernating'
            when r_score <= 2 and f_score <= 2 then 'Lost'
            else 'Other'
        end as customer_segment,
        
        -- Customer lifecycle
        case 
            when total_orders = 1 then 'New'
            when total_orders between 2 and 3 then 'Returning'
            when total_orders between 4 and 10 then 'Regular'
            when total_orders > 10 then 'VIP'
            else 'Prospect'
        end as customer_lifecycle,
        
        -- Customer value tier
        case
            when total_spent >= 5000000 then 'Platinum'
            when total_spent >= 2000000 then 'Gold'
            when total_spent >= 500000 then 'Silver'
            else 'Bronze'
        end as customer_value_tier,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from rfm_calc
)

select * from final
  );
  
[0m13:15:31.849781 [debug] [Thread-1 (]: SQL status: SELECT 268 in 0.017 seconds
[0m13:15:31.865409 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:15:31.868875 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer" rename to "dim_customer__dbt_backup"
[0m13:15:31.872454 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:31.879186 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:15:31.881122 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m13:15:31.884399 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:15:31.887561 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m13:15:31.889820 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:15:31.891065 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m13:15:31.894296 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:15:31.899295 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup"
[0m13:15:31.904698 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:15:31.906077 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup" cascade
[0m13:15:31.916636 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m13:15:31.922558 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: Close
[0m13:15:31.925190 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d2111af0>]}
[0m13:15:31.926492 [info ] [Thread-1 (]: 7 of 14 OK created sql table model analytics_gold.dim_customer ................. [[32mSELECT 268[0m in 0.29s]
[0m13:15:31.928340 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m13:15:31.933217 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m13:15:31.938264 [info ] [Thread-1 (]: 8 of 14 START sql table model analytics_gold.dim_payment ....................... [RUN]
[0m13:15:31.939593 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_customer, now model.ecommerce_dbt.dim_payment)
[0m13:15:31.940950 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_payment
[0m13:15:31.950799 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_payment"
[0m13:15:32.050776 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_payment
[0m13:15:32.059810 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_payment"
[0m13:15:32.127483 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:15:32.129154 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: BEGIN
[0m13:15:32.131433 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:32.143233 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:15:32.144167 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:15:32.145488 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Payment Dimension
-- Extracted from orders, enriched with payment grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique payment methods
unique_payments as (
    select distinct
        payment_method
    from source
    where payment_method is not null
),

enriched as (
    select
        row_number() over (order by payment_method) as payment_method_id,
        trim(payment_method) as payment_method,
        
        -- Payment method grouping
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'COD'
            when payment_method ilike '%shopee%' or payment_method ilike '%spay%' or payment_method ilike '%shopeepay%' then 'ShopeePay'
            when payment_method ilike '%momo%' then 'MoMo'
            when payment_method ilike '%zalo%' then 'ZaloPay'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Credit/Debit Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank Transfer'
            when payment_method ilike '%vnpay%' then 'VNPay'
            else 'Other'
        end as payment_group,
        
        -- Payment type
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'Cash'
            when payment_method ilike '%shopee%' or payment_method ilike '%momo%' or payment_method ilike '%zalo%' or payment_method ilike '%vnpay%' then 'E-Wallet'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank'
            else 'Other'
        end as payment_type,
        
        -- Is digital payment
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then false
            else true
        end as is_digital_payment,
        
        -- Payment key
        md5(coalesce(payment_method, 'unknown')) as payment_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_payments
)

select * from enriched
  );
  
[0m13:15:32.157579 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.011 seconds
[0m13:15:32.165072 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:15:32.166608 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment" rename to "dim_payment__dbt_backup"
[0m13:15:32.169833 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:32.179762 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:15:32.181239 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp" rename to "dim_payment"
[0m13:15:32.184498 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:32.188766 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m13:15:32.192019 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:15:32.194183 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m13:15:32.198168 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:15:32.200953 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup"
[0m13:15:32.202861 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:15:32.204608 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup" cascade
[0m13:15:32.209855 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:15:32.212855 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: Close
[0m13:15:32.214531 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d2291b50>]}
[0m13:15:32.216597 [info ] [Thread-1 (]: 8 of 14 OK created sql table model analytics_gold.dim_payment .................. [[32mSELECT 6[0m in 0.27s]
[0m13:15:32.219597 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m13:15:32.221838 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m13:15:32.223134 [info ] [Thread-1 (]: 9 of 14 START sql table model analytics_gold.dim_shipping ...................... [RUN]
[0m13:15:32.224373 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_payment, now model.ecommerce_dbt.dim_shipping)
[0m13:15:32.225533 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_shipping
[0m13:15:32.234143 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.292804 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_shipping
[0m13:15:32.301736 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.390099 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.390890 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: BEGIN
[0m13:15:32.391559 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:32.402284 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:15:32.403217 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.404017 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Shipping Dimension
-- Extracted from orders, enriched with carrier grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique shipping carriers
unique_carriers as (
    select distinct
        shipping_carrier,
        shipping_method
    from source
    where shipping_carrier is not null
),

enriched as (
    select
        row_number() over (order by shipping_carrier) as shipping_id,
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        
        -- Carrier grouping/normalization
        case
            when shipping_carrier ilike '%giao hang nhanh%' or shipping_carrier ilike '%ghn%' then 'GHN'
            when shipping_carrier ilike '%giao hang tiet kiem%' or shipping_carrier ilike '%ghtk%' then 'GHTK'
            when shipping_carrier ilike '%j&t%' or shipping_carrier ilike '%jt%' then 'J&T Express'
            when shipping_carrier ilike '%shopee express%' or shipping_carrier ilike '%spx%' then 'Shopee Express'
            when shipping_carrier ilike '%viettel%' then 'Viettel Post'
            when shipping_carrier ilike '%grab%' then 'GrabExpress'
            when shipping_carrier ilike '%ninja van%' then 'Ninja Van'
            when shipping_carrier ilike '%best%' then 'BEST Express'
            else 'Other'
        end as carrier_group,
        
        -- Carrier type
        case
            when shipping_carrier ilike '%shopee%' or shipping_carrier ilike '%spx%' then 'Platform Logistics'
            when shipping_carrier ilike '%grab%' then 'On-Demand'
            else 'Third Party Logistics'
        end as carrier_type,
        
        -- Shipping key
        md5(coalesce(shipping_carrier, 'unknown')) as shipping_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_carriers
)

select * from enriched
  );
  
[0m13:15:32.413022 [debug] [Thread-1 (]: SQL status: SELECT 9 in 0.007 seconds
[0m13:15:32.418989 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.421150 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping" rename to "dim_shipping__dbt_backup"
[0m13:15:32.422771 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:32.429557 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.430582 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp" rename to "dim_shipping"
[0m13:15:32.433043 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:32.435970 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m13:15:32.437553 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.439456 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m13:15:32.442715 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:15:32.447859 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup"
[0m13:15:32.450398 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:15:32.451820 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup" cascade
[0m13:15:32.457622 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:15:32.461373 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: Close
[0m13:15:32.463915 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d4f337d0>]}
[0m13:15:32.465383 [info ] [Thread-1 (]: 9 of 14 OK created sql table model analytics_gold.dim_shipping ................. [[32mSELECT 9[0m in 0.24s]
[0m13:15:32.466839 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m13:15:32.468288 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m13:15:32.470030 [info ] [Thread-1 (]: 10 of 14 START sql table model analytics_gold.dim_product ...................... [RUN]
[0m13:15:32.471250 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_shipping, now model.ecommerce_dbt.dim_product)
[0m13:15:32.472301 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_product
[0m13:15:32.477766 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_product"
[0m13:15:32.536043 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_product
[0m13:15:32.544900 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_product"
[0m13:15:32.599791 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:15:32.601548 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: BEGIN
[0m13:15:32.603137 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:32.611916 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:15:32.613484 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:15:32.619837 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Dimension
-- Business-ready product data with performance metrics



with products as (
    select * from "ecommerce_db"."analytics_silver"."slv_products"
),

-- Calculate product performance
product_stats as (
    select
        product_name,
        count(distinct order_id) as total_orders,
        sum(quantity) as total_quantity_sold,
        sum(order_total_vnd) as total_revenue,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by product_name
),

final as (
    select
        p.product_id,
        p.product_name,
        p.product_sku,
        p.variant_name,
        p.variant_sku,
        p.main_category,
        
        -- Pricing
        p.original_price,
        p.discounted_price,
        case 
            when p.original_price > 0 
            then round((1 - p.discounted_price / p.original_price) * 100, 2)
            else 0
        end as discount_percentage,
        
        -- Weight
        p.product_weight,
        
        -- Product key
        p.product_key,
        
        -- Performance metrics
        coalesce(s.total_orders, 0) as total_orders,
        coalesce(s.total_quantity_sold, 0) as total_quantity_sold,
        coalesce(s.total_revenue, 0) as total_revenue,
        coalesce(s.avg_order_value, 0) as avg_order_value,
        s.first_sold_date,
        s.last_sold_date,
        
        -- Product tier based on revenue
        case
            when s.total_revenue >= 10000000 then 'Star Product'
            when s.total_revenue >= 5000000 then 'High Performer'
            when s.total_revenue >= 1000000 then 'Moderate'
            when s.total_revenue > 0 then 'Low Performer'
            else 'No Sales'
        end as product_tier,
        
        -- Velocity
        case 
            when s.total_quantity_sold >= 50 then 'Fast Moving'
            when s.total_quantity_sold >= 20 then 'Medium Moving'
            when s.total_quantity_sold >= 5 then 'Slow Moving'
            else 'Very Slow'
        end as sales_velocity,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from products p
    left join product_stats s on p.product_name = s.product_name
)

select * from final
  );
  
[0m13:15:32.630183 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.009 seconds
[0m13:15:32.636334 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:15:32.638776 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product" rename to "dim_product__dbt_backup"
[0m13:15:32.642008 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:32.649032 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:15:32.656397 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp" rename to "dim_product"
[0m13:15:32.663718 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m13:15:32.675449 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m13:15:32.690618 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:15:32.695940 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m13:15:32.701205 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:15:32.705683 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_product__dbt_backup"
[0m13:15:32.709892 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:15:32.710962 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_product__dbt_backup" cascade
[0m13:15:32.715748 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:15:32.727440 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: Close
[0m13:15:32.729241 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d088d010>]}
[0m13:15:32.730696 [info ] [Thread-1 (]: 10 of 14 OK created sql table model analytics_gold.dim_product ................. [[32mSELECT 45[0m in 0.26s]
[0m13:15:32.732028 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m13:15:32.733897 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m13:15:32.735142 [info ] [Thread-1 (]: 11 of 14 START sql table model analytics_gold.fct_orders ....................... [RUN]
[0m13:15:32.736176 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_product, now model.ecommerce_dbt.fct_orders)
[0m13:15:32.737177 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.fct_orders
[0m13:15:32.748405 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.fct_orders"
[0m13:15:32.796214 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.fct_orders
[0m13:15:32.804202 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.fct_orders"
[0m13:15:32.893765 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:15:32.898027 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: BEGIN
[0m13:15:32.901563 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:32.911273 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:15:32.912203 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:15:32.914152 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Fact Orders
-- Main fact table - Star Schema center
-- Joins all dimensions with measures



with orders as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

customers as (
    select customer_id, buyer_username, customer_key, region, customer_segment
    from "ecommerce_db"."analytics_gold"."dim_customer"
),

products as (
    select distinct on (product_name)
        product_id, product_name, product_key, main_category, product_tier
    from "ecommerce_db"."analytics_gold"."dim_product"
    order by product_name, product_id
),

dates as (
    select date_key, date, is_double_day_sale, sale_event_name
    from "ecommerce_db"."analytics_gold"."dim_date"
),

shipping as (
    select shipping_id, shipping_carrier, shipping_key, carrier_group
    from "ecommerce_db"."analytics_gold"."dim_shipping"
),

payment as (
    select payment_method_id, payment_method, payment_key, payment_group
    from "ecommerce_db"."analytics_gold"."dim_payment"
),

-- Customer order sequence
order_sequence as (
    select
        order_id,
        buyer_username,
        row_number() over (
            partition by buyer_username 
            order by order_date
        ) as customer_order_seq
    from orders
),

fact_orders as (
    select
        -- Primary key
        o.order_id,
        
        -- Dimension keys (foreign keys)
        c.customer_id,
        p.product_id,
        d.date_key as order_date_key,
        s.shipping_id,
        pm.payment_method_id,
        
        -- Surrogate keys (for BI tools)
        c.customer_key,
        p.product_key,
        s.shipping_key,
        pm.payment_key,
        
        -- Natural keys (for reference)
        o.package_id,
        o.tracking_number,
        o.buyer_username,
        
        -- Date dimensions
        o.order_date,
        o.expected_delivery_date,
        o.actual_delivery_date,
        o.order_completed_date,
        o.payment_date,
        
        -- Delivery metrics
        case
            when o.actual_delivery_date is not null and o.order_date is not null
            then extract(day from o.actual_delivery_date - o.order_date)
            else null
        end as delivery_days,
        
        case
            when o.actual_delivery_date is not null and o.expected_delivery_date is not null
            then case 
                when o.actual_delivery_date <= o.expected_delivery_date then 'On Time'
                else 'Late'
            end
            else 'Unknown'
        end as delivery_status,
        
        -- Order status
        o.order_status,
        o.order_type,
        o.return_status,
        
        -- Product details (denormalized for performance)
        o.product_name,
        o.variant_name,
        o.product_weight,
        p.main_category,
        
        -- Quantity and pricing (MEASURES)
        o.quantity,
        o.original_price,
        o.discount_price,
        o.total_product_price,
        o.order_total_vnd,
        
        -- Discount breakdown (MEASURES)
        o.seller_discount,
        o.shopee_discount,
        o.shop_voucher,
        o.shopee_voucher,
        o.coins_cashback,
        o.total_discount,
        
        -- Shipping costs (MEASURES)
        o.shipping_fee_estimated,
        o.shipping_fee_paid,
        o.shipping_subsidy,
        
        -- Payment (MEASURES)
        o.total_paid,
        o.payment_method,
        
        -- Fees (MEASURES)
        o.fixed_fee,
        o.service_fee,
        o.payment_fee,
        o.deposit,
        
        -- Calculated measures
        o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee as net_revenue,
        
        case
            when o.original_price > 0 
            then round(((o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee) / (o.original_price * o.quantity)) * 100, 2)
            else 0
        end as profit_margin_pct,
        
        -- Order value tier
        case
            when o.order_total_vnd >= 1000000 then 'Premium (1M+)'
            when o.order_total_vnd >= 500000 then 'High (500K-1M)'
            when o.order_total_vnd >= 200000 then 'Medium (200K-500K)'
            when o.order_total_vnd >= 100000 then 'Low (100K-200K)'
            else 'Micro (<100K)'
        end as order_value_tier,
        
        -- Customer location (denormalized)
        o.province,
        o.district,
        c.region,
        
        -- Shipping info (denormalized)
        o.shipping_carrier,
        s.carrier_group,
        
        -- Payment info (denormalized)
        pm.payment_group,
        
        -- Customer order sequence
        seq.customer_order_seq,
        case when seq.customer_order_seq = 1 then 'New' else 'Repeat' end as new_vs_repeat,
        
        -- Sale event (denormalized from date)
        d.is_double_day_sale,
        d.sale_event_name,
        
        -- Flags
        o.is_bestseller,
        case when o.return_status is not null and o.return_status != '' then true else false end as is_returned,
        case when o.order_status in ('Ho√†n th√†nh', 'complete', 'completed', 'Completed') then true else false end as is_completed,
        case when o.order_status in ('ƒê√£ h·ªßy', 'cancelled', 'Cancelled', 'cancel') then true else false end as is_cancelled,
        
        -- Metadata
        o.source_file,
        o.source_loaded_at,
        current_timestamp as _gold_loaded_at
        
    from orders o
    left join customers c on o.buyer_username = c.buyer_username
    left join products p on o.product_name = p.product_name
    left join dates d on cast(o.order_date as date) = d.date
    left join shipping s on o.shipping_carrier = s.shipping_carrier
    left join payment pm on o.payment_method = pm.payment_method
    left join order_sequence seq on o.order_id = seq.order_id
)

select * from fact_orders
  );
  
[0m13:15:32.957095 [debug] [Thread-1 (]: SQL status: SELECT 1672 in 0.042 seconds
[0m13:15:32.961682 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:15:32.966298 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders" rename to "fct_orders__dbt_backup"
[0m13:15:32.969423 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:32.977294 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:15:32.978930 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp" rename to "fct_orders"
[0m13:15:32.981627 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:15:32.984030 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m13:15:32.984856 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:15:32.985481 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m13:15:32.989625 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:15:32.994155 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup"
[0m13:15:32.995751 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:15:32.996715 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
drop table if exists "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup" cascade
[0m13:15:33.005941 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m13:15:33.008572 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: Close
[0m13:15:33.010689 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d5b56e40>]}
[0m13:15:33.012979 [info ] [Thread-1 (]: 11 of 14 OK created sql table model analytics_gold.fct_orders .................. [[32mSELECT 1672[0m in 0.27s]
[0m13:15:33.015636 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m13:15:33.018751 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m13:15:33.020137 [info ] [Thread-1 (]: 12 of 14 START sql table model analytics_gold.agg_customer_summary ............. [RUN]
[0m13:15:33.021123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.fct_orders, now model.ecommerce_dbt.agg_customer_summary)
[0m13:15:33.022086 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_customer_summary
[0m13:15:33.026149 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.114279 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_customer_summary
[0m13:15:33.121987 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.201660 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.204028 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: BEGIN
[0m13:15:33.206932 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:33.220003 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:15:33.222133 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.224237 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Summary Aggregate
-- Customer-level aggregated metrics with RFM



with customer_orders as (
    select
        buyer_username,
        customer_id,
        region,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Quantity
        sum(quantity) as total_items_purchased,
        
        -- Revenue
        sum(order_total_vnd) as total_spent,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Time metrics
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order,
        
        -- Product diversity
        count(distinct product_name) as unique_products_ordered,
        count(distinct main_category) as unique_categories,
        
        -- Shipping preferences
        mode() within group (order by carrier_group) as preferred_carrier,
        mode() within group (order by payment_group) as preferred_payment
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where buyer_username is not null
    group by 1, 2, 3
),

with_rfm as (
    select
        *,
        
        -- RFM Scores
        ntile(5) over (order by days_since_last_order desc nulls last) as r_score,
        ntile(5) over (order by total_orders asc nulls first) as f_score,
        ntile(5) over (order by total_spent asc nulls first) as m_score
        
    from customer_orders
    where total_orders > 0
)

select
    buyer_username,
    customer_id,
    region,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    total_items_purchased,
    
    -- Revenue metrics
    total_spent,
    total_net_revenue,
    avg_order_value,
    
    -- Time metrics
    first_order_date,
    last_order_date,
    days_since_last_order,
    
    -- Tenure (days as customer)
    current_date - first_order_date::date as customer_tenure_days,
    
    -- Frequency (orders per month)
    case 
        when current_date - first_order_date::date > 30 
        then round(total_orders * 30.0 / (current_date - first_order_date::date), 2)
        else total_orders
    end as orders_per_month,
    
    -- Product diversity
    unique_products_ordered,
    unique_categories,
    
    -- Preferences
    preferred_carrier,
    preferred_payment,
    
    -- RFM
    r_score,
    f_score,
    m_score,
    r_score * 100 + f_score * 10 + m_score as rfm_score,
    
    -- RFM Segment
    case
        when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
        when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
        when r_score >= 4 and f_score <= 2 then 'Recent Customers'
        when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
        when r_score <= 2 and f_score >= 4 then 'At Risk'
        when r_score <= 2 and f_score >= 2 then 'Hibernating'
        when r_score <= 2 and f_score <= 2 then 'Lost'
        else 'Other'
    end as customer_segment,
    
    -- Customer lifecycle
    case 
        when total_orders = 1 then 'New'
        when total_orders between 2 and 3 then 'Returning'
        when total_orders between 4 and 10 then 'Regular'
        when total_orders > 10 then 'VIP'
    end as customer_lifecycle,
    
    -- Value tier
    case
        when total_spent >= 5000000 then 'Platinum'
        when total_spent >= 2000000 then 'Gold'
        when total_spent >= 500000 then 'Silver'
        else 'Bronze'
    end as customer_value_tier,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from with_rfm
order by total_spent desc
  );
  
[0m13:15:33.265588 [debug] [Thread-1 (]: SQL status: SELECT 321 in 0.040 seconds
[0m13:15:33.269773 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.270933 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary" rename to "agg_customer_summary__dbt_backup"
[0m13:15:33.272486 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:33.276775 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.277801 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp" rename to "agg_customer_summary"
[0m13:15:33.279423 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:33.282826 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m13:15:33.283807 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.284655 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m13:15:33.287204 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:15:33.291122 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup"
[0m13:15:33.292783 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:15:33.293779 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup" cascade
[0m13:15:33.298525 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:15:33.301098 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: Close
[0m13:15:33.302485 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d0867890>]}
[0m13:15:33.305911 [info ] [Thread-1 (]: 12 of 14 OK created sql table model analytics_gold.agg_customer_summary ........ [[32mSELECT 321[0m in 0.28s]
[0m13:15:33.307076 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m13:15:33.307765 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m13:15:33.308471 [info ] [Thread-1 (]: 13 of 14 START sql table model analytics_gold.agg_daily_sales .................. [RUN]
[0m13:15:33.309155 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_customer_summary, now model.ecommerce_dbt.agg_daily_sales)
[0m13:15:33.311083 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_daily_sales
[0m13:15:33.315458 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.361921 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_daily_sales
[0m13:15:33.376215 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.459835 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.462291 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: BEGIN
[0m13:15:33.465646 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:33.475686 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:15:33.477117 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.477886 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Daily Sales Aggregate
-- Daily sales metrics for dashboards



with daily_orders as (
    select
        cast(order_date as date) as order_date,
        order_date_key,
        is_double_day_sale,
        sale_event_name,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_cancelled then order_id end) as cancelled_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        count(distinct case when new_vs_repeat = 'Repeat' then buyer_username end) as repeat_customers,
        
        -- Product counts
        count(distinct product_name) as unique_products,
        sum(quantity) as total_quantity,
        
        -- Revenue metrics
        sum(order_total_vnd) as gross_revenue,
        sum(net_revenue) as net_revenue,
        sum(total_discount) as total_discount,
        sum(shipping_fee_paid) as total_shipping,
        
        -- Fee breakdown
        sum(fixed_fee) as total_fixed_fee,
        sum(service_fee) as total_service_fee,
        sum(payment_fee) as total_payment_fee,
        
        -- Averages
        avg(order_total_vnd) as avg_order_value,
        avg(quantity) as avg_items_per_order,
        avg(delivery_days) as avg_delivery_days,
        
        -- By order value tier
        count(distinct case when order_value_tier = 'Premium (1M+)' then order_id end) as premium_orders,
        count(distinct case when order_value_tier = 'Micro (<100K)' then order_id end) as micro_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    group by 1, 2, 3, 4
)

select
    d.*,
    
    -- Completion rate
    case 
        when total_orders > 0 
        then round(completed_orders * 100.0 / total_orders, 2)
        else 0 
    end as completion_rate_pct,
    
    -- Cancellation rate
    case 
        when total_orders > 0 
        then round(cancelled_orders * 100.0 / total_orders, 2)
        else 0 
    end as cancellation_rate_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- New customer rate
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from daily_orders d
order by order_date desc
  );
  
[0m13:15:33.491639 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.013 seconds
[0m13:15:33.497663 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.498692 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales" rename to "agg_daily_sales__dbt_backup"
[0m13:15:33.500807 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:33.504003 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.505050 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp" rename to "agg_daily_sales"
[0m13:15:33.506903 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:33.511393 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m13:15:33.512735 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.513775 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m13:15:33.516828 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:15:33.519570 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup"
[0m13:15:33.520947 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:15:33.521971 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup" cascade
[0m13:15:33.525977 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:15:33.528182 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: Close
[0m13:15:33.529493 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d22906e0>]}
[0m13:15:33.530679 [info ] [Thread-1 (]: 13 of 14 OK created sql table model analytics_gold.agg_daily_sales ............. [[32mSELECT 111[0m in 0.22s]
[0m13:15:33.531647 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m13:15:33.533502 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m13:15:33.534957 [info ] [Thread-1 (]: 14 of 14 START sql table model analytics_gold.agg_product_performance .......... [RUN]
[0m13:15:33.536608 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_daily_sales, now model.ecommerce_dbt.agg_product_performance)
[0m13:15:33.537499 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_product_performance
[0m13:15:33.541502 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.578379 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_product_performance
[0m13:15:33.582308 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.656061 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.660731 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: BEGIN
[0m13:15:33.662457 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:15:33.674609 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:15:33.675687 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.677054 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Performance Aggregate
-- Product-level aggregated metrics



with product_orders as (
    select
        product_name,
        product_id,
        main_category,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        
        -- Quantity
        sum(quantity) as total_quantity_sold,
        avg(quantity) as avg_quantity_per_order,
        
        -- Revenue
        sum(order_total_vnd) as total_revenue,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Pricing
        avg(original_price) as avg_original_price,
        avg(discount_price) as avg_discount_price,
        sum(total_discount) as total_discount_given,
        
        -- Time metrics
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date,
        current_date - max(order_date)::date as days_since_last_sale,
        
        -- Geography
        mode() within group (order by region) as top_region,
        
        -- Sale events
        count(distinct case when is_double_day_sale then order_id end) as sale_event_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where product_name is not null
    group by 1, 2, 3
)

select
    product_name,
    product_id,
    main_category,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    
    -- Customer metrics
    unique_customers,
    new_customers,
    
    -- Quantity metrics
    total_quantity_sold,
    avg_quantity_per_order,
    
    -- Revenue metrics
    total_revenue,
    total_net_revenue,
    avg_order_value,
    
    -- Pricing metrics
    avg_original_price,
    avg_discount_price,
    total_discount_given,
    
    -- Discount percentage
    case 
        when avg_original_price > 0 
        then round((1 - avg_discount_price / avg_original_price) * 100, 2)
        else 0 
    end as avg_discount_pct,
    
    -- Time metrics
    first_sold_date,
    last_sold_date,
    days_since_last_sale,
    
    -- Selling period (days)
    last_sold_date::date - first_sold_date::date as selling_period_days,
    
    -- Sales velocity (units per day)
    case 
        when last_sold_date::date - first_sold_date::date > 0 
        then round(total_quantity_sold * 1.0 / (last_sold_date::date - first_sold_date::date + 1), 2)
        else total_quantity_sold
    end as daily_sales_velocity,
    
    -- Top region
    top_region,
    
    -- Sale event performance
    sale_event_orders,
    case 
        when total_orders > 0 
        then round(sale_event_orders * 100.0 / total_orders, 2)
        else 0 
    end as sale_event_order_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Customer acquisition
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_pct,
    
    -- Product tier
    case
        when total_revenue >= 10000000 then 'Star Product'
        when total_revenue >= 5000000 then 'High Performer'
        when total_revenue >= 1000000 then 'Moderate'
        when total_revenue > 0 then 'Low Performer'
        else 'No Sales'
    end as product_tier,
    
    -- Sales velocity category
    case 
        when total_quantity_sold >= 50 then 'Fast Moving'
        when total_quantity_sold >= 20 then 'Medium Moving'
        when total_quantity_sold >= 5 then 'Slow Moving'
        else 'Very Slow'
    end as sales_velocity_category,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from product_orders
order by total_revenue desc
  );
  
[0m13:15:33.704899 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.024 seconds
[0m13:15:33.709075 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.710878 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance" rename to "agg_product_performance__dbt_backup"
[0m13:15:33.713121 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:33.719918 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.721925 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp" rename to "agg_product_performance"
[0m13:15:33.724452 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:15:33.730372 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m13:15:33.732304 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.736617 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m13:15:33.741739 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:15:33.749677 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup"
[0m13:15:33.752955 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:15:33.754688 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup" cascade
[0m13:15:33.763762 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m13:15:33.768309 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: Close
[0m13:15:33.772014 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fdd3b5b-a815-48f8-b48a-7db8b6ac8692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d21c2540>]}
[0m13:15:33.773488 [info ] [Thread-1 (]: 14 of 14 OK created sql table model analytics_gold.agg_product_performance ..... [[32mSELECT 45[0m in 0.24s]
[0m13:15:33.774812 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m13:15:33.778644 [debug] [MainThread]: Using postgres connection "master"
[0m13:15:33.779687 [debug] [MainThread]: On master: BEGIN
[0m13:15:33.780752 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:15:33.795553 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m13:15:33.796822 [debug] [MainThread]: On master: COMMIT
[0m13:15:33.797977 [debug] [MainThread]: Using postgres connection "master"
[0m13:15:33.798867 [debug] [MainThread]: On master: COMMIT
[0m13:15:33.800840 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m13:15:33.804028 [debug] [MainThread]: On master: Close
[0m13:15:33.806195 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:15:33.806963 [debug] [MainThread]: Connection 'model.ecommerce_dbt.agg_product_performance' was properly closed.
[0m13:15:33.807950 [info ] [MainThread]: 
[0m13:15:33.809093 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 4.65 seconds (4.65s).
[0m13:15:33.814063 [debug] [MainThread]: Command end result
[0m13:15:34.093336 [info ] [MainThread]: 
[0m13:15:34.097898 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:15:34.099926 [info ] [MainThread]: 
[0m13:15:34.101247 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
[0m13:15:34.107582 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.900332, "process_user_time": 6.209397, "process_kernel_time": 0.548589, "process_mem_max_rss": "126248", "process_in_blocks": "2304", "process_out_blocks": "0"}
[0m13:15:34.113536 [debug] [MainThread]: Command `dbt run` succeeded at 13:15:34.113225 after 9.91 seconds
[0m13:15:34.115049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d6d173b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591d6b045c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7591dabb6e70>]}
[0m13:15:34.119791 [debug] [MainThread]: Flushing usage events
[0m13:17:11.303515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef24211cb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef24165ea80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef242438320>]}


============================== 13:17:11.315325 | fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6 ==============================
[0m13:17:11.315325 [info ] [MainThread]: Running with dbt=1.8.0
[0m13:17:11.317504 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'send_anonymous_usage_stats': 'True'}
[0m13:17:11.638643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef24127bef0>]}
[0m13:17:11.708363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef2403bed80>]}
[0m13:17:11.711360 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m13:17:11.754615 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m13:17:13.805856 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m13:17:13.808086 [debug] [MainThread]: Partial parsing: updated file: ecommerce_dbt://models/gold/dimensions/dim_shipping.sql
[0m13:17:13.812613 [debug] [MainThread]: Partial parsing: updated file: ecommerce_dbt://models/silver/slv_customers.sql
[0m13:17:14.119780 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m13:17:14.120780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23ff54230>]}
[0m13:17:14.365445 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.staging
- models.ecommerce_dbt.marts
[0m13:17:14.389880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23efa93a0>]}
[0m13:17:14.688982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23d53c9b0>]}
[0m13:17:14.690436 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m13:17:14.694996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef2421954c0>]}
[0m13:17:14.698471 [info ] [MainThread]: 
[0m13:17:14.701069 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:17:14.717596 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m13:17:14.769361 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:17:14.772786 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:17:14.780206 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:17:14.798359 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.018 seconds
[0m13:17:14.804158 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:17:14.813081 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:17:14.821358 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:17:14.827948 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:14.846800 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.019 seconds
[0m13:17:14.853413 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:17:14.859325 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:17:14.862229 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:17:14.865038 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:14.879248 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.015 seconds
[0m13:17:14.886742 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:17:14.891496 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics_gold)
[0m13:17:14.903299 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:17:14.904894 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m13:17:14.905682 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:14.921442 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m13:17:14.923426 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:17:14.925342 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m13:17:14.929353 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m13:17:14.933222 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m13:17:14.934621 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m13:17:14.935974 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now list_ecommerce_db_analytics_silver)
[0m13:17:14.938861 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:17:14.939758 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m13:17:14.940512 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:14.948205 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m13:17:14.949356 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:17:14.950039 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m13:17:14.953451 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.003 seconds
[0m13:17:14.956150 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m13:17:14.957328 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m13:17:14.959096 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics_bronze)
[0m13:17:14.961536 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:17:14.962206 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m13:17:14.963978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:14.972041 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m13:17:14.973177 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:17:14.973877 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m13:17:14.977481 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m13:17:14.980565 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m13:17:14.981811 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m13:17:14.983636 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics)
[0m13:17:14.987772 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:17:14.988727 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m13:17:14.989821 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:15.001388 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m13:17:15.002710 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:17:15.004778 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:17:15.013311 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m13:17:15.023098 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m13:17:15.030314 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m13:17:15.047250 [debug] [MainThread]: Using postgres connection "master"
[0m13:17:15.051640 [debug] [MainThread]: On master: BEGIN
[0m13:17:15.055786 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:17:15.073877 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m13:17:15.077561 [debug] [MainThread]: Using postgres connection "master"
[0m13:17:15.079666 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:17:15.095215 [debug] [MainThread]: SQL status: SELECT 1 in 0.012 seconds
[0m13:17:15.100151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23c93aab0>]}
[0m13:17:15.104782 [debug] [MainThread]: On master: ROLLBACK
[0m13:17:15.106536 [debug] [MainThread]: Using postgres connection "master"
[0m13:17:15.109827 [debug] [MainThread]: On master: BEGIN
[0m13:17:15.113060 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m13:17:15.117744 [debug] [MainThread]: On master: COMMIT
[0m13:17:15.119298 [debug] [MainThread]: Using postgres connection "master"
[0m13:17:15.120468 [debug] [MainThread]: On master: COMMIT
[0m13:17:15.122963 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m13:17:15.125871 [debug] [MainThread]: On master: Close
[0m13:17:15.128791 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:17:15.132686 [info ] [MainThread]: 
[0m13:17:15.137061 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m13:17:15.140722 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m13:17:15.141670 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now model.ecommerce_dbt.brz_raw_orders)
[0m13:17:15.147572 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m13:17:15.165307 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.232422 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m13:17:15.336991 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.351376 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.352106 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m13:17:15.352618 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:15.361073 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m13:17:15.368703 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.371104 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    

select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m13:17:15.383254 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m13:17:15.391893 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.395759 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m13:17:15.399126 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:15.405947 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.409282 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m13:17:15.414151 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m13:17:15.445159 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m13:17:15.447137 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.451631 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m13:17:15.455377 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:15.471865 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m13:17:15.486716 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:17:15.489751 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m13:17:15.497222 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.004 seconds
[0m13:17:15.504121 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m13:17:15.511476 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef242b5eff0>]}
[0m13:17:15.515656 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.37s]
[0m13:17:15.520056 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m13:17:15.522085 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m13:17:15.523276 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m13:17:15.524771 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m13:17:15.528432 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m13:17:15.534834 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m13:17:15.550714 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m13:17:15.576580 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m13:17:15.648205 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:17:15.655568 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m13:17:15.662595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:15.683592 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m13:17:15.686991 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:17:15.690151 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct on (buyer_username)
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null and trim(buyer_username) != ''
    order by buyer_username, recipient_name
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        COALESCE(NULLIF(trim(buyer_username), ''), 'guest_' || row_number() over (order by recipient_name)) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m13:17:15.715209 [debug] [Thread-1 (]: SQL status: SELECT 265 in 0.021 seconds
[0m13:17:15.725071 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:17:15.729476 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m13:17:15.731608 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:15.741049 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:17:15.743730 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m13:17:15.745593 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:15.756607 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m13:17:15.757817 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:17:15.763852 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m13:17:15.768017 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:15.775093 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m13:17:15.782904 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:17:15.785533 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m13:17:15.793489 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m13:17:15.796067 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m13:17:15.799885 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef2403bc5f0>]}
[0m13:17:15.801466 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 265[0m in 0.28s]
[0m13:17:15.805297 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m13:17:15.806477 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m13:17:15.807782 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m13:17:15.808958 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m13:17:15.812077 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m13:17:15.818202 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m13:17:15.848157 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m13:17:15.855593 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m13:17:15.909996 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:17:15.911196 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m13:17:15.912801 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:15.929018 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m13:17:15.931784 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:17:15.939492 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m13:17:15.955141 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.011 seconds
[0m13:17:15.963089 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:17:15.968012 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m13:17:15.977261 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:15.987555 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:17:15.989648 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m13:17:15.992093 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:17:15.994448 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m13:17:15.995533 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:17:15.997076 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m13:17:16.000817 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:16.006448 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m13:17:16.008061 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:17:16.009267 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m13:17:16.015797 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:17:16.022522 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m13:17:16.028129 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23f7a0dd0>]}
[0m13:17:16.030219 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.22s]
[0m13:17:16.033885 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m13:17:16.036464 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m13:17:16.043489 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m13:17:16.049953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m13:17:16.051546 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m13:17:16.062592 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m13:17:16.104705 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m13:17:16.108713 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m13:17:16.148730 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:17:16.152948 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m13:17:16.154878 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:16.165627 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:17:16.168516 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:17:16.174725 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        COALESCE(NULLIF(trim(buyer_username), ''), 'guest_' || order_id) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m13:17:16.200498 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.024 seconds
[0m13:17:16.230223 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:17:16.252575 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders" rename to "slv_orders__dbt_backup"
[0m13:17:16.270152 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.282018 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:17:16.291729 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp" rename to "slv_orders"
[0m13:17:16.303761 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.310022 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m13:17:16.313290 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:17:16.315786 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m13:17:16.324652 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m13:17:16.329330 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup"
[0m13:17:16.335268 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:17:16.339595 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup" cascade
[0m13:17:16.345193 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:17:16.349419 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m13:17:16.350965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23c908560>]}
[0m13:17:16.354259 [info ] [Thread-1 (]: 4 of 14 OK created sql table model analytics_silver.slv_orders ................. [[32mSELECT 516[0m in 0.30s]
[0m13:17:16.355561 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m13:17:16.356716 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m13:17:16.359263 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m13:17:16.361319 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m13:17:16.362624 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m13:17:16.367674 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m13:17:16.410636 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m13:17:16.417177 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m13:17:16.433406 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:17:16.437261 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m13:17:16.438203 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:16.446993 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:17:16.448189 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:17:16.449516 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders (one row per product_name, keeping highest price variant)
unique_products as (
    select distinct on (product_name)
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
    order by product_name, original_price desc
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m13:17:16.457477 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.007 seconds
[0m13:17:16.460538 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:17:16.461298 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products" rename to "slv_products__dbt_backup"
[0m13:17:16.463128 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.466332 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:17:16.467448 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m13:17:16.468927 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.472643 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m13:17:16.473647 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:17:16.474811 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m13:17:16.477964 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:16.481676 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m13:17:16.483116 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:17:16.486314 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m13:17:16.491494 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:17:16.494504 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m13:17:16.495914 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23c9b07a0>]}
[0m13:17:16.499171 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 45[0m in 0.13s]
[0m13:17:16.501764 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m13:17:16.502807 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m13:17:16.503732 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m13:17:16.505645 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m13:17:16.508386 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m13:17:16.515347 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m13:17:16.558849 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m13:17:16.566568 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m13:17:16.606575 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:17:16.607306 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m13:17:16.610517 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:16.619092 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:17:16.619799 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:17:16.620475 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m13:17:16.628761 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.008 seconds
[0m13:17:16.633877 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:17:16.634892 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m13:17:16.636338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.640099 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:17:16.641354 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m13:17:16.646652 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.652129 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m13:17:16.653919 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:17:16.654948 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m13:17:16.659092 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:17:16.662597 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m13:17:16.666204 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:17:16.667411 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m13:17:16.670553 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m13:17:16.678272 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m13:17:16.681554 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23f382c90>]}
[0m13:17:16.682769 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.18s]
[0m13:17:16.684070 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m13:17:16.688202 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m13:17:16.690790 [info ] [Thread-1 (]: 7 of 14 START sql table model analytics_gold.dim_customer ...................... [RUN]
[0m13:17:16.694748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_date, now model.ecommerce_dbt.dim_customer)
[0m13:17:16.697771 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_customer
[0m13:17:16.701704 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_customer"
[0m13:17:16.757669 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_customer
[0m13:17:16.762378 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_customer"
[0m13:17:16.801792 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:17:16.804496 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: BEGIN
[0m13:17:16.805940 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:16.816176 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:17:16.819096 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:17:16.820190 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Dimension
-- Business-ready customer data with RFM segmentation



with customers as (
    select * from "ecommerce_db"."analytics_silver"."slv_customers"
),

-- Calculate order aggregates per customer
order_stats as (
    select
        buyer_username,
        count(distinct order_id) as total_orders,
        sum(order_total_vnd) as total_spent,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by buyer_username
),

-- RFM calculation
rfm_calc as (
    select
        c.*,
        coalesce(o.total_orders, 0) as total_orders,
        coalesce(o.total_spent, 0) as total_spent,
        coalesce(o.avg_order_value, 0) as avg_order_value,
        o.first_order_date,
        o.last_order_date,
        coalesce(o.days_since_last_order, 999) as days_since_last_order,
        
        -- RFM Scores (1-5 scale)
        ntile(5) over (order by coalesce(o.days_since_last_order, 999) desc) as r_score,
        ntile(5) over (order by coalesce(o.total_orders, 0)) as f_score,
        ntile(5) over (order by coalesce(o.total_spent, 0)) as m_score
        
    from customers c
    left join order_stats o on c.buyer_username = o.buyer_username
),

final as (
    select
        customer_id,
        buyer_username,
        recipient_name,
        phone_number,
        
        -- Geography
        province,
        district,
        ward,
        shipping_address,
        country,
        region,
        
        -- Customer key
        customer_key,
        
        -- Order metrics
        total_orders,
        total_spent,
        avg_order_value,
        first_order_date,
        last_order_date,
        days_since_last_order,
        
        -- RFM Scores
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score as rfm_score,
        
        -- RFM Segment
        case
            when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
            when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
            when r_score >= 4 and f_score <= 2 then 'Recent Customers'
            when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
            when r_score <= 2 and f_score >= 4 then 'At Risk'
            when r_score <= 2 and f_score >= 2 then 'Hibernating'
            when r_score <= 2 and f_score <= 2 then 'Lost'
            else 'Other'
        end as customer_segment,
        
        -- Customer lifecycle
        case 
            when total_orders = 1 then 'New'
            when total_orders between 2 and 3 then 'Returning'
            when total_orders between 4 and 10 then 'Regular'
            when total_orders > 10 then 'VIP'
            else 'Prospect'
        end as customer_lifecycle,
        
        -- Customer value tier
        case
            when total_spent >= 5000000 then 'Platinum'
            when total_spent >= 2000000 then 'Gold'
            when total_spent >= 500000 then 'Silver'
            else 'Bronze'
        end as customer_value_tier,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from rfm_calc
)

select * from final
  );
  
[0m13:17:16.834565 [debug] [Thread-1 (]: SQL status: SELECT 265 in 0.012 seconds
[0m13:17:16.843434 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:17:16.845349 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer" rename to "dim_customer__dbt_backup"
[0m13:17:16.847617 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.852065 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:17:16.852901 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m13:17:16.853893 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:17:16.855866 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m13:17:16.857242 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:17:16.858050 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m13:17:16.861031 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:16.866145 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup"
[0m13:17:16.867379 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:17:16.868754 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup" cascade
[0m13:17:16.872533 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:17:16.874308 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: Close
[0m13:17:16.877011 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23ffadbb0>]}
[0m13:17:16.878567 [info ] [Thread-1 (]: 7 of 14 OK created sql table model analytics_gold.dim_customer ................. [[32mSELECT 265[0m in 0.18s]
[0m13:17:16.880698 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m13:17:16.881900 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m13:17:16.882889 [info ] [Thread-1 (]: 8 of 14 START sql table model analytics_gold.dim_payment ....................... [RUN]
[0m13:17:16.883775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_customer, now model.ecommerce_dbt.dim_payment)
[0m13:17:16.884682 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_payment
[0m13:17:16.890256 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_payment"
[0m13:17:16.911493 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_payment
[0m13:17:16.915659 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_payment"
[0m13:17:16.931780 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:17:16.932427 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: BEGIN
[0m13:17:16.932965 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:16.940714 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m13:17:16.941579 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:17:16.942315 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Payment Dimension
-- Extracted from orders, enriched with payment grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique payment methods
unique_payments as (
    select distinct
        payment_method
    from source
    where payment_method is not null
),

enriched as (
    select
        row_number() over (order by payment_method) as payment_method_id,
        trim(payment_method) as payment_method,
        
        -- Payment method grouping
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'COD'
            when payment_method ilike '%shopee%' or payment_method ilike '%spay%' or payment_method ilike '%shopeepay%' then 'ShopeePay'
            when payment_method ilike '%momo%' then 'MoMo'
            when payment_method ilike '%zalo%' then 'ZaloPay'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Credit/Debit Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank Transfer'
            when payment_method ilike '%vnpay%' then 'VNPay'
            else 'Other'
        end as payment_group,
        
        -- Payment type
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'Cash'
            when payment_method ilike '%shopee%' or payment_method ilike '%momo%' or payment_method ilike '%zalo%' or payment_method ilike '%vnpay%' then 'E-Wallet'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank'
            else 'Other'
        end as payment_type,
        
        -- Is digital payment
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then false
            else true
        end as is_digital_payment,
        
        -- Payment key
        md5(coalesce(payment_method, 'unknown')) as payment_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_payments
)

select * from enriched
  );
  
[0m13:17:16.948921 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.006 seconds
[0m13:17:16.952957 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:17:16.953747 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment" rename to "dim_payment__dbt_backup"
[0m13:17:16.955342 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:16.959572 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:17:16.960519 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp" rename to "dim_payment"
[0m13:17:16.961845 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:17:16.966326 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m13:17:16.967321 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:17:16.968208 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m13:17:16.972538 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m13:17:16.975304 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup"
[0m13:17:16.978740 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:17:16.979610 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup" cascade
[0m13:17:16.983548 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:17:16.987137 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: Close
[0m13:17:16.988548 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23f3c5490>]}
[0m13:17:16.989859 [info ] [Thread-1 (]: 8 of 14 OK created sql table model analytics_gold.dim_payment .................. [[32mSELECT 6[0m in 0.10s]
[0m13:17:16.994807 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m13:17:17.003129 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m13:17:17.008152 [info ] [Thread-1 (]: 9 of 14 START sql table model analytics_gold.dim_shipping ...................... [RUN]
[0m13:17:17.009436 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_payment, now model.ecommerce_dbt.dim_shipping)
[0m13:17:17.013444 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_shipping
[0m13:17:17.017739 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.110947 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_shipping
[0m13:17:17.123179 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.161928 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.165317 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: BEGIN
[0m13:17:17.169521 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:17.187058 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m13:17:17.201922 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.209950 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Shipping Dimension
-- Extracted from orders, enriched with carrier grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique shipping carriers
unique_carriers as (
    select distinct on (shipping_carrier)
        shipping_carrier,
        shipping_method
    from source
    where shipping_carrier is not null
    order by shipping_carrier, shipping_method
),

enriched as (
    select
        row_number() over (order by shipping_carrier) as shipping_id,
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        
        -- Carrier grouping/normalization
        case
            when shipping_carrier ilike '%giao hang nhanh%' or shipping_carrier ilike '%ghn%' then 'GHN'
            when shipping_carrier ilike '%giao hang tiet kiem%' or shipping_carrier ilike '%ghtk%' then 'GHTK'
            when shipping_carrier ilike '%j&t%' or shipping_carrier ilike '%jt%' then 'J&T Express'
            when shipping_carrier ilike '%shopee express%' or shipping_carrier ilike '%spx%' then 'Shopee Express'
            when shipping_carrier ilike '%viettel%' then 'Viettel Post'
            when shipping_carrier ilike '%grab%' then 'GrabExpress'
            when shipping_carrier ilike '%ninja van%' then 'Ninja Van'
            when shipping_carrier ilike '%best%' then 'BEST Express'
            else 'Other'
        end as carrier_group,
        
        -- Carrier type
        case
            when shipping_carrier ilike '%shopee%' or shipping_carrier ilike '%spx%' then 'Platform Logistics'
            when shipping_carrier ilike '%grab%' then 'On-Demand'
            else 'Third Party Logistics'
        end as carrier_type,
        
        -- Shipping key
        md5(coalesce(shipping_carrier, 'unknown')) as shipping_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_carriers
)

select * from enriched
  );
  
[0m13:17:17.227728 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.008 seconds
[0m13:17:17.251099 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.261924 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping" rename to "dim_shipping__dbt_backup"
[0m13:17:17.273407 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:17.290911 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.310400 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp" rename to "dim_shipping"
[0m13:17:17.321871 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:17.339841 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m13:17:17.342963 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.349212 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m13:17:17.357625 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:17.365694 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup"
[0m13:17:17.371723 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:17:17.377827 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup" cascade
[0m13:17:17.386675 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:17:17.393004 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: Close
[0m13:17:17.398003 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23f37b6b0>]}
[0m13:17:17.405160 [info ] [Thread-1 (]: 9 of 14 OK created sql table model analytics_gold.dim_shipping ................. [[32mSELECT 6[0m in 0.39s]
[0m13:17:17.411998 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m13:17:17.419715 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m13:17:17.425530 [info ] [Thread-1 (]: 10 of 14 START sql table model analytics_gold.dim_product ...................... [RUN]
[0m13:17:17.426669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_shipping, now model.ecommerce_dbt.dim_product)
[0m13:17:17.431194 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_product
[0m13:17:17.436210 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_product"
[0m13:17:17.509036 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_product
[0m13:17:17.523612 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_product"
[0m13:17:17.584560 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:17:17.586544 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: BEGIN
[0m13:17:17.588719 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:17.601177 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:17:17.604944 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:17:17.606832 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Dimension
-- Business-ready product data with performance metrics



with products as (
    select * from "ecommerce_db"."analytics_silver"."slv_products"
),

-- Calculate product performance
product_stats as (
    select
        product_name,
        count(distinct order_id) as total_orders,
        sum(quantity) as total_quantity_sold,
        sum(order_total_vnd) as total_revenue,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by product_name
),

final as (
    select
        p.product_id,
        p.product_name,
        p.product_sku,
        p.variant_name,
        p.variant_sku,
        p.main_category,
        
        -- Pricing
        p.original_price,
        p.discounted_price,
        case 
            when p.original_price > 0 
            then round((1 - p.discounted_price / p.original_price) * 100, 2)
            else 0
        end as discount_percentage,
        
        -- Weight
        p.product_weight,
        
        -- Product key
        p.product_key,
        
        -- Performance metrics
        coalesce(s.total_orders, 0) as total_orders,
        coalesce(s.total_quantity_sold, 0) as total_quantity_sold,
        coalesce(s.total_revenue, 0) as total_revenue,
        coalesce(s.avg_order_value, 0) as avg_order_value,
        s.first_sold_date,
        s.last_sold_date,
        
        -- Product tier based on revenue
        case
            when s.total_revenue >= 10000000 then 'Star Product'
            when s.total_revenue >= 5000000 then 'High Performer'
            when s.total_revenue >= 1000000 then 'Moderate'
            when s.total_revenue > 0 then 'Low Performer'
            else 'No Sales'
        end as product_tier,
        
        -- Velocity
        case 
            when s.total_quantity_sold >= 50 then 'Fast Moving'
            when s.total_quantity_sold >= 20 then 'Medium Moving'
            when s.total_quantity_sold >= 5 then 'Slow Moving'
            else 'Very Slow'
        end as sales_velocity,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from products p
    left join product_stats s on p.product_name = s.product_name
)

select * from final
  );
  
[0m13:17:17.617005 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.008 seconds
[0m13:17:17.621752 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:17:17.624749 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product" rename to "dim_product__dbt_backup"
[0m13:17:17.626380 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:17.631080 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:17:17.632018 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp" rename to "dim_product"
[0m13:17:17.633495 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:17.636550 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m13:17:17.637766 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:17:17.638755 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m13:17:17.641295 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:17.646073 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_product__dbt_backup"
[0m13:17:17.647653 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:17:17.648719 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_product__dbt_backup" cascade
[0m13:17:17.655199 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:17:17.659051 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: Close
[0m13:17:17.660964 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23f37a1b0>]}
[0m13:17:17.662978 [info ] [Thread-1 (]: 10 of 14 OK created sql table model analytics_gold.dim_product ................. [[32mSELECT 45[0m in 0.23s]
[0m13:17:17.666801 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m13:17:17.668593 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m13:17:17.669596 [info ] [Thread-1 (]: 11 of 14 START sql table model analytics_gold.fct_orders ....................... [RUN]
[0m13:17:17.673510 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_product, now model.ecommerce_dbt.fct_orders)
[0m13:17:17.674679 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.fct_orders
[0m13:17:17.682308 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.fct_orders"
[0m13:17:17.750541 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.fct_orders
[0m13:17:17.754114 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.fct_orders"
[0m13:17:17.772520 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:17:17.773319 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: BEGIN
[0m13:17:17.774117 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:17.783985 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:17:17.785609 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:17:17.786728 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Fact Orders
-- Main fact table - Star Schema center
-- Joins all dimensions with measures



with orders as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

customers as (
    select customer_id, buyer_username, customer_key, region, customer_segment
    from "ecommerce_db"."analytics_gold"."dim_customer"
),

products as (
    select distinct on (product_name)
        product_id, product_name, product_key, main_category, product_tier
    from "ecommerce_db"."analytics_gold"."dim_product"
    order by product_name, product_id
),

dates as (
    select date_key, date, is_double_day_sale, sale_event_name
    from "ecommerce_db"."analytics_gold"."dim_date"
),

shipping as (
    select shipping_id, shipping_carrier, shipping_key, carrier_group
    from "ecommerce_db"."analytics_gold"."dim_shipping"
),

payment as (
    select payment_method_id, payment_method, payment_key, payment_group
    from "ecommerce_db"."analytics_gold"."dim_payment"
),

-- Customer order sequence
order_sequence as (
    select
        order_id,
        buyer_username,
        row_number() over (
            partition by buyer_username 
            order by order_date
        ) as customer_order_seq
    from orders
),

fact_orders as (
    select
        -- Primary key
        o.order_id,
        
        -- Dimension keys (foreign keys)
        c.customer_id,
        p.product_id,
        d.date_key as order_date_key,
        s.shipping_id,
        pm.payment_method_id,
        
        -- Surrogate keys (for BI tools)
        c.customer_key,
        p.product_key,
        s.shipping_key,
        pm.payment_key,
        
        -- Natural keys (for reference)
        o.package_id,
        o.tracking_number,
        o.buyer_username,
        
        -- Date dimensions
        o.order_date,
        o.expected_delivery_date,
        o.actual_delivery_date,
        o.order_completed_date,
        o.payment_date,
        
        -- Delivery metrics
        case
            when o.actual_delivery_date is not null and o.order_date is not null
            then extract(day from o.actual_delivery_date - o.order_date)
            else null
        end as delivery_days,
        
        case
            when o.actual_delivery_date is not null and o.expected_delivery_date is not null
            then case 
                when o.actual_delivery_date <= o.expected_delivery_date then 'On Time'
                else 'Late'
            end
            else 'Unknown'
        end as delivery_status,
        
        -- Order status
        o.order_status,
        o.order_type,
        o.return_status,
        
        -- Product details (denormalized for performance)
        o.product_name,
        o.variant_name,
        o.product_weight,
        p.main_category,
        
        -- Quantity and pricing (MEASURES)
        o.quantity,
        o.original_price,
        o.discount_price,
        o.total_product_price,
        o.order_total_vnd,
        
        -- Discount breakdown (MEASURES)
        o.seller_discount,
        o.shopee_discount,
        o.shop_voucher,
        o.shopee_voucher,
        o.coins_cashback,
        o.total_discount,
        
        -- Shipping costs (MEASURES)
        o.shipping_fee_estimated,
        o.shipping_fee_paid,
        o.shipping_subsidy,
        
        -- Payment (MEASURES)
        o.total_paid,
        o.payment_method,
        
        -- Fees (MEASURES)
        o.fixed_fee,
        o.service_fee,
        o.payment_fee,
        o.deposit,
        
        -- Calculated measures
        o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee as net_revenue,
        
        case
            when o.original_price > 0 
            then round(((o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee) / (o.original_price * o.quantity)) * 100, 2)
            else 0
        end as profit_margin_pct,
        
        -- Order value tier
        case
            when o.order_total_vnd >= 1000000 then 'Premium (1M+)'
            when o.order_total_vnd >= 500000 then 'High (500K-1M)'
            when o.order_total_vnd >= 200000 then 'Medium (200K-500K)'
            when o.order_total_vnd >= 100000 then 'Low (100K-200K)'
            else 'Micro (<100K)'
        end as order_value_tier,
        
        -- Customer location (denormalized)
        o.province,
        o.district,
        c.region,
        
        -- Shipping info (denormalized)
        o.shipping_carrier,
        s.carrier_group,
        
        -- Payment info (denormalized)
        pm.payment_group,
        
        -- Customer order sequence
        seq.customer_order_seq,
        case when seq.customer_order_seq = 1 then 'New' else 'Repeat' end as new_vs_repeat,
        
        -- Sale event (denormalized from date)
        d.is_double_day_sale,
        d.sale_event_name,
        
        -- Flags
        o.is_bestseller,
        case when o.return_status is not null and o.return_status != '' then true else false end as is_returned,
        case when o.order_status in ('Ho√†n th√†nh', 'complete', 'completed', 'Completed') then true else false end as is_completed,
        case when o.order_status in ('ƒê√£ h·ªßy', 'cancelled', 'Cancelled', 'cancel') then true else false end as is_cancelled,
        
        -- Metadata
        o.source_file,
        o.source_loaded_at,
        current_timestamp as _gold_loaded_at
        
    from orders o
    left join customers c on o.buyer_username = c.buyer_username
    left join products p on o.product_name = p.product_name
    left join dates d on cast(o.order_date as date) = d.date
    left join shipping s on o.shipping_carrier = s.shipping_carrier
    left join payment pm on o.payment_method = pm.payment_method
    left join order_sequence seq on o.order_id = seq.order_id
)

select * from fact_orders
  );
  
[0m13:17:17.822891 [debug] [Thread-1 (]: SQL status: SELECT 868 in 0.035 seconds
[0m13:17:17.835468 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:17:17.837634 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders" rename to "fct_orders__dbt_backup"
[0m13:17:17.840411 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:17.849233 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:17:17.851994 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp" rename to "fct_orders"
[0m13:17:17.856920 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:17.862260 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m13:17:17.869641 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:17:17.870768 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m13:17:17.876688 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:17.881430 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup"
[0m13:17:17.884770 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:17:17.891941 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
drop table if exists "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup" cascade
[0m13:17:17.903393 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:17:17.910782 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: Close
[0m13:17:17.916822 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23c9c6bd0>]}
[0m13:17:17.924607 [info ] [Thread-1 (]: 11 of 14 OK created sql table model analytics_gold.fct_orders .................. [[32mSELECT 868[0m in 0.24s]
[0m13:17:17.927371 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m13:17:17.933348 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m13:17:17.938626 [info ] [Thread-1 (]: 12 of 14 START sql table model analytics_gold.agg_customer_summary ............. [RUN]
[0m13:17:17.945096 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.fct_orders, now model.ecommerce_dbt.agg_customer_summary)
[0m13:17:17.953270 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_customer_summary
[0m13:17:17.965835 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.027707 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_customer_summary
[0m13:17:18.038485 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.085625 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.090541 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: BEGIN
[0m13:17:18.092958 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:18.106246 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:17:18.107881 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.111880 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Summary Aggregate
-- Customer-level aggregated metrics with RFM



with customer_orders as (
    select
        buyer_username,
        customer_id,
        region,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Quantity
        sum(quantity) as total_items_purchased,
        
        -- Revenue
        sum(order_total_vnd) as total_spent,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Time metrics
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order,
        
        -- Product diversity
        count(distinct product_name) as unique_products_ordered,
        count(distinct main_category) as unique_categories,
        
        -- Shipping preferences
        mode() within group (order by carrier_group) as preferred_carrier,
        mode() within group (order by payment_group) as preferred_payment
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where buyer_username is not null
    group by 1, 2, 3
),

with_rfm as (
    select
        *,
        
        -- RFM Scores
        ntile(5) over (order by days_since_last_order desc nulls last) as r_score,
        ntile(5) over (order by total_orders asc nulls first) as f_score,
        ntile(5) over (order by total_spent asc nulls first) as m_score
        
    from customer_orders
    where total_orders > 0
)

select
    buyer_username,
    customer_id,
    region,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    total_items_purchased,
    
    -- Revenue metrics
    total_spent,
    total_net_revenue,
    avg_order_value,
    
    -- Time metrics
    first_order_date,
    last_order_date,
    days_since_last_order,
    
    -- Tenure (days as customer)
    current_date - first_order_date::date as customer_tenure_days,
    
    -- Frequency (orders per month)
    case 
        when current_date - first_order_date::date > 30 
        then round(total_orders * 30.0 / (current_date - first_order_date::date), 2)
        else total_orders
    end as orders_per_month,
    
    -- Product diversity
    unique_products_ordered,
    unique_categories,
    
    -- Preferences
    preferred_carrier,
    preferred_payment,
    
    -- RFM
    r_score,
    f_score,
    m_score,
    r_score * 100 + f_score * 10 + m_score as rfm_score,
    
    -- RFM Segment
    case
        when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
        when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
        when r_score >= 4 and f_score <= 2 then 'Recent Customers'
        when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
        when r_score <= 2 and f_score >= 4 then 'At Risk'
        when r_score <= 2 and f_score >= 2 then 'Hibernating'
        when r_score <= 2 and f_score <= 2 then 'Lost'
        else 'Other'
    end as customer_segment,
    
    -- Customer lifecycle
    case 
        when total_orders = 1 then 'New'
        when total_orders between 2 and 3 then 'Returning'
        when total_orders between 4 and 10 then 'Regular'
        when total_orders > 10 then 'VIP'
    end as customer_lifecycle,
    
    -- Value tier
    case
        when total_spent >= 5000000 then 'Platinum'
        when total_spent >= 2000000 then 'Gold'
        when total_spent >= 500000 then 'Silver'
        else 'Bronze'
    end as customer_value_tier,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from with_rfm
order by total_spent desc
  );
  
[0m13:17:18.129947 [debug] [Thread-1 (]: SQL status: SELECT 318 in 0.015 seconds
[0m13:17:18.135782 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.137067 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary" rename to "agg_customer_summary__dbt_backup"
[0m13:17:18.138995 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:18.143700 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.146428 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp" rename to "agg_customer_summary"
[0m13:17:18.149219 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:18.154835 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m13:17:18.155870 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.157457 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m13:17:18.160555 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:18.164148 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup"
[0m13:17:18.165585 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:17:18.166722 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup" cascade
[0m13:17:18.170738 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:17:18.173346 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: Close
[0m13:17:18.175085 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23ffad8b0>]}
[0m13:17:18.177248 [info ] [Thread-1 (]: 12 of 14 OK created sql table model analytics_gold.agg_customer_summary ........ [[32mSELECT 318[0m in 0.23s]
[0m13:17:18.179075 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m13:17:18.181618 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m13:17:18.183059 [info ] [Thread-1 (]: 13 of 14 START sql table model analytics_gold.agg_daily_sales .................. [RUN]
[0m13:17:18.186062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_customer_summary, now model.ecommerce_dbt.agg_daily_sales)
[0m13:17:18.188154 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_daily_sales
[0m13:17:18.192883 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.231576 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_daily_sales
[0m13:17:18.239385 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.322431 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.326575 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: BEGIN
[0m13:17:18.329195 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:18.349348 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m13:17:18.357511 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.364814 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Daily Sales Aggregate
-- Daily sales metrics for dashboards



with daily_orders as (
    select
        cast(order_date as date) as order_date,
        order_date_key,
        is_double_day_sale,
        sale_event_name,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_cancelled then order_id end) as cancelled_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        count(distinct case when new_vs_repeat = 'Repeat' then buyer_username end) as repeat_customers,
        
        -- Product counts
        count(distinct product_name) as unique_products,
        sum(quantity) as total_quantity,
        
        -- Revenue metrics
        sum(order_total_vnd) as gross_revenue,
        sum(net_revenue) as net_revenue,
        sum(total_discount) as total_discount,
        sum(shipping_fee_paid) as total_shipping,
        
        -- Fee breakdown
        sum(fixed_fee) as total_fixed_fee,
        sum(service_fee) as total_service_fee,
        sum(payment_fee) as total_payment_fee,
        
        -- Averages
        avg(order_total_vnd) as avg_order_value,
        avg(quantity) as avg_items_per_order,
        avg(delivery_days) as avg_delivery_days,
        
        -- By order value tier
        count(distinct case when order_value_tier = 'Premium (1M+)' then order_id end) as premium_orders,
        count(distinct case when order_value_tier = 'Micro (<100K)' then order_id end) as micro_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    group by 1, 2, 3, 4
)

select
    d.*,
    
    -- Completion rate
    case 
        when total_orders > 0 
        then round(completed_orders * 100.0 / total_orders, 2)
        else 0 
    end as completion_rate_pct,
    
    -- Cancellation rate
    case 
        when total_orders > 0 
        then round(cancelled_orders * 100.0 / total_orders, 2)
        else 0 
    end as cancellation_rate_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- New customer rate
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from daily_orders d
order by order_date desc
  );
  
[0m13:17:18.395991 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.023 seconds
[0m13:17:18.402108 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.431880 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales" rename to "agg_daily_sales__dbt_backup"
[0m13:17:18.454489 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:18.471219 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.474243 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp" rename to "agg_daily_sales"
[0m13:17:18.477452 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:18.481670 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m13:17:18.489732 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.496584 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m13:17:18.504953 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:17:18.512715 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup"
[0m13:17:18.514487 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:17:18.515448 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup" cascade
[0m13:17:18.521671 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m13:17:18.524817 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: Close
[0m13:17:18.528641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23f399ac0>]}
[0m13:17:18.529868 [info ] [Thread-1 (]: 13 of 14 OK created sql table model analytics_gold.agg_daily_sales ............. [[32mSELECT 111[0m in 0.34s]
[0m13:17:18.530821 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m13:17:18.534434 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m13:17:18.536940 [info ] [Thread-1 (]: 14 of 14 START sql table model analytics_gold.agg_product_performance .......... [RUN]
[0m13:17:18.537919 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_daily_sales, now model.ecommerce_dbt.agg_product_performance)
[0m13:17:18.541183 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_product_performance
[0m13:17:18.546564 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.576493 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_product_performance
[0m13:17:18.582498 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.606667 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.611415 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: BEGIN
[0m13:17:18.612610 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:18.621808 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:17:18.624939 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.626151 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Performance Aggregate
-- Product-level aggregated metrics



with product_orders as (
    select
        product_name,
        product_id,
        main_category,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        
        -- Quantity
        sum(quantity) as total_quantity_sold,
        avg(quantity) as avg_quantity_per_order,
        
        -- Revenue
        sum(order_total_vnd) as total_revenue,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Pricing
        avg(original_price) as avg_original_price,
        avg(discount_price) as avg_discount_price,
        sum(total_discount) as total_discount_given,
        
        -- Time metrics
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date,
        current_date - max(order_date)::date as days_since_last_sale,
        
        -- Geography
        mode() within group (order by region) as top_region,
        
        -- Sale events
        count(distinct case when is_double_day_sale then order_id end) as sale_event_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where product_name is not null
    group by 1, 2, 3
)

select
    product_name,
    product_id,
    main_category,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    
    -- Customer metrics
    unique_customers,
    new_customers,
    
    -- Quantity metrics
    total_quantity_sold,
    avg_quantity_per_order,
    
    -- Revenue metrics
    total_revenue,
    total_net_revenue,
    avg_order_value,
    
    -- Pricing metrics
    avg_original_price,
    avg_discount_price,
    total_discount_given,
    
    -- Discount percentage
    case 
        when avg_original_price > 0 
        then round((1 - avg_discount_price / avg_original_price) * 100, 2)
        else 0 
    end as avg_discount_pct,
    
    -- Time metrics
    first_sold_date,
    last_sold_date,
    days_since_last_sale,
    
    -- Selling period (days)
    last_sold_date::date - first_sold_date::date as selling_period_days,
    
    -- Sales velocity (units per day)
    case 
        when last_sold_date::date - first_sold_date::date > 0 
        then round(total_quantity_sold * 1.0 / (last_sold_date::date - first_sold_date::date + 1), 2)
        else total_quantity_sold
    end as daily_sales_velocity,
    
    -- Top region
    top_region,
    
    -- Sale event performance
    sale_event_orders,
    case 
        when total_orders > 0 
        then round(sale_event_orders * 100.0 / total_orders, 2)
        else 0 
    end as sale_event_order_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Customer acquisition
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_pct,
    
    -- Product tier
    case
        when total_revenue >= 10000000 then 'Star Product'
        when total_revenue >= 5000000 then 'High Performer'
        when total_revenue >= 1000000 then 'Moderate'
        when total_revenue > 0 then 'Low Performer'
        else 'No Sales'
    end as product_tier,
    
    -- Sales velocity category
    case 
        when total_quantity_sold >= 50 then 'Fast Moving'
        when total_quantity_sold >= 20 then 'Medium Moving'
        when total_quantity_sold >= 5 then 'Slow Moving'
        else 'Very Slow'
    end as sales_velocity_category,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from product_orders
order by total_revenue desc
  );
  
[0m13:17:18.639882 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.013 seconds
[0m13:17:18.644047 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.646138 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance" rename to "agg_product_performance__dbt_backup"
[0m13:17:18.647797 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:18.652040 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.653080 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp" rename to "agg_product_performance"
[0m13:17:18.654666 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:17:18.658156 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m13:17:18.659473 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.660566 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m13:17:18.663720 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:17:18.668682 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup"
[0m13:17:18.672094 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:17:18.673325 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup" cascade
[0m13:17:18.676990 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:17:18.681127 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: Close
[0m13:17:18.686987 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8beb60-0c32-47ba-bf5c-5b8cc409d1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef23c93aa50>]}
[0m13:17:18.690235 [info ] [Thread-1 (]: 14 of 14 OK created sql table model analytics_gold.agg_product_performance ..... [[32mSELECT 45[0m in 0.15s]
[0m13:17:18.693895 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m13:17:18.698185 [debug] [MainThread]: Using postgres connection "master"
[0m13:17:18.703401 [debug] [MainThread]: On master: BEGIN
[0m13:17:18.708642 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:17:18.718615 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m13:17:18.721095 [debug] [MainThread]: On master: COMMIT
[0m13:17:18.722413 [debug] [MainThread]: Using postgres connection "master"
[0m13:17:18.724723 [debug] [MainThread]: On master: COMMIT
[0m13:17:18.729253 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:17:18.735666 [debug] [MainThread]: On master: Close
[0m13:17:18.738267 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:17:18.742245 [debug] [MainThread]: Connection 'model.ecommerce_dbt.agg_product_performance' was properly closed.
[0m13:17:18.744521 [info ] [MainThread]: 
[0m13:17:18.750379 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 4.04 seconds (4.04s).
[0m13:17:18.754490 [debug] [MainThread]: Command end result
[0m13:17:19.042206 [info ] [MainThread]: 
[0m13:17:19.044222 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:17:19.049970 [info ] [MainThread]: 
[0m13:17:19.055542 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
[0m13:17:19.059486 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.9539256, "process_user_time": 4.253331, "process_kernel_time": 0.461446, "process_mem_max_rss": "125420", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m13:17:19.063924 [debug] [MainThread]: Command `dbt run` succeeded at 13:17:19.063557 after 7.96 seconds
[0m13:17:19.067545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef2415e1820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef2414f8ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ef2415741d0>]}
[0m13:17:19.069277 [debug] [MainThread]: Flushing usage events
[0m13:18:44.690556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242a78bcb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242a621700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242a621610>]}


============================== 13:18:44.702505 | d0fdfae2-0a34-4fdb-bc77-2c58a90a4f64 ==============================
[0m13:18:44.702505 [info ] [MainThread]: Running with dbt=1.8.0
[0m13:18:44.705265 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:18:44.999520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242aeaf740>]}
[0m13:18:45.048709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242bc4ade0>]}
[0m13:18:45.076739 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m13:18:45.133165 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m13:18:46.400633 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:18:46.402460 [debug] [MainThread]: Partial parsing: updated file: ecommerce_dbt://models/gold/facts/fct_orders.sql
[0m13:18:46.608585 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m13:18:46.610292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7824287c09b0>]}
[0m13:18:46.796702 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.staging
- models.ecommerce_dbt.marts
[0m13:18:46.832066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242934ec60>]}
[0m13:18:47.174526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782427f934d0>]}
[0m13:18:47.176750 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m13:18:47.178180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242a753c80>]}
[0m13:18:47.185404 [info ] [MainThread]: 
[0m13:18:47.189420 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:18:47.196267 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db'
[0m13:18:47.250787 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:18:47.252128 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:18:47.253200 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:47.267031 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.014 seconds
[0m13:18:47.269524 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:18:47.274710 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:18:47.276975 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:18:47.278158 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:47.288361 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.010 seconds
[0m13:18:47.290399 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:18:47.293601 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db"
[0m13:18:47.294593 [debug] [ThreadPool]: On list_ecommerce_db: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db"} */

    select distinct nspname from pg_namespace
  
[0m13:18:47.295554 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:47.307763 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.012 seconds
[0m13:18:47.309585 [debug] [ThreadPool]: On list_ecommerce_db: Close
[0m13:18:47.317155 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db, now list_ecommerce_db_analytics)
[0m13:18:47.328061 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:18:47.334552 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m13:18:47.342280 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:47.355694 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m13:18:47.359930 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:18:47.361162 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:18:47.364748 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.002 seconds
[0m13:18:47.367174 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m13:18:47.368932 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m13:18:47.370134 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_silver)
[0m13:18:47.372577 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:18:47.374050 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m13:18:47.375127 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:47.382452 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m13:18:47.383367 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:18:47.384106 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m13:18:47.387228 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.002 seconds
[0m13:18:47.389290 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m13:18:47.390415 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m13:18:47.391436 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics_bronze)
[0m13:18:47.395098 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:18:47.397161 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m13:18:47.398010 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:47.406947 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m13:18:47.409187 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:18:47.410644 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m13:18:47.414861 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m13:18:47.418588 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m13:18:47.420141 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m13:18:47.421804 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics_gold)
[0m13:18:47.425862 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:18:47.426697 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m13:18:47.427476 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:47.437476 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m13:18:47.438762 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:18:47.439683 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m13:18:47.443457 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m13:18:47.446940 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m13:18:47.448170 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m13:18:47.460679 [debug] [MainThread]: Using postgres connection "master"
[0m13:18:47.462274 [debug] [MainThread]: On master: BEGIN
[0m13:18:47.465565 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:18:47.477256 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m13:18:47.479968 [debug] [MainThread]: Using postgres connection "master"
[0m13:18:47.482076 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:18:47.491828 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m13:18:47.494096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782425a47c20>]}
[0m13:18:47.495881 [debug] [MainThread]: On master: ROLLBACK
[0m13:18:47.498409 [debug] [MainThread]: Using postgres connection "master"
[0m13:18:47.499798 [debug] [MainThread]: On master: BEGIN
[0m13:18:47.501653 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m13:18:47.502669 [debug] [MainThread]: On master: COMMIT
[0m13:18:47.503503 [debug] [MainThread]: Using postgres connection "master"
[0m13:18:47.504258 [debug] [MainThread]: On master: COMMIT
[0m13:18:47.505934 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:18:47.507085 [debug] [MainThread]: On master: Close
[0m13:18:47.509378 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:18:47.511142 [info ] [MainThread]: 
[0m13:18:47.519927 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.brz_raw_orders
[0m13:18:47.522556 [info ] [Thread-1 (]: 1 of 14 START sql view model analytics_bronze.brz_raw_orders ................... [RUN]
[0m13:18:47.523852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now model.ecommerce_dbt.brz_raw_orders)
[0m13:18:47.524835 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.brz_raw_orders
[0m13:18:47.538579 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.564466 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.brz_raw_orders
[0m13:18:47.668866 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.699827 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.704231 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: BEGIN
[0m13:18:47.708572 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:47.721712 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:18:47.722756 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.724201 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */

  create view "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp"
    
    
  as (
    

select
    -- All columns from source as-is
    *,
    
    -- Bronze layer metadata
    'shopee_seller_center' as _source_system,
    current_timestamp as _bronze_loaded_at

from "ecommerce_db"."raw"."raw_orders"
  );
[0m13:18:47.729204 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m13:18:47.735303 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.736221 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders" rename to "brz_raw_orders__dbt_backup"
[0m13:18:47.737888 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:47.741134 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.742531 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
alter table "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_tmp" rename to "brz_raw_orders"
[0m13:18:47.744582 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:47.768002 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m13:18:47.769593 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.770771 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: COMMIT
[0m13:18:47.773253 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:47.789403 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup"
[0m13:18:47.798554 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.brz_raw_orders"
[0m13:18:47.799987 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.brz_raw_orders"} */
drop view if exists "ecommerce_db"."analytics_bronze"."brz_raw_orders__dbt_backup" cascade
[0m13:18:47.805323 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.004 seconds
[0m13:18:47.810876 [debug] [Thread-1 (]: On model.ecommerce_dbt.brz_raw_orders: Close
[0m13:18:47.817065 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242aeae840>]}
[0m13:18:47.822691 [info ] [Thread-1 (]: 1 of 14 OK created sql view model analytics_bronze.brz_raw_orders .............. [[32mCREATE VIEW[0m in 0.29s]
[0m13:18:47.828396 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.brz_raw_orders
[0m13:18:47.831329 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_customers
[0m13:18:47.832883 [info ] [Thread-1 (]: 2 of 14 START sql table model analytics_silver.slv_customers ................... [RUN]
[0m13:18:47.834376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.brz_raw_orders, now model.ecommerce_dbt.slv_customers)
[0m13:18:47.835366 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_customers
[0m13:18:47.841806 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_customers"
[0m13:18:47.872776 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_customers
[0m13:18:47.897587 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_customers"
[0m13:18:47.948372 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:18:47.951082 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: BEGIN
[0m13:18:47.952246 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:47.960842 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:18:47.961827 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:18:47.962929 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Customers
-- Extracted from raw_orders, cleaned and enriched with region classification



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique customers from orders
unique_customers as (
    select distinct on (buyer_username)
        buyer_username,
        recipient_name,
        phone_number,
        province,
        district,
        ward,
        shipping_address,
        country,
        _source_system
    from source
    where buyer_username is not null and trim(buyer_username) != ''
    order by buyer_username, recipient_name
),

cleaned as (
    select
        -- Generate customer_id
        row_number() over (order by buyer_username) as customer_id,
        
        COALESCE(NULLIF(trim(buyer_username), ''), 'guest_' || row_number() over (order by recipient_name)) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        
        -- Geography - cleaned
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Region classification (Vietnamese geography)
        case
            when province in ('H·ªì Ch√≠ Minh', 'TP. H·ªì Ch√≠ Minh', 'Ho Chi Minh', 'HCM', 'TP.HCM', 'Tp. H·ªì Ch√≠ Minh') then 'South'
            when province in ('H√† N·ªôi', 'Ha Noi', 'Hanoi', 'TP. H√† N·ªôi') then 'North'
            when province in ('ƒê√† N·∫µng', 'Da Nang', 'TP. ƒê√† N·∫µng') then 'Central'
            when province in ('C·∫ßn Th∆°', 'Can Tho', 'An Giang', 'ƒê·ªìng Th√°p', 'B·∫øn Tre', 'Vƒ©nh Long', 'Ti·ªÅn Giang', 'Long An', 'Ki√™n Giang', 'H·∫≠u Giang', 'S√≥c TrƒÉng', 'B·∫°c Li√™u', 'C√† Mau', 'Tr√† Vinh') then 'Mekong Delta'
            when province in ('B√¨nh D∆∞∆°ng', 'ƒê·ªìng Nai', 'B√† R·ªãa - V≈©ng T√†u', 'T√¢y Ninh', 'B√¨nh Ph∆∞·ªõc') then 'Southeast'
            when province in ('L√¢m ƒê·ªìng', 'ƒê·∫Øk L·∫Øk', 'ƒê·∫Øk N√¥ng', 'Gia Lai', 'Kon Tum') then 'Central Highlands'
            when province in ('Th·ª´a Thi√™n Hu·∫ø', 'Qu·∫£ng Nam', 'Qu·∫£ng Ng√£i', 'B√¨nh ƒê·ªãnh', 'Ph√∫ Y√™n', 'Kh√°nh H√≤a', 'Ninh Thu·∫≠n', 'B√¨nh Thu·∫≠n') then 'South Central Coast'
            when province in ('H·∫£i Ph√≤ng', 'Qu·∫£ng Ninh', 'Th√°i B√¨nh', 'Nam ƒê·ªãnh', 'Ninh B√¨nh', 'H√† Nam', 'H∆∞ng Y√™n', 'H·∫£i D∆∞∆°ng', 'B·∫Øc Ninh', 'Vƒ©nh Ph√∫c') then 'Red River Delta'
            else 'Other'
        end as region,
        
        -- Customer key for joining (deterministic hash)
        md5(coalesce(buyer_username, '') || '|' || coalesce(phone_number, '')) as customer_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_customers
)

select * from cleaned
  );
  
[0m13:18:47.980155 [debug] [Thread-1 (]: SQL status: SELECT 265 in 0.011 seconds
[0m13:18:47.985629 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:18:47.987704 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers" rename to "slv_customers__dbt_backup"
[0m13:18:47.989321 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:18:47.997425 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:18:48.002629 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
alter table "ecommerce_db"."analytics_silver"."slv_customers__dbt_tmp" rename to "slv_customers"
[0m13:18:48.007997 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.019512 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m13:18:48.021322 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:18:48.022986 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: COMMIT
[0m13:18:48.030160 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:48.035914 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup"
[0m13:18:48.042034 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_customers"
[0m13:18:48.044811 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_customers"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_customers__dbt_backup" cascade
[0m13:18:48.052054 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m13:18:48.056575 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_customers: Close
[0m13:18:48.059878 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782428bdbf20>]}
[0m13:18:48.062552 [info ] [Thread-1 (]: 2 of 14 OK created sql table model analytics_silver.slv_customers .............. [[32mSELECT 265[0m in 0.23s]
[0m13:18:48.063565 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_customers
[0m13:18:48.064717 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_dates
[0m13:18:48.066682 [info ] [Thread-1 (]: 3 of 14 START sql table model analytics_silver.slv_dates ....................... [RUN]
[0m13:18:48.067881 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_customers, now model.ecommerce_dbt.slv_dates)
[0m13:18:48.069515 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_dates
[0m13:18:48.075333 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_dates"
[0m13:18:48.102016 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_dates
[0m13:18:48.108242 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_dates"
[0m13:18:48.155270 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:18:48.156092 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: BEGIN
[0m13:18:48.157041 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:48.168899 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:18:48.170088 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:18:48.171446 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Dates
-- Generated from raw_orders date range, enriched with Shopee sale events



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique dates from orders
unique_dates as (
    select distinct
        cast(order_date as date) as date_value
    from source
    where order_date is not null
),

enriched as (
    select
        -- Date key
        cast(to_char(date_value, 'YYYYMMDD') as integer) as date_key,
        date_value as full_date,
        
        -- Date parts
        extract(year from date_value) as year,
        extract(quarter from date_value) as quarter,
        extract(month from date_value) as month,
        extract(week from date_value) as week_of_year,
        extract(day from date_value) as day_of_month,
        extract(dow from date_value) as day_of_week,
        
        -- Date names
        to_char(date_value, 'Month') as month_name,
        to_char(date_value, 'Day') as day_name,
        to_char(date_value, 'Mon') as month_abbr,
        to_char(date_value, 'Dy') as day_abbr,
        
        -- Flags
        case when extract(dow from date_value) in (0, 6) then true else false end as is_weekend,
        case when extract(dow from date_value) between 1 and 5 then true else false end as is_weekday,
        
        -- Shopee Double-Day Sale Events (major e-commerce events in SEA)
        case 
            when extract(month from date_value) = extract(day from date_value) 
                 and extract(day from date_value) <= 12 then true
            else false
        end as is_double_day_sale,
        
        -- Sale event names
        case 
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then '1.1 New Year Sale'
            when extract(month from date_value) = 2 and extract(day from date_value) = 2 then '2.2 Sale'
            when extract(month from date_value) = 3 and extract(day from date_value) = 3 then '3.3 Sale'
            when extract(month from date_value) = 4 and extract(day from date_value) = 4 then '4.4 Sale'
            when extract(month from date_value) = 5 and extract(day from date_value) = 5 then '5.5 Sale'
            when extract(month from date_value) = 6 and extract(day from date_value) = 6 then '6.6 Mid-Year Sale'
            when extract(month from date_value) = 7 and extract(day from date_value) = 7 then '7.7 Sale'
            when extract(month from date_value) = 8 and extract(day from date_value) = 8 then '8.8 Sale'
            when extract(month from date_value) = 9 and extract(day from date_value) = 9 then '9.9 Super Shopping Day'
            when extract(month from date_value) = 10 and extract(day from date_value) = 10 then '10.10 Sale'
            when extract(month from date_value) = 11 and extract(day from date_value) = 11 then '11.11 Singles Day'
            when extract(month from date_value) = 12 and extract(day from date_value) = 12 then '12.12 Birthday Sale'
            else null
        end as sale_event_name,
        
        -- Vietnamese holidays
        case
            when extract(month from date_value) = 1 and extract(day from date_value) = 1 then true  -- New Year
            when extract(month from date_value) = 4 and extract(day from date_value) = 30 then true  -- Liberation Day
            when extract(month from date_value) = 5 and extract(day from date_value) = 1 then true  -- Labour Day
            when extract(month from date_value) = 9 and extract(day from date_value) = 2 then true  -- Independence Day
            else false
        end as is_vn_holiday,
        
        -- Period helpers
        date_trunc('month', date_value)::date as first_day_of_month,
        (date_trunc('month', date_value) + interval '1 month' - interval '1 day')::date as last_day_of_month,
        date_trunc('week', date_value)::date as first_day_of_week,
        
        -- Source metadata
        'shopee_seller_center' as _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_dates
)

select * from enriched
  );
  
[0m13:18:48.184525 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.011 seconds
[0m13:18:48.189225 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:18:48.190142 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates" rename to "slv_dates__dbt_backup"
[0m13:18:48.191437 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.197617 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:18:48.198408 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
alter table "ecommerce_db"."analytics_silver"."slv_dates__dbt_tmp" rename to "slv_dates"
[0m13:18:48.201432 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.204126 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m13:18:48.210333 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:18:48.212397 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: COMMIT
[0m13:18:48.216243 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m13:18:48.219730 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup"
[0m13:18:48.222524 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_dates"
[0m13:18:48.225114 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_dates"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_dates__dbt_backup" cascade
[0m13:18:48.230342 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:18:48.232274 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_dates: Close
[0m13:18:48.233089 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782428b1bef0>]}
[0m13:18:48.234904 [info ] [Thread-1 (]: 3 of 14 OK created sql table model analytics_silver.slv_dates .................. [[32mSELECT 111[0m in 0.17s]
[0m13:18:48.236442 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_dates
[0m13:18:48.238215 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_orders
[0m13:18:48.239088 [info ] [Thread-1 (]: 4 of 14 START sql table model analytics_silver.slv_orders ...................... [RUN]
[0m13:18:48.240491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_dates, now model.ecommerce_dbt.slv_orders)
[0m13:18:48.241345 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_orders
[0m13:18:48.244387 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_orders"
[0m13:18:48.391663 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_orders
[0m13:18:48.401635 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_orders"
[0m13:18:48.462439 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:18:48.465697 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: BEGIN
[0m13:18:48.467539 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:48.477122 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:18:48.480177 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:18:48.481428 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Orders
-- Cleaned, validated, standardized order data
-- Type casting, null handling, deduplication



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

cleaned as (
    select
        -- Order identifiers
        order_id,
        package_id,
        tracking_number,
        
        -- Dates - standardized casting
        cast(order_date as timestamp) as order_date,
        cast(expected_delivery_date as timestamp) as expected_delivery_date,
        cast(actual_delivery_date as timestamp) as actual_delivery_date,
        cast(order_completed_date as timestamp) as order_completed_date,
        cast(payment_date as timestamp) as payment_date,
        
        -- Order status - cleaned
        trim(order_status) as order_status,
        trim(order_type) as order_type,
        trim(return_status) as return_status,
        
        -- Product info - cleaned
        trim(product_sku) as product_sku,
        trim(product_name) as product_name,
        trim(variant_sku) as variant_sku,
        trim(variant_name) as variant_name,
        coalesce(cast("c√¢n_nƒÉng_san_ph√¢m" as numeric), 0) as product_weight,
        
        -- Pricing - validated numerics
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast("gia_∆∞u_ƒëai" as numeric), 0) as discount_price,
        coalesce(cast(quantity as integer), 1) as quantity,
        coalesce(cast(total_product_price as numeric), 0) as total_product_price,
        coalesce(cast(order_total_vnd as numeric), 0) as order_total_vnd,
        
        -- Discounts - validated
        coalesce(cast(seller_discount as numeric), 0) as seller_discount,
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) as shopee_discount,
        coalesce(cast(shop_voucher as numeric), 0) as shop_voucher,
        coalesce(cast(shopee_voucher as numeric), 0) as shopee_voucher,
        coalesce(cast(coins_cashback as numeric), 0) as coins_cashback,
        
        -- Shipping - cleaned
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        coalesce(cast("phi_v√¢n_chuy√™n_d∆∞_ki√™n" as numeric), 0) as shipping_fee_estimated,
        coalesce(cast("phi_v√¢n_chuy√™n_ma_ng∆∞∆°i_mua_tra" as numeric), 0) as shipping_fee_paid,
        coalesce(cast(shipping_subsidy as numeric), 0) as shipping_subsidy,
        
        -- Customer info - cleaned
        COALESCE(NULLIF(trim(buyer_username), ''), 'guest_' || order_id) as buyer_username,
        trim(recipient_name) as recipient_name,
        trim(phone_number) as phone_number,
        trim(province) as province,
        trim(district) as district,
        trim(ward) as ward,
        trim(shipping_address) as shipping_address,
        coalesce(trim(country), 'VN') as country,
        
        -- Payment - cleaned
        trim(payment_method) as payment_method,
        coalesce(cast(total_paid as numeric), 0) as total_paid,
        
        -- Fees - validated
        coalesce(cast(fixed_fee as numeric), 0) as fixed_fee,
        coalesce(cast(service_fee as numeric), 0) as service_fee,
        coalesce(cast(payment_fee as numeric), 0) as payment_fee,
        coalesce(cast(deposit as numeric), 0) as deposit,
        
        -- Flags
        case when is_bestseller in ('Y', 'Yes', '1', 'true') then true else false end as is_bestseller,
        buyer_review,
        note,
        
        -- Source metadata
        source_file,
        loaded_at as source_loaded_at,
        data_source,
        _source_system,
        
        -- Calculated fields
        coalesce(cast(seller_discount as numeric), 0) + 
        coalesce(cast("ƒë∆∞∆°c_shopee_tr∆°_gia" as numeric), 0) + 
        coalesce(cast(shop_voucher as numeric), 0) + 
        coalesce(cast(shopee_voucher as numeric), 0) as total_discount,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at,
        
        -- Row number for deduplication
        row_number() over (
            partition by order_id, product_name 
            order by loaded_at desc
        ) as _row_num
        
    from source
    where order_id is not null
)

-- Keep only the latest record for each order+product
select * from cleaned
where _row_num = 1
  );
  
[0m13:18:48.501079 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.018 seconds
[0m13:18:48.505744 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:18:48.507873 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders" rename to "slv_orders__dbt_backup"
[0m13:18:48.510802 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.515549 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:18:48.517118 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
alter table "ecommerce_db"."analytics_silver"."slv_orders__dbt_tmp" rename to "slv_orders"
[0m13:18:48.518942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.522126 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m13:18:48.523222 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:18:48.523873 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: COMMIT
[0m13:18:48.526918 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:48.530054 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup"
[0m13:18:48.531246 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_orders"
[0m13:18:48.531994 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_orders"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_orders__dbt_backup" cascade
[0m13:18:48.535732 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:18:48.537826 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_orders: Close
[0m13:18:48.538999 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782425ace3c0>]}
[0m13:18:48.540693 [info ] [Thread-1 (]: 4 of 14 OK created sql table model analytics_silver.slv_orders ................. [[32mSELECT 516[0m in 0.30s]
[0m13:18:48.543318 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_orders
[0m13:18:48.545083 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.slv_products
[0m13:18:48.548656 [info ] [Thread-1 (]: 5 of 14 START sql table model analytics_silver.slv_products .................... [RUN]
[0m13:18:48.550646 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_orders, now model.ecommerce_dbt.slv_products)
[0m13:18:48.551694 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.slv_products
[0m13:18:48.555509 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.slv_products"
[0m13:18:48.594045 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.slv_products
[0m13:18:48.599264 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.slv_products"
[0m13:18:48.622394 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:18:48.624285 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: BEGIN
[0m13:18:48.625678 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:48.633557 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m13:18:48.634405 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:18:48.635461 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */

  
    

  create  table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp"
  
  
    as
  
  (
    -- SILVER LAYER: Products
-- Extracted from raw_orders, cleaned and standardized



with source as (
    select * from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
),

-- Extract unique products from orders (one row per product_name, keeping highest price variant)
unique_products as (
    select distinct on (product_name)
        product_name,
        product_sku,
        variant_name,
        variant_sku,
        "c√¢n_nƒÉng_san_ph√¢m" as product_weight,
        original_price,
        "gia_∆∞u_ƒëai" as discount_price,
        _source_system
    from source
    where product_name is not null
    order by product_name, original_price desc
),

cleaned as (
    select
        -- Generate product_id
        row_number() over (order by product_name, coalesce(variant_name, '')) as product_id,
        
        trim(product_name) as product_name,
        trim(product_sku) as product_sku,
        trim(variant_name) as variant_name,
        trim(variant_sku) as variant_sku,
        
        -- Category extraction from product name (Vietnamese keywords)
        case
            when product_name ilike '%√°o%' then 'Clothing'
            when product_name ilike '%qu·∫ßn%' then 'Clothing'
            when product_name ilike '%v√°y%' then 'Clothing'
            when product_name ilike '%gi√†y%' then 'Footwear'
            when product_name ilike '%d√©p%' then 'Footwear'
            when product_name ilike '%t√∫i%' then 'Bags'
            when product_name ilike '%balo%' then 'Bags'
            when product_name ilike '%ƒë·ªìng h·ªì%' then 'Watches'
            when product_name ilike '%ph·ª• ki·ªán%' then 'Accessories'
            when product_name ilike '%m·ªπ ph·∫©m%' then 'Beauty'
            when product_name ilike '%son%' then 'Beauty'
            when product_name ilike '%kem%' then 'Beauty'
            else 'Other'
        end as main_category,
        
        -- Pricing from first occurrence
        coalesce(cast(original_price as numeric), 0) as original_price,
        coalesce(cast(discount_price as numeric), 0) as discounted_price,
        coalesce(cast(product_weight as numeric), 0) as product_weight,
        
        -- Product key for joining
        md5(coalesce(product_name, '') || '|' || coalesce(product_sku, '')) as product_key,
        
        -- Source metadata
        _source_system,
        
        -- Silver layer metadata
        current_timestamp as _silver_loaded_at
        
    from unique_products
)

select * from cleaned
  );
  
[0m13:18:48.646547 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.008 seconds
[0m13:18:48.649978 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:18:48.651772 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products" rename to "slv_products__dbt_backup"
[0m13:18:48.654129 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.657094 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:18:48.659176 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
alter table "ecommerce_db"."analytics_silver"."slv_products__dbt_tmp" rename to "slv_products"
[0m13:18:48.660700 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.662988 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m13:18:48.663906 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:18:48.666361 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: COMMIT
[0m13:18:48.669559 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:48.672850 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_silver"."slv_products__dbt_backup"
[0m13:18:48.674259 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.slv_products"
[0m13:18:48.675372 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.slv_products"} */
drop table if exists "ecommerce_db"."analytics_silver"."slv_products__dbt_backup" cascade
[0m13:18:48.679812 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:18:48.683155 [debug] [Thread-1 (]: On model.ecommerce_dbt.slv_products: Close
[0m13:18:48.684455 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782425a30e00>]}
[0m13:18:48.687513 [info ] [Thread-1 (]: 5 of 14 OK created sql table model analytics_silver.slv_products ............... [[32mSELECT 45[0m in 0.13s]
[0m13:18:48.689125 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.slv_products
[0m13:18:48.690369 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_date
[0m13:18:48.691383 [info ] [Thread-1 (]: 6 of 14 START sql table model analytics_gold.dim_date .......................... [RUN]
[0m13:18:48.692581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.slv_products, now model.ecommerce_dbt.dim_date)
[0m13:18:48.694067 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_date
[0m13:18:48.700267 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_date"
[0m13:18:48.730697 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_date
[0m13:18:48.735087 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_date"
[0m13:18:48.774932 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:18:48.776310 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: BEGIN
[0m13:18:48.777481 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:48.785039 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m13:18:48.786172 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:18:48.787232 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Date Dimension
-- Business-ready calendar with Shopee events



select
    date_key,
    full_date as date,
    
    -- Date parts
    year,
    quarter,
    month,
    week_of_year,
    day_of_month,
    day_of_week,
    
    -- Date names
    month_name,
    day_name,
    month_abbr,
    day_abbr,
    
    -- Year-Month key for reporting
    year * 100 + month as year_month_key,
    to_char(full_date, 'YYYY-MM') as year_month,
    
    -- Flags
    is_weekend,
    is_weekday,
    is_double_day_sale,
    is_vn_holiday,
    
    -- Sale events
    sale_event_name,
    
    -- Period helpers
    first_day_of_month,
    last_day_of_month,
    first_day_of_week,
    
    -- Relative date flags (useful for dashboards)
    case when full_date = current_date then true else false end as is_today,
    case when full_date = current_date - interval '1 day' then true else false end as is_yesterday,
    case when full_date >= date_trunc('month', current_date) then true else false end as is_current_month,
    case when full_date >= date_trunc('year', current_date) then true else false end as is_current_year,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from "ecommerce_db"."analytics_silver"."slv_dates"
  );
  
[0m13:18:48.794256 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.005 seconds
[0m13:18:48.798718 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:18:48.802170 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date" rename to "dim_date__dbt_backup"
[0m13:18:48.804182 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.809287 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:18:48.810974 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
alter table "ecommerce_db"."analytics_gold"."dim_date__dbt_tmp" rename to "dim_date"
[0m13:18:48.814126 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:18:48.816455 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m13:18:48.817809 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:18:48.820300 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: COMMIT
[0m13:18:48.823474 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:48.827527 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_date__dbt_backup"
[0m13:18:48.829000 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_date"
[0m13:18:48.829994 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_date"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_date__dbt_backup" cascade
[0m13:18:48.833788 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:18:48.835951 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_date: Close
[0m13:18:48.837977 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242a3a35c0>]}
[0m13:18:48.841127 [info ] [Thread-1 (]: 6 of 14 OK created sql table model analytics_gold.dim_date ..................... [[32mSELECT 111[0m in 0.15s]
[0m13:18:48.842504 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_date
[0m13:18:48.843459 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_customer
[0m13:18:48.844286 [info ] [Thread-1 (]: 7 of 14 START sql table model analytics_gold.dim_customer ...................... [RUN]
[0m13:18:48.845476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_date, now model.ecommerce_dbt.dim_customer)
[0m13:18:48.846979 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_customer
[0m13:18:48.851367 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_customer"
[0m13:18:48.886450 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_customer
[0m13:18:48.892979 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_customer"
[0m13:18:48.931095 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:18:48.932186 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: BEGIN
[0m13:18:48.933132 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:48.942365 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:18:48.946133 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:18:48.947325 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Dimension
-- Business-ready customer data with RFM segmentation



with customers as (
    select * from "ecommerce_db"."analytics_silver"."slv_customers"
),

-- Calculate order aggregates per customer
order_stats as (
    select
        buyer_username,
        count(distinct order_id) as total_orders,
        sum(order_total_vnd) as total_spent,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by buyer_username
),

-- RFM calculation
rfm_calc as (
    select
        c.*,
        coalesce(o.total_orders, 0) as total_orders,
        coalesce(o.total_spent, 0) as total_spent,
        coalesce(o.avg_order_value, 0) as avg_order_value,
        o.first_order_date,
        o.last_order_date,
        coalesce(o.days_since_last_order, 999) as days_since_last_order,
        
        -- RFM Scores (1-5 scale)
        ntile(5) over (order by coalesce(o.days_since_last_order, 999) desc) as r_score,
        ntile(5) over (order by coalesce(o.total_orders, 0)) as f_score,
        ntile(5) over (order by coalesce(o.total_spent, 0)) as m_score
        
    from customers c
    left join order_stats o on c.buyer_username = o.buyer_username
),

final as (
    select
        customer_id,
        buyer_username,
        recipient_name,
        phone_number,
        
        -- Geography
        province,
        district,
        ward,
        shipping_address,
        country,
        region,
        
        -- Customer key
        customer_key,
        
        -- Order metrics
        total_orders,
        total_spent,
        avg_order_value,
        first_order_date,
        last_order_date,
        days_since_last_order,
        
        -- RFM Scores
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score as rfm_score,
        
        -- RFM Segment
        case
            when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
            when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
            when r_score >= 4 and f_score <= 2 then 'Recent Customers'
            when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
            when r_score <= 2 and f_score >= 4 then 'At Risk'
            when r_score <= 2 and f_score >= 2 then 'Hibernating'
            when r_score <= 2 and f_score <= 2 then 'Lost'
            else 'Other'
        end as customer_segment,
        
        -- Customer lifecycle
        case 
            when total_orders = 1 then 'New'
            when total_orders between 2 and 3 then 'Returning'
            when total_orders between 4 and 10 then 'Regular'
            when total_orders > 10 then 'VIP'
            else 'Prospect'
        end as customer_lifecycle,
        
        -- Customer value tier
        case
            when total_spent >= 5000000 then 'Platinum'
            when total_spent >= 2000000 then 'Gold'
            when total_spent >= 500000 then 'Silver'
            else 'Bronze'
        end as customer_value_tier,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from rfm_calc
)

select * from final
  );
  
[0m13:18:48.960303 [debug] [Thread-1 (]: SQL status: SELECT 265 in 0.012 seconds
[0m13:18:48.966463 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:18:48.967528 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer" rename to "dim_customer__dbt_backup"
[0m13:18:48.969486 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.975118 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:18:48.976427 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
alter table "ecommerce_db"."analytics_gold"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m13:18:48.980507 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:48.983592 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m13:18:48.988220 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:18:48.991575 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: COMMIT
[0m13:18:48.996677 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:49.000419 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup"
[0m13:18:49.002219 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_customer"
[0m13:18:49.003077 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_customer"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_customer__dbt_backup" cascade
[0m13:18:49.006827 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:18:49.008609 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_customer: Close
[0m13:18:49.009629 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7824287ad070>]}
[0m13:18:49.010733 [info ] [Thread-1 (]: 7 of 14 OK created sql table model analytics_gold.dim_customer ................. [[32mSELECT 265[0m in 0.16s]
[0m13:18:49.012873 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_customer
[0m13:18:49.013722 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_payment
[0m13:18:49.015161 [info ] [Thread-1 (]: 8 of 14 START sql table model analytics_gold.dim_payment ....................... [RUN]
[0m13:18:49.016300 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_customer, now model.ecommerce_dbt.dim_payment)
[0m13:18:49.019712 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_payment
[0m13:18:49.028757 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_payment"
[0m13:18:49.106091 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_payment
[0m13:18:49.109965 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_payment"
[0m13:18:49.178608 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:18:49.184718 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: BEGIN
[0m13:18:49.190050 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:49.205178 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m13:18:49.209761 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:18:49.211336 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Payment Dimension
-- Extracted from orders, enriched with payment grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique payment methods
unique_payments as (
    select distinct
        payment_method
    from source
    where payment_method is not null
),

enriched as (
    select
        row_number() over (order by payment_method) as payment_method_id,
        trim(payment_method) as payment_method,
        
        -- Payment method grouping
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'COD'
            when payment_method ilike '%shopee%' or payment_method ilike '%spay%' or payment_method ilike '%shopeepay%' then 'ShopeePay'
            when payment_method ilike '%momo%' then 'MoMo'
            when payment_method ilike '%zalo%' then 'ZaloPay'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Credit/Debit Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank Transfer'
            when payment_method ilike '%vnpay%' then 'VNPay'
            else 'Other'
        end as payment_group,
        
        -- Payment type
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then 'Cash'
            when payment_method ilike '%shopee%' or payment_method ilike '%momo%' or payment_method ilike '%zalo%' or payment_method ilike '%vnpay%' then 'E-Wallet'
            when payment_method ilike '%visa%' or payment_method ilike '%mastercard%' or payment_method ilike '%credit%' or payment_method ilike '%th·∫ª%' then 'Card'
            when payment_method ilike '%bank%' or payment_method ilike '%ng√¢n h√†ng%' then 'Bank'
            else 'Other'
        end as payment_type,
        
        -- Is digital payment
        case
            when payment_method ilike '%cod%' or payment_method ilike '%thanh to√°n khi nh·∫≠n%' then false
            else true
        end as is_digital_payment,
        
        -- Payment key
        md5(coalesce(payment_method, 'unknown')) as payment_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_payments
)

select * from enriched
  );
  
[0m13:18:49.222433 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.009 seconds
[0m13:18:49.227169 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:18:49.228220 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment" rename to "dim_payment__dbt_backup"
[0m13:18:49.229749 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:49.234164 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:18:49.235343 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
alter table "ecommerce_db"."analytics_gold"."dim_payment__dbt_tmp" rename to "dim_payment"
[0m13:18:49.237207 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:49.239341 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m13:18:49.240199 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:18:49.241497 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: COMMIT
[0m13:18:49.244322 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m13:18:49.247902 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup"
[0m13:18:49.251828 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_payment"
[0m13:18:49.270142 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_payment"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_payment__dbt_backup" cascade
[0m13:18:49.296609 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m13:18:49.321275 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_payment: Close
[0m13:18:49.328608 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782425a2c140>]}
[0m13:18:49.330477 [info ] [Thread-1 (]: 8 of 14 OK created sql table model analytics_gold.dim_payment .................. [[32mSELECT 6[0m in 0.31s]
[0m13:18:49.337277 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_payment
[0m13:18:49.345169 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_shipping
[0m13:18:49.352370 [info ] [Thread-1 (]: 9 of 14 START sql table model analytics_gold.dim_shipping ...................... [RUN]
[0m13:18:49.357624 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_payment, now model.ecommerce_dbt.dim_shipping)
[0m13:18:49.363867 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_shipping
[0m13:18:49.374425 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.411121 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_shipping
[0m13:18:49.416758 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.444969 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.446375 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: BEGIN
[0m13:18:49.452448 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:49.463849 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:18:49.466077 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.467543 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Shipping Dimension
-- Extracted from orders, enriched with carrier grouping



with source as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

-- Extract unique shipping carriers
unique_carriers as (
    select distinct on (shipping_carrier)
        shipping_carrier,
        shipping_method
    from source
    where shipping_carrier is not null
    order by shipping_carrier, shipping_method
),

enriched as (
    select
        row_number() over (order by shipping_carrier) as shipping_id,
        trim(shipping_carrier) as shipping_carrier,
        trim(shipping_method) as shipping_method,
        
        -- Carrier grouping/normalization
        case
            when shipping_carrier ilike '%giao hang nhanh%' or shipping_carrier ilike '%ghn%' then 'GHN'
            when shipping_carrier ilike '%giao hang tiet kiem%' or shipping_carrier ilike '%ghtk%' then 'GHTK'
            when shipping_carrier ilike '%j&t%' or shipping_carrier ilike '%jt%' then 'J&T Express'
            when shipping_carrier ilike '%shopee express%' or shipping_carrier ilike '%spx%' then 'Shopee Express'
            when shipping_carrier ilike '%viettel%' then 'Viettel Post'
            when shipping_carrier ilike '%grab%' then 'GrabExpress'
            when shipping_carrier ilike '%ninja van%' then 'Ninja Van'
            when shipping_carrier ilike '%best%' then 'BEST Express'
            else 'Other'
        end as carrier_group,
        
        -- Carrier type
        case
            when shipping_carrier ilike '%shopee%' or shipping_carrier ilike '%spx%' then 'Platform Logistics'
            when shipping_carrier ilike '%grab%' then 'On-Demand'
            else 'Third Party Logistics'
        end as carrier_type,
        
        -- Shipping key
        md5(coalesce(shipping_carrier, 'unknown')) as shipping_key,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from unique_carriers
)

select * from enriched
  );
  
[0m13:18:49.475426 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.007 seconds
[0m13:18:49.480954 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.482719 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping" rename to "dim_shipping__dbt_backup"
[0m13:18:49.486725 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:49.493071 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.496198 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
alter table "ecommerce_db"."analytics_gold"."dim_shipping__dbt_tmp" rename to "dim_shipping"
[0m13:18:49.503274 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:49.513525 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m13:18:49.517900 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.521783 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: COMMIT
[0m13:18:49.526343 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:49.529119 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup"
[0m13:18:49.532393 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_shipping"
[0m13:18:49.534069 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_shipping"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_shipping__dbt_backup" cascade
[0m13:18:49.537737 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m13:18:49.539990 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_shipping: Close
[0m13:18:49.542496 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7824287d1ee0>]}
[0m13:18:49.546239 [info ] [Thread-1 (]: 9 of 14 OK created sql table model analytics_gold.dim_shipping ................. [[32mSELECT 6[0m in 0.19s]
[0m13:18:49.547658 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_shipping
[0m13:18:49.549603 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.dim_product
[0m13:18:49.551003 [info ] [Thread-1 (]: 10 of 14 START sql table model analytics_gold.dim_product ...................... [RUN]
[0m13:18:49.552841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_shipping, now model.ecommerce_dbt.dim_product)
[0m13:18:49.556754 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.dim_product
[0m13:18:49.561331 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.dim_product"
[0m13:18:49.634464 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.dim_product
[0m13:18:49.639037 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.dim_product"
[0m13:18:49.666422 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:18:49.668222 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: BEGIN
[0m13:18:49.669399 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:49.680076 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:18:49.682148 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:18:49.683776 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Dimension
-- Business-ready product data with performance metrics



with products as (
    select * from "ecommerce_db"."analytics_silver"."slv_products"
),

-- Calculate product performance
product_stats as (
    select
        product_name,
        count(distinct order_id) as total_orders,
        sum(quantity) as total_quantity_sold,
        sum(order_total_vnd) as total_revenue,
        avg(order_total_vnd) as avg_order_value,
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date
    from "ecommerce_db"."analytics_silver"."slv_orders"
    group by product_name
),

final as (
    select
        p.product_id,
        p.product_name,
        p.product_sku,
        p.variant_name,
        p.variant_sku,
        p.main_category,
        
        -- Pricing
        p.original_price,
        p.discounted_price,
        case 
            when p.original_price > 0 
            then round((1 - p.discounted_price / p.original_price) * 100, 2)
            else 0
        end as discount_percentage,
        
        -- Weight
        p.product_weight,
        
        -- Product key
        p.product_key,
        
        -- Performance metrics
        coalesce(s.total_orders, 0) as total_orders,
        coalesce(s.total_quantity_sold, 0) as total_quantity_sold,
        coalesce(s.total_revenue, 0) as total_revenue,
        coalesce(s.avg_order_value, 0) as avg_order_value,
        s.first_sold_date,
        s.last_sold_date,
        
        -- Product tier based on revenue
        case
            when s.total_revenue >= 10000000 then 'Star Product'
            when s.total_revenue >= 5000000 then 'High Performer'
            when s.total_revenue >= 1000000 then 'Moderate'
            when s.total_revenue > 0 then 'Low Performer'
            else 'No Sales'
        end as product_tier,
        
        -- Velocity
        case 
            when s.total_quantity_sold >= 50 then 'Fast Moving'
            when s.total_quantity_sold >= 20 then 'Medium Moving'
            when s.total_quantity_sold >= 5 then 'Slow Moving'
            else 'Very Slow'
        end as sales_velocity,
        
        -- Metadata
        current_timestamp as _gold_loaded_at
        
    from products p
    left join product_stats s on p.product_name = s.product_name
)

select * from final
  );
  
[0m13:18:49.695513 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.011 seconds
[0m13:18:49.700443 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:18:49.703063 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product" rename to "dim_product__dbt_backup"
[0m13:18:49.704976 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:49.711962 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:18:49.714267 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
alter table "ecommerce_db"."analytics_gold"."dim_product__dbt_tmp" rename to "dim_product"
[0m13:18:49.718552 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:49.722900 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m13:18:49.725045 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:18:49.726765 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: COMMIT
[0m13:18:49.730255 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:49.734078 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."dim_product__dbt_backup"
[0m13:18:49.735982 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.dim_product"
[0m13:18:49.737137 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.dim_product"} */
drop table if exists "ecommerce_db"."analytics_gold"."dim_product__dbt_backup" cascade
[0m13:18:49.820567 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.082 seconds
[0m13:18:49.843530 [debug] [Thread-1 (]: On model.ecommerce_dbt.dim_product: Close
[0m13:18:49.848058 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7824287c3d40>]}
[0m13:18:49.851294 [info ] [Thread-1 (]: 10 of 14 OK created sql table model analytics_gold.dim_product ................. [[32mSELECT 45[0m in 0.30s]
[0m13:18:49.853821 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.dim_product
[0m13:18:49.856285 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.fct_orders
[0m13:18:49.857951 [info ] [Thread-1 (]: 11 of 14 START sql table model analytics_gold.fct_orders ....................... [RUN]
[0m13:18:49.861499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.dim_product, now model.ecommerce_dbt.fct_orders)
[0m13:18:49.862794 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.fct_orders
[0m13:18:49.868744 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.fct_orders"
[0m13:18:49.920652 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.fct_orders
[0m13:18:49.927443 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.fct_orders"
[0m13:18:49.971940 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:18:49.974279 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: BEGIN
[0m13:18:49.976568 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:49.987840 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:18:49.989386 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:18:49.992121 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Fact Orders
-- Main fact table - Star Schema center
-- Joins all dimensions with measures



with orders as (
    select * from "ecommerce_db"."analytics_silver"."slv_orders"
),

customers as (
    select customer_id, buyer_username, customer_key, region, customer_segment
    from "ecommerce_db"."analytics_gold"."dim_customer"
),

products as (
    select distinct on (product_name)
        product_id, product_name, product_key, main_category, product_tier
    from "ecommerce_db"."analytics_gold"."dim_product"
    order by product_name, product_id
),

dates as (
    select date_key, date, is_double_day_sale, sale_event_name
    from "ecommerce_db"."analytics_gold"."dim_date"
),

shipping as (
    select shipping_id, shipping_carrier, shipping_key, carrier_group
    from "ecommerce_db"."analytics_gold"."dim_shipping"
),

payment as (
    select payment_method_id, payment_method, payment_key, payment_group
    from "ecommerce_db"."analytics_gold"."dim_payment"
),

-- Customer order sequence (distinct orders only)
order_sequence as (
    select distinct on (order_id)
        order_id,
        buyer_username,
        order_date
    from orders
    order by order_id, order_date
),

order_seq_numbered as (
    select
        order_id,
        buyer_username,
        row_number() over (
            partition by buyer_username 
            order by order_date
        ) as customer_order_seq
    from order_sequence
),

fact_orders as (
    select
        -- Primary key
        o.order_id,
        
        -- Dimension keys (foreign keys)
        c.customer_id,
        p.product_id,
        d.date_key as order_date_key,
        s.shipping_id,
        pm.payment_method_id,
        
        -- Surrogate keys (for BI tools)
        c.customer_key,
        p.product_key,
        s.shipping_key,
        pm.payment_key,
        
        -- Natural keys (for reference)
        o.package_id,
        o.tracking_number,
        o.buyer_username,
        
        -- Date dimensions
        o.order_date,
        o.expected_delivery_date,
        o.actual_delivery_date,
        o.order_completed_date,
        o.payment_date,
        
        -- Delivery metrics
        case
            when o.actual_delivery_date is not null and o.order_date is not null
            then extract(day from o.actual_delivery_date - o.order_date)
            else null
        end as delivery_days,
        
        case
            when o.actual_delivery_date is not null and o.expected_delivery_date is not null
            then case 
                when o.actual_delivery_date <= o.expected_delivery_date then 'On Time'
                else 'Late'
            end
            else 'Unknown'
        end as delivery_status,
        
        -- Order status
        o.order_status,
        o.order_type,
        o.return_status,
        
        -- Product details (denormalized for performance)
        o.product_name,
        o.variant_name,
        o.product_weight,
        p.main_category,
        
        -- Quantity and pricing (MEASURES)
        o.quantity,
        o.original_price,
        o.discount_price,
        o.total_product_price,
        o.order_total_vnd,
        
        -- Discount breakdown (MEASURES)
        o.seller_discount,
        o.shopee_discount,
        o.shop_voucher,
        o.shopee_voucher,
        o.coins_cashback,
        o.total_discount,
        
        -- Shipping costs (MEASURES)
        o.shipping_fee_estimated,
        o.shipping_fee_paid,
        o.shipping_subsidy,
        
        -- Payment (MEASURES)
        o.total_paid,
        o.payment_method,
        
        -- Fees (MEASURES)
        o.fixed_fee,
        o.service_fee,
        o.payment_fee,
        o.deposit,
        
        -- Calculated measures
        o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee as net_revenue,
        
        case
            when o.original_price > 0 
            then round(((o.total_paid - o.fixed_fee - o.service_fee - o.payment_fee) / (o.original_price * o.quantity)) * 100, 2)
            else 0
        end as profit_margin_pct,
        
        -- Order value tier
        case
            when o.order_total_vnd >= 1000000 then 'Premium (1M+)'
            when o.order_total_vnd >= 500000 then 'High (500K-1M)'
            when o.order_total_vnd >= 200000 then 'Medium (200K-500K)'
            when o.order_total_vnd >= 100000 then 'Low (100K-200K)'
            else 'Micro (<100K)'
        end as order_value_tier,
        
        -- Customer location (denormalized)
        o.province,
        o.district,
        c.region,
        
        -- Shipping info (denormalized)
        o.shipping_carrier,
        s.carrier_group,
        
        -- Payment info (denormalized)
        pm.payment_group,
        
        -- Customer order sequence
        seq.customer_order_seq,
        case when seq.customer_order_seq = 1 then 'New' else 'Repeat' end as new_vs_repeat,
        
        -- Sale event (denormalized from date)
        d.is_double_day_sale,
        d.sale_event_name,
        
        -- Flags
        o.is_bestseller,
        case when o.return_status is not null and o.return_status != '' then true else false end as is_returned,
        case when o.order_status in ('Ho√†n th√†nh', 'complete', 'completed', 'Completed') then true else false end as is_completed,
        case when o.order_status in ('ƒê√£ h·ªßy', 'cancelled', 'Cancelled', 'cancel') then true else false end as is_cancelled,
        
        -- Metadata
        o.source_file,
        o.source_loaded_at,
        current_timestamp as _gold_loaded_at
        
    from orders o
    left join customers c on o.buyer_username = c.buyer_username
    left join products p on o.product_name = p.product_name
    left join dates d on cast(o.order_date as date) = d.date
    left join shipping s on o.shipping_carrier = s.shipping_carrier
    left join payment pm on o.payment_method = pm.payment_method
    left join order_seq_numbered seq on o.order_id = seq.order_id
)

select * from fact_orders
  );
  
[0m13:18:50.015392 [debug] [Thread-1 (]: SQL status: SELECT 516 in 0.022 seconds
[0m13:18:50.021399 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:18:50.024265 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders" rename to "fct_orders__dbt_backup"
[0m13:18:50.026447 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:50.033448 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:18:50.035739 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
alter table "ecommerce_db"."analytics_gold"."fct_orders__dbt_tmp" rename to "fct_orders"
[0m13:18:50.039042 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:50.043445 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m13:18:50.044773 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:18:50.046046 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: COMMIT
[0m13:18:50.052006 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m13:18:50.056816 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup"
[0m13:18:50.061056 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.fct_orders"
[0m13:18:50.063756 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.fct_orders"} */
drop table if exists "ecommerce_db"."analytics_gold"."fct_orders__dbt_backup" cascade
[0m13:18:50.068675 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:18:50.071358 [debug] [Thread-1 (]: On model.ecommerce_dbt.fct_orders: Close
[0m13:18:50.073304 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7824287d2f90>]}
[0m13:18:50.075779 [info ] [Thread-1 (]: 11 of 14 OK created sql table model analytics_gold.fct_orders .................. [[32mSELECT 516[0m in 0.21s]
[0m13:18:50.077224 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.fct_orders
[0m13:18:50.081734 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_customer_summary
[0m13:18:50.084380 [info ] [Thread-1 (]: 12 of 14 START sql table model analytics_gold.agg_customer_summary ............. [RUN]
[0m13:18:50.089722 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.fct_orders, now model.ecommerce_dbt.agg_customer_summary)
[0m13:18:50.093918 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_customer_summary
[0m13:18:50.106051 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.175593 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_customer_summary
[0m13:18:50.181184 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.240093 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.248774 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: BEGIN
[0m13:18:50.252380 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:50.267856 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m13:18:50.269293 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.271128 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Customer Summary Aggregate
-- Customer-level aggregated metrics with RFM



with customer_orders as (
    select
        buyer_username,
        customer_id,
        region,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Quantity
        sum(quantity) as total_items_purchased,
        
        -- Revenue
        sum(order_total_vnd) as total_spent,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Time metrics
        min(order_date) as first_order_date,
        max(order_date) as last_order_date,
        current_date - max(order_date)::date as days_since_last_order,
        
        -- Product diversity
        count(distinct product_name) as unique_products_ordered,
        count(distinct main_category) as unique_categories,
        
        -- Shipping preferences
        mode() within group (order by carrier_group) as preferred_carrier,
        mode() within group (order by payment_group) as preferred_payment
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where buyer_username is not null
    group by 1, 2, 3
),

with_rfm as (
    select
        *,
        
        -- RFM Scores
        ntile(5) over (order by days_since_last_order desc nulls last) as r_score,
        ntile(5) over (order by total_orders asc nulls first) as f_score,
        ntile(5) over (order by total_spent asc nulls first) as m_score
        
    from customer_orders
    where total_orders > 0
)

select
    buyer_username,
    customer_id,
    region,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    total_items_purchased,
    
    -- Revenue metrics
    total_spent,
    total_net_revenue,
    avg_order_value,
    
    -- Time metrics
    first_order_date,
    last_order_date,
    days_since_last_order,
    
    -- Tenure (days as customer)
    current_date - first_order_date::date as customer_tenure_days,
    
    -- Frequency (orders per month)
    case 
        when current_date - first_order_date::date > 30 
        then round(total_orders * 30.0 / (current_date - first_order_date::date), 2)
        else total_orders
    end as orders_per_month,
    
    -- Product diversity
    unique_products_ordered,
    unique_categories,
    
    -- Preferences
    preferred_carrier,
    preferred_payment,
    
    -- RFM
    r_score,
    f_score,
    m_score,
    r_score * 100 + f_score * 10 + m_score as rfm_score,
    
    -- RFM Segment
    case
        when r_score >= 4 and f_score >= 4 and m_score >= 4 then 'Champions'
        when r_score >= 4 and f_score >= 3 then 'Loyal Customers'
        when r_score >= 4 and f_score <= 2 then 'Recent Customers'
        when r_score >= 3 and f_score >= 3 and m_score >= 3 then 'Potential Loyalists'
        when r_score <= 2 and f_score >= 4 then 'At Risk'
        when r_score <= 2 and f_score >= 2 then 'Hibernating'
        when r_score <= 2 and f_score <= 2 then 'Lost'
        else 'Other'
    end as customer_segment,
    
    -- Customer lifecycle
    case 
        when total_orders = 1 then 'New'
        when total_orders between 2 and 3 then 'Returning'
        when total_orders between 4 and 10 then 'Regular'
        when total_orders > 10 then 'VIP'
    end as customer_lifecycle,
    
    -- Value tier
    case
        when total_spent >= 5000000 then 'Platinum'
        when total_spent >= 2000000 then 'Gold'
        when total_spent >= 500000 then 'Silver'
        else 'Bronze'
    end as customer_value_tier,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from with_rfm
order by total_spent desc
  );
  
[0m13:18:50.285928 [debug] [Thread-1 (]: SQL status: SELECT 318 in 0.013 seconds
[0m13:18:50.290826 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.305004 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary" rename to "agg_customer_summary__dbt_backup"
[0m13:18:50.328088 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:50.351244 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.355022 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
alter table "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_tmp" rename to "agg_customer_summary"
[0m13:18:50.356469 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m13:18:50.360169 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m13:18:50.363491 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.371941 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: COMMIT
[0m13:18:50.375780 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:50.381180 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup"
[0m13:18:50.383113 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_customer_summary"
[0m13:18:50.383962 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_customer_summary"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_customer_summary__dbt_backup" cascade
[0m13:18:50.390106 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m13:18:50.392988 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_customer_summary: Close
[0m13:18:50.394553 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782428bbcb90>]}
[0m13:18:50.396166 [info ] [Thread-1 (]: 12 of 14 OK created sql table model analytics_gold.agg_customer_summary ........ [[32mSELECT 318[0m in 0.31s]
[0m13:18:50.397717 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_customer_summary
[0m13:18:50.399211 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_daily_sales
[0m13:18:50.401316 [info ] [Thread-1 (]: 13 of 14 START sql table model analytics_gold.agg_daily_sales .................. [RUN]
[0m13:18:50.402777 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_customer_summary, now model.ecommerce_dbt.agg_daily_sales)
[0m13:18:50.404920 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_daily_sales
[0m13:18:50.409546 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.456710 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_daily_sales
[0m13:18:50.461756 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.498626 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.499993 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: BEGIN
[0m13:18:50.501925 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:50.513005 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:18:50.517456 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.522604 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Daily Sales Aggregate
-- Daily sales metrics for dashboards



with daily_orders as (
    select
        cast(order_date as date) as order_date,
        order_date_key,
        is_double_day_sale,
        sale_event_name,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_cancelled then order_id end) as cancelled_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        count(distinct case when new_vs_repeat = 'Repeat' then buyer_username end) as repeat_customers,
        
        -- Product counts
        count(distinct product_name) as unique_products,
        sum(quantity) as total_quantity,
        
        -- Revenue metrics
        sum(order_total_vnd) as gross_revenue,
        sum(net_revenue) as net_revenue,
        sum(total_discount) as total_discount,
        sum(shipping_fee_paid) as total_shipping,
        
        -- Fee breakdown
        sum(fixed_fee) as total_fixed_fee,
        sum(service_fee) as total_service_fee,
        sum(payment_fee) as total_payment_fee,
        
        -- Averages
        avg(order_total_vnd) as avg_order_value,
        avg(quantity) as avg_items_per_order,
        avg(delivery_days) as avg_delivery_days,
        
        -- By order value tier
        count(distinct case when order_value_tier = 'Premium (1M+)' then order_id end) as premium_orders,
        count(distinct case when order_value_tier = 'Micro (<100K)' then order_id end) as micro_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    group by 1, 2, 3, 4
)

select
    d.*,
    
    -- Completion rate
    case 
        when total_orders > 0 
        then round(completed_orders * 100.0 / total_orders, 2)
        else 0 
    end as completion_rate_pct,
    
    -- Cancellation rate
    case 
        when total_orders > 0 
        then round(cancelled_orders * 100.0 / total_orders, 2)
        else 0 
    end as cancellation_rate_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- New customer rate
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_rate_pct,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from daily_orders d
order by order_date desc
  );
  
[0m13:18:50.536307 [debug] [Thread-1 (]: SQL status: SELECT 111 in 0.011 seconds
[0m13:18:50.541749 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.543067 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales" rename to "agg_daily_sales__dbt_backup"
[0m13:18:50.544968 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:50.550574 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.552176 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
alter table "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_tmp" rename to "agg_daily_sales"
[0m13:18:50.554539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:50.558694 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m13:18:50.560162 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.561345 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: COMMIT
[0m13:18:50.563804 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m13:18:50.568042 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup"
[0m13:18:50.571269 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_daily_sales"
[0m13:18:50.572449 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_daily_sales"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_daily_sales__dbt_backup" cascade
[0m13:18:50.577489 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m13:18:50.580008 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_daily_sales: Close
[0m13:18:50.582171 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782425a47ad0>]}
[0m13:18:50.584209 [info ] [Thread-1 (]: 13 of 14 OK created sql table model analytics_gold.agg_daily_sales ............. [[32mSELECT 111[0m in 0.18s]
[0m13:18:50.586101 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_daily_sales
[0m13:18:50.587154 [debug] [Thread-1 (]: Began running node model.ecommerce_dbt.agg_product_performance
[0m13:18:50.588422 [info ] [Thread-1 (]: 14 of 14 START sql table model analytics_gold.agg_product_performance .......... [RUN]
[0m13:18:50.589908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ecommerce_dbt.agg_daily_sales, now model.ecommerce_dbt.agg_product_performance)
[0m13:18:50.591910 [debug] [Thread-1 (]: Began compiling node model.ecommerce_dbt.agg_product_performance
[0m13:18:50.596956 [debug] [Thread-1 (]: Writing injected SQL for node "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.641245 [debug] [Thread-1 (]: Began executing node model.ecommerce_dbt.agg_product_performance
[0m13:18:50.651165 [debug] [Thread-1 (]: Writing runtime sql for node "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.733236 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.739542 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: BEGIN
[0m13:18:50.746249 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:50.764347 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m13:18:50.770155 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.776754 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */

  
    

  create  table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp"
  
  
    as
  
  (
    -- GOLD LAYER: Product Performance Aggregate
-- Product-level aggregated metrics



with product_orders as (
    select
        product_name,
        product_id,
        main_category,
        
        -- Order counts
        count(distinct order_id) as total_orders,
        count(distinct case when is_completed then order_id end) as completed_orders,
        count(distinct case when is_returned then order_id end) as returned_orders,
        
        -- Customer counts
        count(distinct buyer_username) as unique_customers,
        count(distinct case when new_vs_repeat = 'New' then buyer_username end) as new_customers,
        
        -- Quantity
        sum(quantity) as total_quantity_sold,
        avg(quantity) as avg_quantity_per_order,
        
        -- Revenue
        sum(order_total_vnd) as total_revenue,
        sum(net_revenue) as total_net_revenue,
        avg(order_total_vnd) as avg_order_value,
        
        -- Pricing
        avg(original_price) as avg_original_price,
        avg(discount_price) as avg_discount_price,
        sum(total_discount) as total_discount_given,
        
        -- Time metrics
        min(order_date) as first_sold_date,
        max(order_date) as last_sold_date,
        current_date - max(order_date)::date as days_since_last_sale,
        
        -- Geography
        mode() within group (order by region) as top_region,
        
        -- Sale events
        count(distinct case when is_double_day_sale then order_id end) as sale_event_orders
        
    from "ecommerce_db"."analytics_gold"."fct_orders"
    where product_name is not null
    group by 1, 2, 3
)

select
    product_name,
    product_id,
    main_category,
    
    -- Order metrics
    total_orders,
    completed_orders,
    returned_orders,
    
    -- Customer metrics
    unique_customers,
    new_customers,
    
    -- Quantity metrics
    total_quantity_sold,
    avg_quantity_per_order,
    
    -- Revenue metrics
    total_revenue,
    total_net_revenue,
    avg_order_value,
    
    -- Pricing metrics
    avg_original_price,
    avg_discount_price,
    total_discount_given,
    
    -- Discount percentage
    case 
        when avg_original_price > 0 
        then round((1 - avg_discount_price / avg_original_price) * 100, 2)
        else 0 
    end as avg_discount_pct,
    
    -- Time metrics
    first_sold_date,
    last_sold_date,
    days_since_last_sale,
    
    -- Selling period (days)
    last_sold_date::date - first_sold_date::date as selling_period_days,
    
    -- Sales velocity (units per day)
    case 
        when last_sold_date::date - first_sold_date::date > 0 
        then round(total_quantity_sold * 1.0 / (last_sold_date::date - first_sold_date::date + 1), 2)
        else total_quantity_sold
    end as daily_sales_velocity,
    
    -- Top region
    top_region,
    
    -- Sale event performance
    sale_event_orders,
    case 
        when total_orders > 0 
        then round(sale_event_orders * 100.0 / total_orders, 2)
        else 0 
    end as sale_event_order_pct,
    
    -- Return rate
    case 
        when total_orders > 0 
        then round(returned_orders * 100.0 / total_orders, 2)
        else 0 
    end as return_rate_pct,
    
    -- Customer acquisition
    case 
        when unique_customers > 0 
        then round(new_customers * 100.0 / unique_customers, 2)
        else 0 
    end as new_customer_pct,
    
    -- Product tier
    case
        when total_revenue >= 10000000 then 'Star Product'
        when total_revenue >= 5000000 then 'High Performer'
        when total_revenue >= 1000000 then 'Moderate'
        when total_revenue > 0 then 'Low Performer'
        else 'No Sales'
    end as product_tier,
    
    -- Sales velocity category
    case 
        when total_quantity_sold >= 50 then 'Fast Moving'
        when total_quantity_sold >= 20 then 'Medium Moving'
        when total_quantity_sold >= 5 then 'Slow Moving'
        else 'Very Slow'
    end as sales_velocity_category,
    
    -- Metadata
    current_timestamp as _gold_loaded_at
    
from product_orders
order by total_revenue desc
  );
  
[0m13:18:50.798451 [debug] [Thread-1 (]: SQL status: SELECT 45 in 0.017 seconds
[0m13:18:50.804746 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.806551 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance" rename to "agg_product_performance__dbt_backup"
[0m13:18:50.809494 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:50.818831 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.820495 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
alter table "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_tmp" rename to "agg_product_performance"
[0m13:18:50.823550 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m13:18:50.830467 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m13:18:50.834902 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.836830 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: COMMIT
[0m13:18:50.844357 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m13:18:50.853101 [debug] [Thread-1 (]: Applying DROP to: "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup"
[0m13:18:50.854784 [debug] [Thread-1 (]: Using postgres connection "model.ecommerce_dbt.agg_product_performance"
[0m13:18:50.856205 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "model.ecommerce_dbt.agg_product_performance"} */
drop table if exists "ecommerce_db"."analytics_gold"."agg_product_performance__dbt_backup" cascade
[0m13:18:50.860987 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m13:18:50.865788 [debug] [Thread-1 (]: On model.ecommerce_dbt.agg_product_performance: Close
[0m13:18:50.869312 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0fdfae2-0a34-4fdb-bc77-2c58a90a4f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x782425ade660>]}
[0m13:18:50.871296 [info ] [Thread-1 (]: 14 of 14 OK created sql table model analytics_gold.agg_product_performance ..... [[32mSELECT 45[0m in 0.28s]
[0m13:18:50.875928 [debug] [Thread-1 (]: Finished running node model.ecommerce_dbt.agg_product_performance
[0m13:18:50.880340 [debug] [MainThread]: Using postgres connection "master"
[0m13:18:50.882875 [debug] [MainThread]: On master: BEGIN
[0m13:18:50.883843 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:18:50.893324 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m13:18:50.897397 [debug] [MainThread]: On master: COMMIT
[0m13:18:50.898709 [debug] [MainThread]: Using postgres connection "master"
[0m13:18:50.900043 [debug] [MainThread]: On master: COMMIT
[0m13:18:50.904431 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:18:50.906039 [debug] [MainThread]: On master: Close
[0m13:18:50.907538 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:18:50.910166 [debug] [MainThread]: Connection 'model.ecommerce_dbt.agg_product_performance' was properly closed.
[0m13:18:50.911386 [info ] [MainThread]: 
[0m13:18:50.913025 [info ] [MainThread]: Finished running 1 view model, 13 table models in 0 hours 0 minutes and 3.72 seconds (3.72s).
[0m13:18:50.920831 [debug] [MainThread]: Command end result
[0m13:18:51.147996 [info ] [MainThread]: 
[0m13:18:51.149565 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:18:51.157981 [info ] [MainThread]: 
[0m13:18:51.162974 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
[0m13:18:51.170018 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.626045, "process_user_time": 3.706154, "process_kernel_time": 0.407224, "process_mem_max_rss": "125548", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m13:18:51.177691 [debug] [MainThread]: Command `dbt run` succeeded at 13:18:51.177483 after 6.63 seconds
[0m13:18:51.184462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242aadb0b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242c8cd640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78242e43ee70>]}
[0m13:18:51.191034 [debug] [MainThread]: Flushing usage events
[0m13:19:20.123225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231fe20d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231e436840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231e26d940>]}


============================== 13:19:20.128097 | d5301d32-614e-473a-ac1c-63516f6b587f ==============================
[0m13:19:20.128097 [info ] [MainThread]: Running with dbt=1.8.0
[0m13:19:20.129282 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:19:20.326132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd5301d32-614e-473a-ac1c-63516f6b587f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231d3a1190>]}
[0m13:19:20.411956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd5301d32-614e-473a-ac1c-63516f6b587f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231e0347a0>]}
[0m13:19:20.413234 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m13:19:20.440525 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m13:19:21.708242 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:19:21.709716 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:19:21.715096 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.marts
- models.ecommerce_dbt.staging
[0m13:19:21.753535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5301d32-614e-473a-ac1c-63516f6b587f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231cf79ac0>]}
[0m13:19:22.011150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5301d32-614e-473a-ac1c-63516f6b587f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231bf2ab40>]}
[0m13:19:22.012028 [info ] [MainThread]: Found 14 models, 1 seed, 31 data tests, 1 source, 417 macros
[0m13:19:22.018573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5301d32-614e-473a-ac1c-63516f6b587f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231e9b03e0>]}
[0m13:19:22.026745 [info ] [MainThread]: 
[0m13:19:22.031886 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:19:22.041814 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db_analytics'
[0m13:19:22.090560 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:19:22.092063 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m13:19:22.093163 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:19:22.103215 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m13:19:22.106654 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:19:22.107785 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:19:22.113388 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m13:19:22.115659 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m13:19:22.116614 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m13:19:22.117585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_bronze)
[0m13:19:22.120871 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:19:22.121676 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m13:19:22.122203 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:22.134411 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m13:19:22.135620 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:19:22.136610 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m13:19:22.141049 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m13:19:22.143956 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m13:19:22.145040 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m13:19:22.147820 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics_gold)
[0m13:19:22.151126 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:19:22.152103 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m13:19:22.156579 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:22.163718 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m13:19:22.164734 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:19:22.165512 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m13:19:22.168564 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.002 seconds
[0m13:19:22.172281 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m13:19:22.174694 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m13:19:22.178417 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now list_ecommerce_db_analytics_silver)
[0m13:19:22.182368 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:19:22.183383 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m13:19:22.184220 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:22.192170 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m13:19:22.193155 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:19:22.193902 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m13:19:22.197630 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.003 seconds
[0m13:19:22.201781 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m13:19:22.202990 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m13:19:22.209798 [debug] [MainThread]: Using postgres connection "master"
[0m13:19:22.210679 [debug] [MainThread]: On master: BEGIN
[0m13:19:22.211370 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:19:22.218616 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m13:19:22.219600 [debug] [MainThread]: Using postgres connection "master"
[0m13:19:22.220521 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:19:22.227513 [debug] [MainThread]: SQL status: SELECT 1 in 0.006 seconds
[0m13:19:22.229666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5301d32-614e-473a-ac1c-63516f6b587f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231d391880>]}
[0m13:19:22.239487 [debug] [MainThread]: On master: ROLLBACK
[0m13:19:22.240964 [debug] [MainThread]: Using postgres connection "master"
[0m13:19:22.244514 [debug] [MainThread]: On master: BEGIN
[0m13:19:22.247067 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m13:19:22.248263 [debug] [MainThread]: On master: COMMIT
[0m13:19:22.249216 [debug] [MainThread]: Using postgres connection "master"
[0m13:19:22.252928 [debug] [MainThread]: On master: COMMIT
[0m13:19:22.254459 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:19:22.255460 [debug] [MainThread]: On master: Close
[0m13:19:22.256940 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:19:22.259733 [info ] [MainThread]: 
[0m13:19:22.263612 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:19:22.267535 [info ] [Thread-1 (]: 1 of 31 START test not_null_agg_customer_summary_buyer_username ................ [RUN]
[0m13:19:22.270201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e)
[0m13:19:22.275181 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:19:22.295149 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:19:22.358645 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:19:22.388986 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:19:22.435995 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:19:22.439087 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: BEGIN
[0m13:19:22.441094 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:22.464660 [debug] [Thread-1 (]: SQL status: BEGIN in 0.023 seconds
[0m13:19:22.483043 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:19:22.499709 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_gold"."agg_customer_summary"
where buyer_username is null



      
    ) dbt_internal_test
[0m13:19:22.505913 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:22.511764 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: ROLLBACK
[0m13:19:22.513076 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: Close
[0m13:19:22.514589 [info ] [Thread-1 (]: 1 of 31 PASS not_null_agg_customer_summary_buyer_username ...................... [[32mPASS[0m in 0.24s]
[0m13:19:22.515760 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:19:22.516618 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:19:22.517442 [info ] [Thread-1 (]: 2 of 31 START test not_null_agg_daily_sales_order_date ......................... [RUN]
[0m13:19:22.526351 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e, now test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8)
[0m13:19:22.529538 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:19:22.535521 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:19:22.602824 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:19:22.609900 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:19:22.663219 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:19:22.665871 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: BEGIN
[0m13:19:22.670258 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:22.683918 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:19:22.686032 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:19:22.688022 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_date
from "ecommerce_db"."analytics_gold"."agg_daily_sales"
where order_date is null



      
    ) dbt_internal_test
[0m13:19:22.690425 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:22.692415 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: ROLLBACK
[0m13:19:22.693798 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: Close
[0m13:19:22.696192 [info ] [Thread-1 (]: 2 of 31 PASS not_null_agg_daily_sales_order_date ............................... [[32mPASS[0m in 0.17s]
[0m13:19:22.698043 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:19:22.698858 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:19:22.699511 [info ] [Thread-1 (]: 3 of 31 START test not_null_agg_product_performance_product_name ............... [RUN]
[0m13:19:22.700356 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8, now test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1)
[0m13:19:22.701428 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:19:22.711803 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:19:22.796423 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:19:22.800698 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:19:22.862443 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:19:22.863567 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: BEGIN
[0m13:19:22.865201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:22.874518 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:19:22.875983 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:19:22.877284 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_name
from "ecommerce_db"."analytics_gold"."agg_product_performance"
where product_name is null



      
    ) dbt_internal_test
[0m13:19:22.880008 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:22.882545 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: ROLLBACK
[0m13:19:22.883997 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: Close
[0m13:19:22.885801 [info ] [Thread-1 (]: 3 of 31 PASS not_null_agg_product_performance_product_name ..................... [[32mPASS[0m in 0.19s]
[0m13:19:22.887722 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:19:22.889785 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:19:22.894365 [info ] [Thread-1 (]: 4 of 31 START test not_null_brz_raw_orders_order_id ............................ [RUN]
[0m13:19:22.895664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1, now test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750)
[0m13:19:22.899523 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:19:22.905810 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:19:22.955646 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:19:22.960121 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:19:23.044999 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:19:23.049585 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: BEGIN
[0m13:19:23.056609 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:23.072879 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m13:19:23.075003 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:19:23.077392 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
where order_id is null



      
    ) dbt_internal_test
[0m13:19:23.080425 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:23.084948 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: ROLLBACK
[0m13:19:23.086314 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: Close
[0m13:19:23.087634 [info ] [Thread-1 (]: 4 of 31 PASS not_null_brz_raw_orders_order_id .................................. [[32mPASS[0m in 0.19s]
[0m13:19:23.089066 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:19:23.092349 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:19:23.096781 [info ] [Thread-1 (]: 5 of 31 START test not_null_dim_customer_buyer_username ........................ [RUN]
[0m13:19:23.103373 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750, now test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b)
[0m13:19:23.108347 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:19:23.113842 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:19:23.206623 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:19:23.215293 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:19:23.504037 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:19:23.518655 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: BEGIN
[0m13:19:23.526039 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:23.543003 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m13:19:23.546453 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:19:23.554275 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_gold"."dim_customer"
where buyer_username is null



      
    ) dbt_internal_test
[0m13:19:23.561148 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:23.569419 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: ROLLBACK
[0m13:19:23.575086 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: Close
[0m13:19:23.584195 [info ] [Thread-1 (]: 5 of 31 PASS not_null_dim_customer_buyer_username .............................. [[32mPASS[0m in 0.48s]
[0m13:19:23.589464 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:19:23.596603 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:19:23.601540 [info ] [Thread-1 (]: 6 of 31 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m13:19:23.606874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b, now test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc)
[0m13:19:23.609798 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:19:23.618263 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:19:23.678802 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:19:23.682368 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:19:23.857451 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:19:23.870062 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m13:19:23.877825 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:23.890481 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:19:23.893720 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:19:23.894869 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "ecommerce_db"."analytics_gold"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m13:19:23.899959 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:23.901718 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m13:19:23.905914 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: Close
[0m13:19:23.907236 [info ] [Thread-1 (]: 6 of 31 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.30s]
[0m13:19:23.908943 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:19:23.911428 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:19:23.912506 [info ] [Thread-1 (]: 7 of 31 START test not_null_dim_date_date_key .................................. [RUN]
[0m13:19:23.913612 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc, now test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6)
[0m13:19:23.914844 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:19:23.918965 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:19:23.978353 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:19:23.989473 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:19:24.207490 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:19:24.211808 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: BEGIN
[0m13:19:24.213346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:24.226546 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:19:24.228883 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:19:24.233427 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date_key
from "ecommerce_db"."analytics_gold"."dim_date"
where date_key is null



      
    ) dbt_internal_test
[0m13:19:24.236866 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:24.241401 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: ROLLBACK
[0m13:19:24.246813 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: Close
[0m13:19:24.250005 [info ] [Thread-1 (]: 7 of 31 PASS not_null_dim_date_date_key ........................................ [[32mPASS[0m in 0.34s]
[0m13:19:24.254109 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:19:24.259894 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:19:24.261990 [info ] [Thread-1 (]: 8 of 31 START test not_null_dim_payment_payment_method_id ...................... [RUN]
[0m13:19:24.268210 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6, now test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b)
[0m13:19:24.276207 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:19:24.288239 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:19:24.451474 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:19:24.460123 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:19:24.587384 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:19:24.603673 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: BEGIN
[0m13:19:24.616223 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:24.635604 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m13:19:24.638714 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:19:24.644464 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select payment_method_id
from "ecommerce_db"."analytics_gold"."dim_payment"
where payment_method_id is null



      
    ) dbt_internal_test
[0m13:19:24.656634 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:24.666555 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: ROLLBACK
[0m13:19:24.670966 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: Close
[0m13:19:24.679181 [info ] [Thread-1 (]: 8 of 31 PASS not_null_dim_payment_payment_method_id ............................ [[32mPASS[0m in 0.41s]
[0m13:19:24.684477 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:19:24.691801 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:19:24.697915 [info ] [Thread-1 (]: 9 of 31 START test not_null_dim_product_product_id ............................. [RUN]
[0m13:19:24.703913 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b, now test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816)
[0m13:19:24.707748 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:19:24.718463 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:19:24.852303 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:19:24.859777 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:19:25.038786 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:19:25.046806 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: BEGIN
[0m13:19:25.054892 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:25.072296 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m13:19:25.079766 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:19:25.087513 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_id
from "ecommerce_db"."analytics_gold"."dim_product"
where product_id is null



      
    ) dbt_internal_test
[0m13:19:25.094513 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:25.097073 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: ROLLBACK
[0m13:19:25.099244 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: Close
[0m13:19:25.100631 [info ] [Thread-1 (]: 9 of 31 PASS not_null_dim_product_product_id ................................... [[32mPASS[0m in 0.40s]
[0m13:19:25.101808 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:19:25.102995 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:19:25.106767 [info ] [Thread-1 (]: 10 of 31 START test not_null_dim_shipping_shipping_id .......................... [RUN]
[0m13:19:25.107904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816, now test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc)
[0m13:19:25.108675 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:19:25.113507 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:19:25.176947 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:19:25.181159 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:19:25.256890 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:19:25.265149 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: BEGIN
[0m13:19:25.273487 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:25.295208 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m13:19:25.303238 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:19:25.311718 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select shipping_id
from "ecommerce_db"."analytics_gold"."dim_shipping"
where shipping_id is null



      
    ) dbt_internal_test
[0m13:19:25.323004 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:25.328715 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: ROLLBACK
[0m13:19:25.337280 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: Close
[0m13:19:25.354157 [info ] [Thread-1 (]: 10 of 31 PASS not_null_dim_shipping_shipping_id ................................ [[32mPASS[0m in 0.25s]
[0m13:19:25.359961 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:19:25.366525 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:19:25.372868 [info ] [Thread-1 (]: 11 of 31 START test not_null_fct_orders_order_id ............................... [RUN]
[0m13:19:25.377829 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc, now test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0)
[0m13:19:25.384166 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:19:25.392342 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:19:25.496801 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:19:25.499989 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:19:25.567067 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:19:25.568498 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: BEGIN
[0m13:19:25.571096 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:25.582680 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:19:25.584632 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:19:25.587606 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_gold"."fct_orders"
where order_id is null



      
    ) dbt_internal_test
[0m13:19:25.590243 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:25.593177 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: ROLLBACK
[0m13:19:25.594696 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: Close
[0m13:19:25.596156 [info ] [Thread-1 (]: 11 of 31 PASS not_null_fct_orders_order_id ..................................... [[32mPASS[0m in 0.22s]
[0m13:19:25.597917 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:19:25.599200 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:19:25.600282 [info ] [Thread-1 (]: 12 of 31 START test not_null_fct_orders_order_total_vnd ........................ [RUN]
[0m13:19:25.601321 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0, now test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95)
[0m13:19:25.602437 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:19:25.607553 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:19:25.871033 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:19:25.882122 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:19:26.052548 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:19:26.064636 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: BEGIN
[0m13:19:26.068813 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:26.080895 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:19:26.087460 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:19:26.093167 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_total_vnd
from "ecommerce_db"."analytics_gold"."fct_orders"
where order_total_vnd is null



      
    ) dbt_internal_test
[0m13:19:26.098044 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:26.118937 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: ROLLBACK
[0m13:19:26.129946 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: Close
[0m13:19:26.142983 [info ] [Thread-1 (]: 12 of 31 PASS not_null_fct_orders_order_total_vnd .............................. [[32mPASS[0m in 0.54s]
[0m13:19:26.159192 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:19:26.168732 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:19:26.184743 [info ] [Thread-1 (]: 13 of 31 START test not_null_slv_customers_buyer_username ...................... [RUN]
[0m13:19:26.192631 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95, now test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c)
[0m13:19:26.200242 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:19:26.213345 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:19:26.652192 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:19:26.668379 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:19:26.760369 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:19:26.762526 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: BEGIN
[0m13:19:26.766787 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:26.779182 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:19:26.782116 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:19:26.787831 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_silver"."slv_customers"
where buyer_username is null



      
    ) dbt_internal_test
[0m13:19:26.790428 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:26.795122 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: ROLLBACK
[0m13:19:26.797497 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: Close
[0m13:19:26.803624 [info ] [Thread-1 (]: 13 of 31 PASS not_null_slv_customers_buyer_username ............................ [[32mPASS[0m in 0.61s]
[0m13:19:26.805449 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:19:26.807809 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:19:26.809276 [info ] [Thread-1 (]: 14 of 31 START test not_null_slv_customers_customer_id ......................... [RUN]
[0m13:19:26.811437 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c, now test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9)
[0m13:19:26.816711 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:19:26.824116 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:19:27.074438 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:19:27.084204 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:19:27.315112 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:19:27.322286 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: BEGIN
[0m13:19:27.325616 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:27.338471 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:19:27.345119 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:19:27.357672 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "ecommerce_db"."analytics_silver"."slv_customers"
where customer_id is null



      
    ) dbt_internal_test
[0m13:19:27.368316 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:27.379718 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: ROLLBACK
[0m13:19:27.383732 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: Close
[0m13:19:27.387633 [info ] [Thread-1 (]: 14 of 31 PASS not_null_slv_customers_customer_id ............................... [[32mPASS[0m in 0.58s]
[0m13:19:27.393020 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:19:27.398632 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:19:27.400743 [info ] [Thread-1 (]: 15 of 31 START test not_null_slv_dates_date_key ................................ [RUN]
[0m13:19:27.407268 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9, now test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954)
[0m13:19:27.412824 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:19:27.420541 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:19:27.581547 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:19:27.588551 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:19:27.748656 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:19:27.753624 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: BEGIN
[0m13:19:27.755492 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:27.770988 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m13:19:27.775541 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:19:27.777261 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date_key
from "ecommerce_db"."analytics_silver"."slv_dates"
where date_key is null



      
    ) dbt_internal_test
[0m13:19:27.782943 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:27.790032 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: ROLLBACK
[0m13:19:27.795645 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: Close
[0m13:19:27.798352 [info ] [Thread-1 (]: 15 of 31 PASS not_null_slv_dates_date_key ...................................... [[32mPASS[0m in 0.39s]
[0m13:19:27.802677 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:19:27.808746 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:19:27.824513 [info ] [Thread-1 (]: 16 of 31 START test not_null_slv_orders_order_date ............................. [RUN]
[0m13:19:27.832322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954, now test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442)
[0m13:19:27.844892 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:19:27.856879 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:19:27.941293 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:19:27.945866 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:19:28.076141 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:19:28.081988 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: BEGIN
[0m13:19:28.085875 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:28.094913 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:19:28.095953 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:19:28.103065 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_date
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_date is null



      
    ) dbt_internal_test
[0m13:19:28.110662 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:28.115521 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: ROLLBACK
[0m13:19:28.117549 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: Close
[0m13:19:28.122019 [info ] [Thread-1 (]: 16 of 31 PASS not_null_slv_orders_order_date ................................... [[32mPASS[0m in 0.29s]
[0m13:19:28.123934 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:19:28.128503 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:19:28.129802 [info ] [Thread-1 (]: 17 of 31 START test not_null_slv_orders_order_id ............................... [RUN]
[0m13:19:28.131691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442, now test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2)
[0m13:19:28.135867 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:19:28.210385 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:19:28.515090 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:19:28.529430 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:19:28.735185 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:19:28.739717 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: BEGIN
[0m13:19:28.741169 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:28.752063 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:19:28.753446 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:19:28.754786 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_id is null



      
    ) dbt_internal_test
[0m13:19:28.757774 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:28.761855 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: ROLLBACK
[0m13:19:28.763626 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: Close
[0m13:19:28.767885 [info ] [Thread-1 (]: 17 of 31 PASS not_null_slv_orders_order_id ..................................... [[32mPASS[0m in 0.64s]
[0m13:19:28.769727 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:19:28.774700 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:19:28.781998 [info ] [Thread-1 (]: 18 of 31 START test not_null_slv_orders_order_total_vnd ........................ [RUN]
[0m13:19:28.784121 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2, now test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1)
[0m13:19:28.789349 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:19:28.797936 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:19:28.876280 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:19:28.880394 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:19:28.962359 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:19:28.964326 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: BEGIN
[0m13:19:28.966067 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:28.975224 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m13:19:28.976083 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:19:28.976996 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_total_vnd
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_total_vnd is null



      
    ) dbt_internal_test
[0m13:19:28.979071 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:28.980998 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: ROLLBACK
[0m13:19:28.982043 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: Close
[0m13:19:28.983538 [info ] [Thread-1 (]: 18 of 31 PASS not_null_slv_orders_order_total_vnd .............................. [[32mPASS[0m in 0.20s]
[0m13:19:28.984726 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:19:28.986721 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:19:28.990366 [info ] [Thread-1 (]: 19 of 31 START test not_null_slv_products_product_id ........................... [RUN]
[0m13:19:28.992219 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1, now test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621)
[0m13:19:28.995890 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:19:29.001212 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:19:29.078958 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:19:29.083379 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:19:29.185263 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:19:29.188300 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: BEGIN
[0m13:19:29.191157 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:29.208365 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m13:19:29.211672 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:19:29.213336 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_id
from "ecommerce_db"."analytics_silver"."slv_products"
where product_id is null



      
    ) dbt_internal_test
[0m13:19:29.216983 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:29.219533 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: ROLLBACK
[0m13:19:29.221581 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: Close
[0m13:19:29.225372 [info ] [Thread-1 (]: 19 of 31 PASS not_null_slv_products_product_id ................................. [[32mPASS[0m in 0.23s]
[0m13:19:29.226490 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:19:29.227464 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:19:29.228153 [info ] [Thread-1 (]: 20 of 31 START test unique_agg_customer_summary_buyer_username ................. [RUN]
[0m13:19:29.232691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621, now test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359)
[0m13:19:29.235821 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:19:29.253830 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:19:29.380096 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:19:29.389729 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:19:29.544741 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:19:29.545751 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: BEGIN
[0m13:19:29.546865 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:29.562551 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m13:19:29.567102 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:19:29.568736 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    buyer_username as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_customer_summary"
where buyer_username is not null
group by buyer_username
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:29.574818 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m13:19:29.580714 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: ROLLBACK
[0m13:19:29.582584 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: Close
[0m13:19:29.586305 [info ] [Thread-1 (]: 20 of 31 PASS unique_agg_customer_summary_buyer_username ....................... [[32mPASS[0m in 0.35s]
[0m13:19:29.588080 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:19:29.589071 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:19:29.592922 [info ] [Thread-1 (]: 21 of 31 START test unique_agg_daily_sales_order_date .......................... [RUN]
[0m13:19:29.594116 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359, now test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d)
[0m13:19:29.595639 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:19:29.601963 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:19:29.690647 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:19:29.694448 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:19:29.823266 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:19:29.848228 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: BEGIN
[0m13:19:29.862386 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:29.876307 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:19:29.892653 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:19:29.898280 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_date as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_daily_sales"
where order_date is not null
group by order_date
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:29.902947 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:29.910805 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: ROLLBACK
[0m13:19:29.912928 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: Close
[0m13:19:29.914570 [info ] [Thread-1 (]: 21 of 31 PASS unique_agg_daily_sales_order_date ................................ [[32mPASS[0m in 0.32s]
[0m13:19:29.916102 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:19:29.920144 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:19:29.921236 [info ] [Thread-1 (]: 22 of 31 START test unique_agg_product_performance_product_name ................ [RUN]
[0m13:19:29.922727 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d, now test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03)
[0m13:19:29.926561 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:19:29.933904 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:19:29.997537 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:19:30.000938 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:19:30.040618 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:19:30.041692 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: BEGIN
[0m13:19:30.043141 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:30.052843 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:19:30.053808 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:19:30.054800 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_name as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_product_performance"
where product_name is not null
group by product_name
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:30.057464 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:30.065840 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: ROLLBACK
[0m13:19:30.067545 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: Close
[0m13:19:30.069036 [info ] [Thread-1 (]: 22 of 31 PASS unique_agg_product_performance_product_name ...................... [[32mPASS[0m in 0.15s]
[0m13:19:30.070559 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:19:30.072250 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:19:30.073241 [info ] [Thread-1 (]: 23 of 31 START test unique_dim_customer_customer_id ............................ [RUN]
[0m13:19:30.074504 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03, now test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1)
[0m13:19:30.075555 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:19:30.083617 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:19:30.195923 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:19:30.208856 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:19:30.293233 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:19:30.294919 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: BEGIN
[0m13:19:30.296476 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:30.304868 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m13:19:30.306042 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:19:30.306911 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_customer"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:30.308992 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:30.311072 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: ROLLBACK
[0m13:19:30.312768 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: Close
[0m13:19:30.314186 [info ] [Thread-1 (]: 23 of 31 PASS unique_dim_customer_customer_id .................................. [[32mPASS[0m in 0.24s]
[0m13:19:30.316018 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:19:30.317201 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:19:30.318278 [info ] [Thread-1 (]: 24 of 31 START test unique_dim_date_date_key ................................... [RUN]
[0m13:19:30.320801 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1, now test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9)
[0m13:19:30.321814 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:19:30.326800 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:19:30.373771 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:19:30.381162 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:19:30.451854 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:19:30.455410 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: BEGIN
[0m13:19:30.460637 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:30.480578 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m13:19:30.481720 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:19:30.483256 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_key as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_date"
where date_key is not null
group by date_key
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:30.486805 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:19:30.489047 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: ROLLBACK
[0m13:19:30.491678 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: Close
[0m13:19:30.493421 [info ] [Thread-1 (]: 24 of 31 PASS unique_dim_date_date_key ......................................... [[32mPASS[0m in 0.17s]
[0m13:19:30.494805 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:19:30.496319 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:19:30.498213 [info ] [Thread-1 (]: 25 of 31 START test unique_dim_payment_payment_method_id ....................... [RUN]
[0m13:19:30.499163 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9, now test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209)
[0m13:19:30.500067 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:19:30.508035 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:19:30.671021 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:19:30.680861 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:19:30.832703 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:19:30.836309 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: BEGIN
[0m13:19:30.839486 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:30.853411 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:19:30.855654 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:19:30.856918 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    payment_method_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_payment"
where payment_method_id is not null
group by payment_method_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:30.859492 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:30.866663 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: ROLLBACK
[0m13:19:30.870913 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: Close
[0m13:19:30.872919 [info ] [Thread-1 (]: 25 of 31 PASS unique_dim_payment_payment_method_id ............................. [[32mPASS[0m in 0.37s]
[0m13:19:30.877674 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:19:30.879418 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:19:30.881065 [info ] [Thread-1 (]: 26 of 31 START test unique_dim_product_product_id .............................. [RUN]
[0m13:19:30.884510 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209, now test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe)
[0m13:19:30.885953 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:19:30.891528 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:19:31.005819 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:19:31.013774 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:19:31.204092 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:19:31.206279 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: BEGIN
[0m13:19:31.207649 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:31.219855 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:19:31.221080 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:19:31.222863 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_product"
where product_id is not null
group by product_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:31.225983 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:31.230405 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: ROLLBACK
[0m13:19:31.233020 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: Close
[0m13:19:31.235033 [info ] [Thread-1 (]: 26 of 31 PASS unique_dim_product_product_id .................................... [[32mPASS[0m in 0.35s]
[0m13:19:31.238185 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:19:31.239705 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:19:31.241332 [info ] [Thread-1 (]: 27 of 31 START test unique_dim_shipping_shipping_id ............................ [RUN]
[0m13:19:31.245727 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe, now test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f)
[0m13:19:31.247726 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:19:31.253221 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:19:31.394095 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:19:31.416817 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:19:31.544690 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:19:31.550597 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: BEGIN
[0m13:19:31.551884 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:31.562393 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:19:31.565058 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:19:31.566058 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    shipping_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_shipping"
where shipping_id is not null
group by shipping_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:31.568377 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:31.572482 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: ROLLBACK
[0m13:19:31.574030 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: Close
[0m13:19:31.575528 [info ] [Thread-1 (]: 27 of 31 PASS unique_dim_shipping_shipping_id .................................. [[32mPASS[0m in 0.33s]
[0m13:19:31.580044 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:19:31.581664 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:19:31.584335 [info ] [Thread-1 (]: 28 of 31 START test unique_slv_customers_customer_id ........................... [RUN]
[0m13:19:31.585986 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f, now test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b)
[0m13:19:31.587521 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:19:31.593659 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:19:31.653491 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:19:31.657012 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:19:31.725057 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:19:31.731860 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: BEGIN
[0m13:19:31.735842 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:31.749702 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:19:31.752972 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:19:31.754899 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_customers"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:31.759235 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m13:19:31.764565 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: ROLLBACK
[0m13:19:31.767155 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: Close
[0m13:19:31.770563 [info ] [Thread-1 (]: 28 of 31 PASS unique_slv_customers_customer_id ................................. [[32mPASS[0m in 0.18s]
[0m13:19:31.771694 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:19:31.772660 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:19:31.773630 [info ] [Thread-1 (]: 29 of 31 START test unique_slv_dates_date_key .................................. [RUN]
[0m13:19:31.774629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b, now test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc)
[0m13:19:31.775658 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:19:31.786180 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:19:31.871110 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:19:31.874793 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:19:31.958932 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:19:31.961309 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: BEGIN
[0m13:19:31.978739 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:32.005875 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m13:19:32.012090 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:19:32.021631 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_key as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_dates"
where date_key is not null
group by date_key
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:32.027194 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m13:19:32.045462 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: ROLLBACK
[0m13:19:32.048433 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: Close
[0m13:19:32.052044 [info ] [Thread-1 (]: 29 of 31 PASS unique_slv_dates_date_key ........................................ [[32mPASS[0m in 0.28s]
[0m13:19:32.053558 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:19:32.056380 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m13:19:32.058886 [info ] [Thread-1 (]: 30 of 31 START test unique_slv_orders_order_id ................................. [RUN]
[0m13:19:32.059980 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc, now test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e)
[0m13:19:32.060980 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m13:19:32.070160 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m13:19:32.142227 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m13:19:32.149035 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m13:19:32.297231 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m13:19:32.302258 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: BEGIN
[0m13:19:32.304731 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:32.326910 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m13:19:32.329286 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"
[0m13:19:32.331395 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_orders"
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:32.336172 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m13:19:32.340279 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: ROLLBACK
[0m13:19:32.341874 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e: Close
[0m13:19:32.343618 [error] [Thread-1 (]: 30 of 31 FAIL 154 unique_slv_orders_order_id ................................... [[31mFAIL 154[0m in 0.28s]
[0m13:19:32.345993 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e
[0m13:19:32.348345 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:19:32.349577 [info ] [Thread-1 (]: 31 of 31 START test unique_slv_products_product_id ............................. [RUN]
[0m13:19:32.351767 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_orders_order_id.eb9511b79e, now test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb)
[0m13:19:32.353298 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:19:32.361324 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:19:32.432742 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:19:32.435726 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:19:32.508023 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:19:32.510213 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: BEGIN
[0m13:19:32.511931 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:32.533030 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m13:19:32.535059 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:19:32.536853 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_products"
where product_id is not null
group by product_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:19:32.539712 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:19:32.544937 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: ROLLBACK
[0m13:19:32.548155 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: Close
[0m13:19:32.552599 [info ] [Thread-1 (]: 31 of 31 PASS unique_slv_products_product_id ................................... [[32mPASS[0m in 0.20s]
[0m13:19:32.555176 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:19:32.562059 [debug] [MainThread]: Using postgres connection "master"
[0m13:19:32.563578 [debug] [MainThread]: On master: BEGIN
[0m13:19:32.564550 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:19:32.579083 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m13:19:32.581701 [debug] [MainThread]: On master: COMMIT
[0m13:19:32.586208 [debug] [MainThread]: Using postgres connection "master"
[0m13:19:32.588504 [debug] [MainThread]: On master: COMMIT
[0m13:19:32.592035 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m13:19:32.594481 [debug] [MainThread]: On master: Close
[0m13:19:32.596877 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:19:32.599818 [debug] [MainThread]: Connection 'test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb' was properly closed.
[0m13:19:32.601540 [info ] [MainThread]: 
[0m13:19:32.603259 [info ] [MainThread]: Finished running 31 data tests in 0 hours 0 minutes and 10.57 seconds (10.57s).
[0m13:19:32.620051 [debug] [MainThread]: Command end result
[0m13:19:32.888161 [info ] [MainThread]: 
[0m13:19:32.891147 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:19:32.892729 [info ] [MainThread]: 
[0m13:19:32.893641 [error] [MainThread]: [31mFailure in test unique_slv_orders_order_id (models/silver/_silver__models.yml)[0m
[0m13:19:32.898902 [error] [MainThread]:   Got 154 results, configured to fail if != 0
[0m13:19:32.901860 [info ] [MainThread]: 
[0m13:19:32.907420 [info ] [MainThread]:   compiled code at target/compiled/ecommerce_dbt/models/silver/_silver__models.yml/unique_slv_orders_order_id.sql
[0m13:19:32.909024 [info ] [MainThread]: 
[0m13:19:32.913812 [info ] [MainThread]: Done. PASS=30 WARN=0 ERROR=1 SKIP=0 TOTAL=31
[0m13:19:32.916554 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 12.939996, "process_user_time": 3.563534, "process_kernel_time": 0.494597, "process_mem_max_rss": "121976", "process_in_blocks": "1112", "command_success": false, "process_out_blocks": "0"}
[0m13:19:32.920896 [debug] [MainThread]: Command `dbt test` failed at 13:19:32.920550 after 12.94 seconds
[0m13:19:32.923646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231e3a72f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e231ad88bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e23220e2e70>]}
[0m13:19:32.926399 [debug] [MainThread]: Flushing usage events
[0m13:20:28.379809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c489cec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c469f860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c4fff590>]}


============================== 13:20:28.384515 | e9cf5faa-e150-49a2-8a61-3a3438a3b785 ==============================
[0m13:20:28.384515 [info ] [MainThread]: Running with dbt=1.8.0
[0m13:20:28.385717 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:20:28.650803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e9cf5faa-e150-49a2-8a61-3a3438a3b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c35919d0>]}
[0m13:20:28.711941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e9cf5faa-e150-49a2-8a61-3a3438a3b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c4c10950>]}
[0m13:20:28.715188 [info ] [MainThread]: Registered adapter: postgres=1.8.0
[0m13:20:28.767064 [debug] [MainThread]: checksum: dbb12d416fdb55e3665e4828703bbedf40c5c90ed7ca6ff39bbbfb29b12b0a92, vars: {}, profile: , target: , version: 1.8.0
[0m13:20:30.727348 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:20:30.731151 [debug] [MainThread]: Partial parsing: updated file: ecommerce_dbt://models/silver/_silver__models.yml
[0m13:20:31.160159 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m13:20:31.166379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e9cf5faa-e150-49a2-8a61-3a3438a3b785', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c35a1b80>]}
[0m13:20:31.602924 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ecommerce_dbt.marts
- models.ecommerce_dbt.staging
[0m13:20:31.638420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e9cf5faa-e150-49a2-8a61-3a3438a3b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c21aae40>]}
[0m13:20:31.986714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e9cf5faa-e150-49a2-8a61-3a3438a3b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c04b4ec0>]}
[0m13:20:31.992334 [info ] [MainThread]: Found 14 models, 1 seed, 30 data tests, 1 source, 417 macros
[0m13:20:31.995236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9cf5faa-e150-49a2-8a61-3a3438a3b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c35e6240>]}
[0m13:20:32.006623 [info ] [MainThread]: 
[0m13:20:32.010170 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:20:32.022208 [debug] [ThreadPool]: Acquiring new postgres connection 'list_ecommerce_db_analytics_silver'
[0m13:20:32.090130 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:20:32.093717 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: BEGIN
[0m13:20:32.097276 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:20:32.119985 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m13:20:32.122323 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_silver"
[0m13:20:32.127051 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_silver"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_silver'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_silver'
  
[0m13:20:32.134569 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.005 seconds
[0m13:20:32.136791 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: ROLLBACK
[0m13:20:32.140115 [debug] [ThreadPool]: On list_ecommerce_db_analytics_silver: Close
[0m13:20:32.143101 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_silver, now list_ecommerce_db_analytics_bronze)
[0m13:20:32.146187 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:20:32.147513 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: BEGIN
[0m13:20:32.149769 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:20:32.162111 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m13:20:32.163835 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_bronze"
[0m13:20:32.165147 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_bronze"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_bronze'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_bronze'
  
[0m13:20:32.169454 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m13:20:32.174607 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: ROLLBACK
[0m13:20:32.175607 [debug] [ThreadPool]: On list_ecommerce_db_analytics_bronze: Close
[0m13:20:32.176688 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_bronze, now list_ecommerce_db_analytics)
[0m13:20:32.179252 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:20:32.180667 [debug] [ThreadPool]: On list_ecommerce_db_analytics: BEGIN
[0m13:20:32.182698 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:20:32.194601 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m13:20:32.195372 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics"
[0m13:20:32.196168 [debug] [ThreadPool]: On list_ecommerce_db_analytics: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m13:20:32.200080 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m13:20:32.202873 [debug] [ThreadPool]: On list_ecommerce_db_analytics: ROLLBACK
[0m13:20:32.204039 [debug] [ThreadPool]: On list_ecommerce_db_analytics: Close
[0m13:20:32.206319 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics, now list_ecommerce_db_analytics_gold)
[0m13:20:32.209064 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:20:32.210038 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: BEGIN
[0m13:20:32.210732 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:20:32.219756 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m13:20:32.221215 [debug] [ThreadPool]: Using postgres connection "list_ecommerce_db_analytics_gold"
[0m13:20:32.222297 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "list_ecommerce_db_analytics_gold"} */
select
      'ecommerce_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_gold'
    union all
    select
      'ecommerce_db' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_gold'
  
[0m13:20:32.227514 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.004 seconds
[0m13:20:32.231118 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: ROLLBACK
[0m13:20:32.233233 [debug] [ThreadPool]: On list_ecommerce_db_analytics_gold: Close
[0m13:20:32.240449 [debug] [MainThread]: Using postgres connection "master"
[0m13:20:32.242676 [debug] [MainThread]: On master: BEGIN
[0m13:20:32.243645 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:20:32.252413 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m13:20:32.255645 [debug] [MainThread]: Using postgres connection "master"
[0m13:20:32.257471 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:20:32.274117 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m13:20:32.286453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9cf5faa-e150-49a2-8a61-3a3438a3b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c3558560>]}
[0m13:20:32.289293 [debug] [MainThread]: On master: ROLLBACK
[0m13:20:32.292658 [debug] [MainThread]: Using postgres connection "master"
[0m13:20:32.295244 [debug] [MainThread]: On master: BEGIN
[0m13:20:32.300522 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m13:20:32.302847 [debug] [MainThread]: On master: COMMIT
[0m13:20:32.305642 [debug] [MainThread]: Using postgres connection "master"
[0m13:20:32.307300 [debug] [MainThread]: On master: COMMIT
[0m13:20:32.310151 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m13:20:32.312550 [debug] [MainThread]: On master: Close
[0m13:20:32.315764 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:20:32.319801 [info ] [MainThread]: 
[0m13:20:32.328021 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:20:32.329140 [info ] [Thread-1 (]: 1 of 30 START test not_null_agg_customer_summary_buyer_username ................ [RUN]
[0m13:20:32.407780 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_ecommerce_db_analytics_gold, now test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e)
[0m13:20:32.409771 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:20:32.446376 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:20:32.530740 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:20:32.568105 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:20:32.686415 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:20:32.689936 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: BEGIN
[0m13:20:32.693454 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:32.709442 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m13:20:32.711987 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"
[0m13:20:32.716110 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_gold"."agg_customer_summary"
where buyer_username is null



      
    ) dbt_internal_test
[0m13:20:32.721534 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:32.727502 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: ROLLBACK
[0m13:20:32.730275 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e: Close
[0m13:20:32.733932 [info ] [Thread-1 (]: 1 of 30 PASS not_null_agg_customer_summary_buyer_username ...................... [[32mPASS[0m in 0.40s]
[0m13:20:32.735931 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e
[0m13:20:32.737048 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:20:32.738083 [info ] [Thread-1 (]: 2 of 30 START test not_null_agg_daily_sales_order_date ......................... [RUN]
[0m13:20:32.739012 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_customer_summary_buyer_username.8e7587428e, now test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8)
[0m13:20:32.740650 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:20:32.747291 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:20:32.779433 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:20:32.784256 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:20:32.827089 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:20:32.830469 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: BEGIN
[0m13:20:32.836639 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:32.847464 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:20:32.848494 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"
[0m13:20:32.849446 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_date
from "ecommerce_db"."analytics_gold"."agg_daily_sales"
where order_date is null



      
    ) dbt_internal_test
[0m13:20:32.851068 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:32.855207 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: ROLLBACK
[0m13:20:32.856454 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8: Close
[0m13:20:32.857534 [info ] [Thread-1 (]: 2 of 30 PASS not_null_agg_daily_sales_order_date ............................... [[32mPASS[0m in 0.12s]
[0m13:20:32.861304 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8
[0m13:20:32.862167 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:20:32.862908 [info ] [Thread-1 (]: 3 of 30 START test not_null_agg_product_performance_product_name ............... [RUN]
[0m13:20:32.863666 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_daily_sales_order_date.abb84547a8, now test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1)
[0m13:20:32.864517 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:20:32.873788 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:20:32.946361 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:20:32.953326 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:20:33.035360 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:20:33.038137 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: BEGIN
[0m13:20:33.042214 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:33.052615 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:20:33.054803 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"
[0m13:20:33.056869 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_name
from "ecommerce_db"."analytics_gold"."agg_product_performance"
where product_name is null



      
    ) dbt_internal_test
[0m13:20:33.058696 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:33.063441 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: ROLLBACK
[0m13:20:33.065606 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1: Close
[0m13:20:33.068931 [info ] [Thread-1 (]: 3 of 30 PASS not_null_agg_product_performance_product_name ..................... [[32mPASS[0m in 0.21s]
[0m13:20:33.070387 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1
[0m13:20:33.071327 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:20:33.072751 [info ] [Thread-1 (]: 4 of 30 START test not_null_brz_raw_orders_order_id ............................ [RUN]
[0m13:20:33.076114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_agg_product_performance_product_name.1b70d729a1, now test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750)
[0m13:20:33.077696 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:20:33.085118 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:20:33.124177 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:20:33.128831 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:20:33.160670 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:20:33.162256 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: BEGIN
[0m13:20:33.163664 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:33.174317 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:20:33.175185 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"
[0m13:20:33.176149 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_bronze"."brz_raw_orders"
where order_id is null



      
    ) dbt_internal_test
[0m13:20:33.179034 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:33.182101 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: ROLLBACK
[0m13:20:33.183255 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750: Close
[0m13:20:33.184711 [info ] [Thread-1 (]: 4 of 30 PASS not_null_brz_raw_orders_order_id .................................. [[32mPASS[0m in 0.11s]
[0m13:20:33.186586 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750
[0m13:20:33.187831 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:20:33.188685 [info ] [Thread-1 (]: 5 of 30 START test not_null_dim_customer_buyer_username ........................ [RUN]
[0m13:20:33.189585 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_brz_raw_orders_order_id.a201b7c750, now test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b)
[0m13:20:33.190701 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:20:33.198226 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:20:33.233008 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:20:33.239502 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:20:33.279822 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:20:33.280917 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: BEGIN
[0m13:20:33.283979 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:33.295805 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:20:33.299585 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"
[0m13:20:33.301038 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_gold"."dim_customer"
where buyer_username is null



      
    ) dbt_internal_test
[0m13:20:33.303627 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:33.306312 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: ROLLBACK
[0m13:20:33.308303 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b: Close
[0m13:20:33.310302 [info ] [Thread-1 (]: 5 of 30 PASS not_null_dim_customer_buyer_username .............................. [[32mPASS[0m in 0.12s]
[0m13:20:33.312863 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b
[0m13:20:33.314107 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:20:33.315518 [info ] [Thread-1 (]: 6 of 30 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m13:20:33.318626 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_customer_buyer_username.ab75a7306b, now test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc)
[0m13:20:33.320098 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:20:33.326817 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:20:33.372177 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:20:33.378696 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:20:33.412550 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:20:33.413535 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m13:20:33.416576 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:33.424076 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m13:20:33.425038 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"
[0m13:20:33.425709 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "ecommerce_db"."analytics_gold"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m13:20:33.427231 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:33.430235 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m13:20:33.431472 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc: Close
[0m13:20:33.433407 [info ] [Thread-1 (]: 6 of 30 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.11s]
[0m13:20:33.434964 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc
[0m13:20:33.436464 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:20:33.437379 [info ] [Thread-1 (]: 7 of 30 START test not_null_dim_date_date_key .................................. [RUN]
[0m13:20:33.438384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_customer_customer_id.9775012dfc, now test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6)
[0m13:20:33.439353 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:20:33.444353 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:20:33.486032 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:20:33.490254 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:20:33.519909 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:20:33.520875 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: BEGIN
[0m13:20:33.521767 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:33.529095 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m13:20:33.534122 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"
[0m13:20:33.536449 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date_key
from "ecommerce_db"."analytics_gold"."dim_date"
where date_key is null



      
    ) dbt_internal_test
[0m13:20:33.538275 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:33.541728 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: ROLLBACK
[0m13:20:33.543002 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6: Close
[0m13:20:33.544271 [info ] [Thread-1 (]: 7 of 30 PASS not_null_dim_date_date_key ........................................ [[32mPASS[0m in 0.11s]
[0m13:20:33.545479 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6
[0m13:20:33.547051 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:20:33.548213 [info ] [Thread-1 (]: 8 of 30 START test not_null_dim_payment_payment_method_id ...................... [RUN]
[0m13:20:33.549267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_date_date_key.881d0a31b6, now test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b)
[0m13:20:33.550375 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:20:33.556414 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:20:33.599998 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:20:33.609355 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:20:33.698278 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:20:33.701643 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: BEGIN
[0m13:20:33.704180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:33.715787 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:20:33.716903 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"
[0m13:20:33.717993 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select payment_method_id
from "ecommerce_db"."analytics_gold"."dim_payment"
where payment_method_id is null



      
    ) dbt_internal_test
[0m13:20:33.720229 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:33.723273 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: ROLLBACK
[0m13:20:33.725935 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b: Close
[0m13:20:33.729827 [info ] [Thread-1 (]: 8 of 30 PASS not_null_dim_payment_payment_method_id ............................ [[32mPASS[0m in 0.18s]
[0m13:20:33.732605 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b
[0m13:20:33.735511 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:20:33.736436 [info ] [Thread-1 (]: 9 of 30 START test not_null_dim_product_product_id ............................. [RUN]
[0m13:20:33.738004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_payment_payment_method_id.479876bd4b, now test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816)
[0m13:20:33.739767 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:20:33.751854 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:20:33.812534 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:20:33.817605 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:20:33.898905 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:20:33.905695 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: BEGIN
[0m13:20:33.910608 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:33.923600 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m13:20:33.925365 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"
[0m13:20:33.927964 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_id
from "ecommerce_db"."analytics_gold"."dim_product"
where product_id is null



      
    ) dbt_internal_test
[0m13:20:33.932808 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:33.939548 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: ROLLBACK
[0m13:20:33.944617 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816: Close
[0m13:20:33.946189 [info ] [Thread-1 (]: 9 of 30 PASS not_null_dim_product_product_id ................................... [[32mPASS[0m in 0.21s]
[0m13:20:33.948659 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816
[0m13:20:33.951507 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:20:33.953516 [info ] [Thread-1 (]: 10 of 30 START test not_null_dim_shipping_shipping_id .......................... [RUN]
[0m13:20:33.958737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_product_product_id.02b1f06816, now test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc)
[0m13:20:33.961317 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:20:33.975978 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:20:34.058186 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:20:34.062528 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:20:34.126925 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:20:34.132063 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: BEGIN
[0m13:20:34.134303 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:34.144756 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:20:34.145755 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"
[0m13:20:34.147023 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select shipping_id
from "ecommerce_db"."analytics_gold"."dim_shipping"
where shipping_id is null



      
    ) dbt_internal_test
[0m13:20:34.150540 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:34.156349 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: ROLLBACK
[0m13:20:34.159843 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc: Close
[0m13:20:34.163258 [info ] [Thread-1 (]: 10 of 30 PASS not_null_dim_shipping_shipping_id ................................ [[32mPASS[0m in 0.20s]
[0m13:20:34.167131 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc
[0m13:20:34.169612 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:20:34.173238 [info ] [Thread-1 (]: 11 of 30 START test not_null_fct_orders_order_id ............................... [RUN]
[0m13:20:34.175363 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_dim_shipping_shipping_id.a602555adc, now test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0)
[0m13:20:34.177147 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:20:34.187223 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:20:34.261232 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:20:34.267002 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:20:34.326893 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:20:34.329054 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: BEGIN
[0m13:20:34.330543 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:34.348872 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m13:20:34.349968 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"
[0m13:20:34.353689 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_gold"."fct_orders"
where order_id is null



      
    ) dbt_internal_test
[0m13:20:34.356915 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:34.363866 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: ROLLBACK
[0m13:20:34.366413 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0: Close
[0m13:20:34.368151 [info ] [Thread-1 (]: 11 of 30 PASS not_null_fct_orders_order_id ..................................... [[32mPASS[0m in 0.19s]
[0m13:20:34.369496 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0
[0m13:20:34.370578 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:20:34.371680 [info ] [Thread-1 (]: 12 of 30 START test not_null_fct_orders_order_total_vnd ........................ [RUN]
[0m13:20:34.374948 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_fct_orders_order_id.4e687af8d0, now test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95)
[0m13:20:34.375874 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:20:34.388622 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:20:34.434386 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:20:34.439756 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:20:34.486826 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:20:34.488236 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: BEGIN
[0m13:20:34.489915 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:34.499575 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:20:34.501131 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"
[0m13:20:34.505468 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_total_vnd
from "ecommerce_db"."analytics_gold"."fct_orders"
where order_total_vnd is null



      
    ) dbt_internal_test
[0m13:20:34.508765 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:34.513127 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: ROLLBACK
[0m13:20:34.515072 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95: Close
[0m13:20:34.517009 [info ] [Thread-1 (]: 12 of 30 PASS not_null_fct_orders_order_total_vnd .............................. [[32mPASS[0m in 0.14s]
[0m13:20:34.520661 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95
[0m13:20:34.522656 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:20:34.526891 [info ] [Thread-1 (]: 13 of 30 START test not_null_slv_customers_buyer_username ...................... [RUN]
[0m13:20:34.528894 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_fct_orders_order_total_vnd.a38654ad95, now test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c)
[0m13:20:34.530069 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:20:34.535740 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:20:34.601263 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:20:34.606285 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:20:34.649106 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:20:34.652463 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: BEGIN
[0m13:20:34.654094 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:34.664096 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:20:34.666755 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"
[0m13:20:34.668757 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select buyer_username
from "ecommerce_db"."analytics_silver"."slv_customers"
where buyer_username is null



      
    ) dbt_internal_test
[0m13:20:34.671052 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:34.675939 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: ROLLBACK
[0m13:20:34.678381 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c: Close
[0m13:20:34.682040 [info ] [Thread-1 (]: 13 of 30 PASS not_null_slv_customers_buyer_username ............................ [[32mPASS[0m in 0.15s]
[0m13:20:34.683932 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c
[0m13:20:34.687178 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:20:34.688937 [info ] [Thread-1 (]: 14 of 30 START test not_null_slv_customers_customer_id ......................... [RUN]
[0m13:20:34.692057 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_customers_buyer_username.7e4f76622c, now test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9)
[0m13:20:34.694315 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:20:34.700446 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:20:34.737199 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:20:34.740744 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:20:34.800749 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:20:34.802743 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: BEGIN
[0m13:20:34.805819 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:34.821673 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m13:20:34.822888 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"
[0m13:20:34.827806 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "ecommerce_db"."analytics_silver"."slv_customers"
where customer_id is null



      
    ) dbt_internal_test
[0m13:20:34.837436 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.008 seconds
[0m13:20:34.844526 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: ROLLBACK
[0m13:20:34.847768 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9: Close
[0m13:20:34.849346 [info ] [Thread-1 (]: 14 of 30 PASS not_null_slv_customers_customer_id ............................... [[32mPASS[0m in 0.16s]
[0m13:20:34.850746 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9
[0m13:20:34.852790 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:20:34.853604 [info ] [Thread-1 (]: 15 of 30 START test not_null_slv_dates_date_key ................................ [RUN]
[0m13:20:34.854516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_customers_customer_id.de8346b1c9, now test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954)
[0m13:20:34.855905 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:20:34.862061 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:20:34.907418 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:20:34.911350 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:20:35.031713 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:20:35.036302 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: BEGIN
[0m13:20:35.044425 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:35.060683 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m13:20:35.062888 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"
[0m13:20:35.064206 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date_key
from "ecommerce_db"."analytics_silver"."slv_dates"
where date_key is null



      
    ) dbt_internal_test
[0m13:20:35.068261 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:35.073166 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: ROLLBACK
[0m13:20:35.075333 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954: Close
[0m13:20:35.076585 [info ] [Thread-1 (]: 15 of 30 PASS not_null_slv_dates_date_key ...................................... [[32mPASS[0m in 0.22s]
[0m13:20:35.077802 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954
[0m13:20:35.079708 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:20:35.081829 [info ] [Thread-1 (]: 16 of 30 START test not_null_slv_orders_order_date ............................. [RUN]
[0m13:20:35.082958 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_dates_date_key.b820144954, now test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442)
[0m13:20:35.083895 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:20:35.089593 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:20:35.132517 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:20:35.137001 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:20:35.180595 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:20:35.182681 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: BEGIN
[0m13:20:35.184464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:35.197915 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:20:35.200062 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"
[0m13:20:35.201984 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_date
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_date is null



      
    ) dbt_internal_test
[0m13:20:35.206630 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m13:20:35.210117 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: ROLLBACK
[0m13:20:35.212726 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442: Close
[0m13:20:35.217535 [info ] [Thread-1 (]: 16 of 30 PASS not_null_slv_orders_order_date ................................... [[32mPASS[0m in 0.13s]
[0m13:20:35.222767 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442
[0m13:20:35.226368 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:20:35.229767 [info ] [Thread-1 (]: 17 of 30 START test not_null_slv_orders_order_id ............................... [RUN]
[0m13:20:35.233089 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_date.2cb25d8442, now test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2)
[0m13:20:35.236648 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:20:35.243136 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:20:35.319618 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:20:35.324426 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:20:35.396281 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:20:35.397176 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: BEGIN
[0m13:20:35.398358 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:35.410163 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:20:35.411552 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"
[0m13:20:35.413813 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_id is null



      
    ) dbt_internal_test
[0m13:20:35.415836 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:35.421402 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: ROLLBACK
[0m13:20:35.423227 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2: Close
[0m13:20:35.425320 [info ] [Thread-1 (]: 17 of 30 PASS not_null_slv_orders_order_id ..................................... [[32mPASS[0m in 0.19s]
[0m13:20:35.429038 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2
[0m13:20:35.430951 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:20:35.433436 [info ] [Thread-1 (]: 18 of 30 START test not_null_slv_orders_order_total_vnd ........................ [RUN]
[0m13:20:35.435666 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_id.aad51188c2, now test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1)
[0m13:20:35.436773 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:20:35.449429 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:20:35.487782 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:20:35.490163 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:20:35.512403 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:20:35.514678 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: BEGIN
[0m13:20:35.516266 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:35.528459 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:20:35.530130 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"
[0m13:20:35.532211 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_total_vnd
from "ecommerce_db"."analytics_silver"."slv_orders"
where order_total_vnd is null



      
    ) dbt_internal_test
[0m13:20:35.536067 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:35.540407 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: ROLLBACK
[0m13:20:35.543081 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1: Close
[0m13:20:35.546460 [info ] [Thread-1 (]: 18 of 30 PASS not_null_slv_orders_order_total_vnd .............................. [[32mPASS[0m in 0.11s]
[0m13:20:35.548057 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1
[0m13:20:35.549113 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:20:35.550784 [info ] [Thread-1 (]: 19 of 30 START test not_null_slv_products_product_id ........................... [RUN]
[0m13:20:35.552101 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_orders_order_total_vnd.497d91e9b1, now test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621)
[0m13:20:35.553828 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:20:35.565366 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:20:35.605595 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:20:35.610366 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:20:35.640290 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:20:35.641556 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: BEGIN
[0m13:20:35.645718 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:35.655829 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:20:35.661716 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"
[0m13:20:35.666644 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select product_id
from "ecommerce_db"."analytics_silver"."slv_products"
where product_id is null



      
    ) dbt_internal_test
[0m13:20:35.670179 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:35.674687 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: ROLLBACK
[0m13:20:35.677279 [debug] [Thread-1 (]: On test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621: Close
[0m13:20:35.680965 [info ] [Thread-1 (]: 19 of 30 PASS not_null_slv_products_product_id ................................. [[32mPASS[0m in 0.13s]
[0m13:20:35.682684 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621
[0m13:20:35.684608 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:20:35.687700 [info ] [Thread-1 (]: 20 of 30 START test unique_agg_customer_summary_buyer_username ................. [RUN]
[0m13:20:35.689037 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.not_null_slv_products_product_id.480f90f621, now test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359)
[0m13:20:35.690733 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:20:35.703607 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:20:35.762935 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:20:35.766770 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:20:35.827774 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:20:35.828782 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: BEGIN
[0m13:20:35.830145 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:35.839924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m13:20:35.841462 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"
[0m13:20:35.843169 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    buyer_username as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_customer_summary"
where buyer_username is not null
group by buyer_username
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:35.847144 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:35.850918 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: ROLLBACK
[0m13:20:35.853394 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359: Close
[0m13:20:35.855028 [info ] [Thread-1 (]: 20 of 30 PASS unique_agg_customer_summary_buyer_username ....................... [[32mPASS[0m in 0.17s]
[0m13:20:35.856339 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359
[0m13:20:35.858540 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:20:35.860421 [info ] [Thread-1 (]: 21 of 30 START test unique_agg_daily_sales_order_date .......................... [RUN]
[0m13:20:35.861543 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_customer_summary_buyer_username.8637cbb359, now test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d)
[0m13:20:35.862933 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:20:35.870148 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:20:35.937772 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:20:35.946209 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:20:36.006854 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:20:36.009221 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: BEGIN
[0m13:20:36.012662 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:36.026393 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:20:36.027644 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"
[0m13:20:36.028427 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_date as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_daily_sales"
where order_date is not null
group by order_date
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:36.031371 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:36.035798 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: ROLLBACK
[0m13:20:36.039591 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d: Close
[0m13:20:36.042190 [info ] [Thread-1 (]: 21 of 30 PASS unique_agg_daily_sales_order_date ................................ [[32mPASS[0m in 0.18s]
[0m13:20:36.045175 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d
[0m13:20:36.047581 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:20:36.048881 [info ] [Thread-1 (]: 22 of 30 START test unique_agg_product_performance_product_name ................ [RUN]
[0m13:20:36.049952 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_daily_sales_order_date.964f674d6d, now test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03)
[0m13:20:36.051548 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:20:36.059303 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:20:36.148521 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:20:36.158940 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:20:36.280408 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:20:36.283273 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: BEGIN
[0m13:20:36.285626 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:36.299515 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:20:36.301368 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"
[0m13:20:36.304411 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_name as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."agg_product_performance"
where product_name is not null
group by product_name
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:36.308025 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:36.313102 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: ROLLBACK
[0m13:20:36.315908 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03: Close
[0m13:20:36.319293 [info ] [Thread-1 (]: 22 of 30 PASS unique_agg_product_performance_product_name ...................... [[32mPASS[0m in 0.27s]
[0m13:20:36.322141 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03
[0m13:20:36.324782 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:20:36.326114 [info ] [Thread-1 (]: 23 of 30 START test unique_dim_customer_customer_id ............................ [RUN]
[0m13:20:36.328062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_agg_product_performance_product_name.bde0ccbe03, now test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1)
[0m13:20:36.330283 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:20:36.341182 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:20:36.390897 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:20:36.394367 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:20:36.459405 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:20:36.460825 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: BEGIN
[0m13:20:36.461829 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:36.473547 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:20:36.475528 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"
[0m13:20:36.477805 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_customer"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:36.481037 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:36.483903 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: ROLLBACK
[0m13:20:36.487407 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1: Close
[0m13:20:36.489447 [info ] [Thread-1 (]: 23 of 30 PASS unique_dim_customer_customer_id .................................. [[32mPASS[0m in 0.16s]
[0m13:20:36.494405 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1
[0m13:20:36.495443 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:20:36.496317 [info ] [Thread-1 (]: 24 of 30 START test unique_dim_date_date_key ................................... [RUN]
[0m13:20:36.498881 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_customer_customer_id.b42affccd1, now test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9)
[0m13:20:36.500065 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:20:36.507156 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:20:36.549601 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:20:36.551683 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:20:36.702328 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:20:36.711317 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: BEGIN
[0m13:20:36.717455 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:36.737716 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m13:20:36.738865 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"
[0m13:20:36.740289 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_key as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_date"
where date_key is not null
group by date_key
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:36.748074 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.004 seconds
[0m13:20:36.751250 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: ROLLBACK
[0m13:20:36.754332 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9: Close
[0m13:20:36.757260 [info ] [Thread-1 (]: 24 of 30 PASS unique_dim_date_date_key ......................................... [[32mPASS[0m in 0.26s]
[0m13:20:36.758813 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9
[0m13:20:36.760644 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:20:36.762750 [info ] [Thread-1 (]: 25 of 30 START test unique_dim_payment_payment_method_id ....................... [RUN]
[0m13:20:36.763993 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_date_date_key.0869fd48f9, now test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209)
[0m13:20:36.765360 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:20:36.775178 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:20:36.841165 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:20:36.843537 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:20:36.910159 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:20:36.912040 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: BEGIN
[0m13:20:36.913604 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:36.927250 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m13:20:36.929011 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"
[0m13:20:36.931752 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    payment_method_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_payment"
where payment_method_id is not null
group by payment_method_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:36.935102 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:36.940116 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: ROLLBACK
[0m13:20:36.944713 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209: Close
[0m13:20:36.947966 [info ] [Thread-1 (]: 25 of 30 PASS unique_dim_payment_payment_method_id ............................. [[32mPASS[0m in 0.18s]
[0m13:20:36.950995 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209
[0m13:20:36.952294 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:20:36.954780 [info ] [Thread-1 (]: 26 of 30 START test unique_dim_product_product_id .............................. [RUN]
[0m13:20:36.957877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_payment_payment_method_id.2bbeaf8209, now test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe)
[0m13:20:36.959660 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:20:36.969470 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:20:37.015468 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:20:37.018783 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:20:37.056003 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:20:37.057630 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: BEGIN
[0m13:20:37.059629 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:37.077066 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m13:20:37.080347 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"
[0m13:20:37.082868 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_product"
where product_id is not null
group by product_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:37.089266 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.004 seconds
[0m13:20:37.094755 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: ROLLBACK
[0m13:20:37.098331 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe: Close
[0m13:20:37.101915 [info ] [Thread-1 (]: 26 of 30 PASS unique_dim_product_product_id .................................... [[32mPASS[0m in 0.14s]
[0m13:20:37.108038 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe
[0m13:20:37.112279 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:20:37.118735 [info ] [Thread-1 (]: 27 of 30 START test unique_dim_shipping_shipping_id ............................ [RUN]
[0m13:20:37.122351 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_product_product_id.46495bf7fe, now test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f)
[0m13:20:37.126321 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:20:37.138556 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:20:37.260739 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:20:37.268637 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:20:37.328951 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:20:37.334074 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: BEGIN
[0m13:20:37.336287 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:37.348617 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:20:37.349936 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"
[0m13:20:37.351175 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    shipping_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_gold"."dim_shipping"
where shipping_id is not null
group by shipping_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:37.355056 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:37.357022 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: ROLLBACK
[0m13:20:37.360909 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f: Close
[0m13:20:37.362399 [info ] [Thread-1 (]: 27 of 30 PASS unique_dim_shipping_shipping_id .................................. [[32mPASS[0m in 0.24s]
[0m13:20:37.363892 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f
[0m13:20:37.365565 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:20:37.367488 [info ] [Thread-1 (]: 28 of 30 START test unique_slv_customers_customer_id ........................... [RUN]
[0m13:20:37.368717 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_dim_shipping_shipping_id.42a5650e0f, now test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b)
[0m13:20:37.369719 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:20:37.376839 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:20:37.446686 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:20:37.452843 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:20:37.510653 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:20:37.513162 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: BEGIN
[0m13:20:37.515044 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:37.525538 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:20:37.527570 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"
[0m13:20:37.529132 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_customers"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:37.531628 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:37.535321 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: ROLLBACK
[0m13:20:37.538101 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b: Close
[0m13:20:37.541670 [info ] [Thread-1 (]: 28 of 30 PASS unique_slv_customers_customer_id ................................. [[32mPASS[0m in 0.17s]
[0m13:20:37.544216 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b
[0m13:20:37.548036 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:20:37.551480 [info ] [Thread-1 (]: 29 of 30 START test unique_slv_dates_date_key .................................. [RUN]
[0m13:20:37.554977 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_customers_customer_id.d47db4273b, now test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc)
[0m13:20:37.555847 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:20:37.560539 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:20:37.591532 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:20:37.596439 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:20:37.634353 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:20:37.635653 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: BEGIN
[0m13:20:37.638910 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:37.650403 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m13:20:37.653154 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"
[0m13:20:37.654313 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_key as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_dates"
where date_key is not null
group by date_key
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:37.656498 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m13:20:37.660618 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: ROLLBACK
[0m13:20:37.662307 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc: Close
[0m13:20:37.665041 [info ] [Thread-1 (]: 29 of 30 PASS unique_slv_dates_date_key ........................................ [[32mPASS[0m in 0.11s]
[0m13:20:37.666882 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc
[0m13:20:37.668220 [debug] [Thread-1 (]: Began running node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:20:37.669701 [info ] [Thread-1 (]: 30 of 30 START test unique_slv_products_product_id ............................. [RUN]
[0m13:20:37.673162 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ecommerce_dbt.unique_slv_dates_date_key.31a74be3dc, now test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb)
[0m13:20:37.674206 [debug] [Thread-1 (]: Began compiling node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:20:37.681307 [debug] [Thread-1 (]: Writing injected SQL for node "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:20:37.801800 [debug] [Thread-1 (]: Began executing node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:20:37.811140 [debug] [Thread-1 (]: Writing runtime sql for node "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:20:37.867972 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:20:37.868708 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: BEGIN
[0m13:20:37.869367 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:37.881596 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m13:20:37.882381 [debug] [Thread-1 (]: Using postgres connection "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"
[0m13:20:37.883126 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: /* {"app": "dbt", "dbt_version": "1.8.0", "profile_name": "ecommerce_profile", "target_name": "dev", "node_id": "test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    product_id as unique_field,
    count(*) as n_records

from "ecommerce_db"."analytics_silver"."slv_products"
where product_id is not null
group by product_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:20:37.886212 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m13:20:37.889453 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: ROLLBACK
[0m13:20:37.890563 [debug] [Thread-1 (]: On test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb: Close
[0m13:20:37.892957 [info ] [Thread-1 (]: 30 of 30 PASS unique_slv_products_product_id ................................... [[32mPASS[0m in 0.22s]
[0m13:20:37.896355 [debug] [Thread-1 (]: Finished running node test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb
[0m13:20:37.898819 [debug] [MainThread]: Using postgres connection "master"
[0m13:20:37.900225 [debug] [MainThread]: On master: BEGIN
[0m13:20:37.901461 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:20:37.909232 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m13:20:37.912018 [debug] [MainThread]: On master: COMMIT
[0m13:20:37.916340 [debug] [MainThread]: Using postgres connection "master"
[0m13:20:37.918568 [debug] [MainThread]: On master: COMMIT
[0m13:20:37.924444 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m13:20:37.925804 [debug] [MainThread]: On master: Close
[0m13:20:37.926955 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:20:37.930615 [debug] [MainThread]: Connection 'test.ecommerce_dbt.unique_slv_products_product_id.cf18bf12eb' was properly closed.
[0m13:20:37.932060 [info ] [MainThread]: 
[0m13:20:37.933815 [info ] [MainThread]: Finished running 30 data tests in 0 hours 0 minutes and 5.92 seconds (5.92s).
[0m13:20:37.943075 [debug] [MainThread]: Command end result
[0m13:20:38.424634 [info ] [MainThread]: 
[0m13:20:38.425969 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:20:38.427129 [info ] [MainThread]: 
[0m13:20:38.432492 [info ] [MainThread]: Done. PASS=30 WARN=0 ERROR=0 SKIP=0 TOTAL=30
[0m13:20:38.434448 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 10.1685505, "process_user_time": 4.583659, "process_kernel_time": 0.49553, "process_mem_max_rss": "125888", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m13:20:38.437551 [debug] [MainThread]: Command `dbt test` succeeded at 13:20:38.437280 after 10.17 seconds
[0m13:20:38.439991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c0482600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c01f0110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7436c01f3f80>]}
[0m13:20:38.443858 [debug] [MainThread]: Flushing usage events
[0m13:08:00.382109 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 13:08:00.396411 | aeaf3823-a4da-4b40-b570-822bfa0cb6f7 ==============================
[0m13:08:00.396411 [info ] [MainThread]: Running with dbt=1.8.0
[0m13:08:00.399525 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'log_path': '/opt/airflow/dbt/ecommerce_dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt debug --profiles-dir /opt/airflow/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:08:00.440166 [info ] [MainThread]: dbt version: 1.8.0
[0m13:08:00.441849 [info ] [MainThread]: python version: 3.12.11
[0m13:08:00.444810 [info ] [MainThread]: python path: /usr/local/bin/python3.12
[0m13:08:00.445963 [info ] [MainThread]: os info: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[0m13:08:00.486652 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.postgres'
[0m13:08:00.487844 [info ] [MainThread]: Using profiles dir at /opt/airflow/.dbt
[0m13:08:00.488659 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/.dbt/profiles.yml
[0m13:08:00.489446 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt/ecommerce_dbt/dbt_project.yml
[0m13:08:00.687789 [info ] [MainThread]: Configuration:
[0m13:08:00.691915 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m13:08:00.702423 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:08:00.706331 [info ] [MainThread]: Required dependencies:
[0m13:08:00.709342 [debug] [MainThread]: Executing "git --help"
[0m13:08:00.712337 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m13:08:00.716610 [info ] [MainThread]: Connection test skipped since no profile was found
[0m13:08:00.718474 [info ] [MainThread]: [31m2 checks failed:[0m
[0m13:08:00.722667 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "ecommerce_profile", target "dev" invalid: Runtime Error
    Could not find adapter type postgres!


[0m13:08:00.723975 [info ] [MainThread]: Error from git --help: Could not find command, ensure it is in the user's PATH: "git"

[0m13:08:00.726028 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_wall_clock_time": 0.7137982, "process_user_time": 2.384839, "process_kernel_time": 0.310029, "process_mem_max_rss": "101020", "process_in_blocks": "240", "command_success": false, "process_out_blocks": "0"}
[0m13:08:00.727352 [debug] [MainThread]: Command `dbt debug` failed at 13:08:00.726997 after 0.72 seconds
[0m13:08:00.729764 [debug] [MainThread]: Flushing usage events
